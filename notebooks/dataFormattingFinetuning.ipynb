{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash /home/azureuser/cloudfiles/code/blobfuse/blobfuse_raadsinformatie.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Select where to run notebook: \"azure\" or \"local\"\n",
    "my_run = \"azure\"\n",
    "\n",
    "import my_secrets as sc\n",
    "import settings as st\n",
    "\n",
    "if my_run == \"azure\":\n",
    "    import config_azure as cf\n",
    "elif my_run == \"local\":\n",
    "    import config as cf\n",
    "\n",
    "\n",
    "import os\n",
    "if my_run == \"azure\":\n",
    "    if not os.path.exists(cf.HUGGING_CACHE):\n",
    "        os.mkdir(cf.HUGGING_CACHE)\n",
    "    os.environ[\"TRANSFORMERS_CACHE\"] = cf.HUGGING_CACHE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load example data\n",
    "Datasets used in Finetuning.py example of the GitHub of GEITje. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test_sft: Dataset({\n",
      "        features: ['prompt', 'prompt_id', 'messages', 'category', 'messages_nl'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    train_sft: Dataset({\n",
      "        features: ['prompt', 'prompt_id', 'messages', 'category', 'messages_nl'],\n",
      "        num_rows: 9500\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    test_sft: Dataset({\n",
      "        features: ['prompt', 'prompt_id', 'messages', 'messages_nl'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    train_sft: Dataset({\n",
      "        features: ['prompt', 'prompt_id', 'messages', 'messages_nl'],\n",
      "        num_rows: 9500\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import DatasetDict, load_dataset, concatenate_datasets\n",
    "\n",
    "\n",
    "no_robots_nl = load_dataset('Rijgersberg/no_robots_nl')\n",
    "print(no_robots_nl)\n",
    "no_robots_nl[\"train_sft\"]=no_robots_nl[\"train_sft\"].select(range(2))\n",
    "no_robots_nl[\"test_sft\"]=no_robots_nl[\"test_sft\"].select(range(2))\n",
    "\n",
    "ultrachat_nl = load_dataset('Rijgersberg/ultrachat_10k_nl')\n",
    "print(ultrachat_nl)\n",
    "ultrachat_nl[\"train_sft\"]=ultrachat_nl[\"train_sft\"].select(range(2))\n",
    "ultrachat_nl[\"test_sft\"]=ultrachat_nl[\"test_sft\"].select(range(2))\n",
    "\n",
    "chat_dataset = DatasetDict({\n",
    "    'train_sft': concatenate_datasets([no_robots_nl['train_sft'],\n",
    "                                        ultrachat_nl['train_sft']]).shuffle(seed=42),\n",
    "    'test_sft': concatenate_datasets([no_robots_nl['test_sft'],\n",
    "                                        ultrachat_nl['test_sft']]).shuffle(seed=42),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspection: we only need the columns prompt_id (equal to doc id) and messages_nl. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Amsterdam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(f\"{cf.output_path}/txtfiles.pkl\")\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize text using GEITje/Mistral tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def get_tokens(model_name, df, text_col, new_col_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    all_texts = list(df[text_col].values)\n",
    "\n",
    "    all_len_tokens = []\n",
    "    for txt in all_texts:\n",
    "        tokens = tokenizer.tokenize(txt)\n",
    "        all_len_tokens.append(tokens)\n",
    "\n",
    "    df[new_col_name] = all_len_tokens\n",
    "    return df\n",
    "\n",
    "tokens_df = get_tokens('Rijgersberg/GEITje-7B-chat-v2', df, 'text', 'GEITjeTokens')\n",
    "# display(tokens_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f92ed8ae5d442890ad1c24eb4ecc4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3192525107b49919c2fd0456fcab30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191ecd610529470d9f2ff6ad91a9c2e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0894a97903bf499195868d43e2810127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a3f4b1415042659e28e2d882b9c29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5130b2f577bd4470a511b9d6318a6878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02933601e9c349158db0ebe4d3e02b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa3949e30fe4075a8f2afb0411b01e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c655670f1d4099beff7705df34c9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/FemkeBakker/AmsterdamGEITjeFormat200Tokens/commit/f01db5be52dcc2c7fe856041e7d401b3ecf02e20', commit_message='Upload dataset', commit_description='', oid='f01db5be52dcc2c7fe856041e7d401b3ecf02e20', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_message(input_txt, label):\n",
    "    message_user = {\n",
    "        \"content\":input_txt,\n",
    "        'role':'user'\n",
    "    }\n",
    "\n",
    "    message_model = {\n",
    "        \"content\":label,\n",
    "        'role':'assistant'\n",
    "    }\n",
    "\n",
    "    return [message_user, message_model]\n",
    "\n",
    "\n",
    "\n",
    "def format_data(df, text_col, model_token_col, label_col, split_col,  token_threshold='full_text'):\n",
    "    format_df = pd.DataFrame(columns=['prompt_id', 'message', split_col])\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        # select whole text\n",
    "        if token_threshold == 'full_text':\n",
    "            input_txt = row[text_col]\n",
    "\n",
    "        # else select text according to the token threshold\n",
    "        else:\n",
    "            # select first n (= token_theshold) tokens using the model tokenizer\n",
    "            tokens = row[model_token_col][0:token_threshold]\n",
    "\n",
    "            # combine tokens into txt\n",
    "            tokens_txt = ''.join(tokens)\n",
    "\n",
    "            # \\n is converted by tokenizer to <0x0A>, we reverse this to get original length\n",
    "            len_char = len(tokens_txt.replace(\"<0x0A>\", \"\\n\")) # get character length\n",
    "\n",
    "            # select the same amount of characters as the tokens\n",
    "            input_txt = row[text_col][0:len_char]\n",
    "\n",
    "        \n",
    "        # format message\n",
    "        label = row[label_col]\n",
    "        message = format_message(input_txt, label)\n",
    "\n",
    "        # save in dataframe\n",
    "        format_df.loc[len(format_df)] = {'prompt_id':row['id'], 'message':message, split_col:row[split_col]}\n",
    "\n",
    "    # split data\n",
    "    # if split_col = 4split -> split into dev, train, val and test\n",
    "    # if split_col = 2split -> split into train and test. Dev and val will be left empty\n",
    "    train_set = format_df.loc[format_df[split_col]=='train'].drop(columns=[split_col])\n",
    "    test_set = format_df.loc[format_df[split_col]=='test'].drop(columns=[split_col])\n",
    "\n",
    "    if split_col == '4split':\n",
    "        dev_set = format_df.loc[format_df[split_col]=='dev'].drop(columns=[split_col])\n",
    "        val_set = format_df.loc[format_df[split_col]=='val'].drop(columns=[split_col])\n",
    "\n",
    "        chat_dataset = DatasetDict({\n",
    "            'train': Dataset.from_pandas(train_set).remove_columns('__index_level_0__'),\n",
    "            'test': Dataset.from_pandas(test_set).remove_columns('__index_level_0__'),\n",
    "            'dev': Dataset.from_pandas(dev_set).remove_columns('__index_level_0__'),\n",
    "            'val': Dataset.from_pandas(val_set).remove_columns('__index_level_0__')\n",
    "        })\n",
    "\n",
    "    elif split_col == '2split':\n",
    "            chat_dataset = DatasetDict({\n",
    "            'train': Dataset.from_pandas(train_set).remove_columns('__index_level_0__'),\n",
    "            'test': Dataset.from_pandas(test_set).remove_columns('__index_level_0__'),\n",
    "        })\n",
    "\n",
    "\n",
    "    return chat_dataset\n",
    "     \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "data = format_data(tokens_df, 'text', 'GEITjeTokens', 'label', '4split', 200)\n",
    "data.push_to_hub(\"FemkeBakker/AmsterdamGEITjeFormat200Tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt_id', 'message'],\n",
       "        num_rows: 20028\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt_id', 'message'],\n",
       "        num_rows: 5340\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['prompt_id', 'message'],\n",
       "        num_rows: 1068\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['prompt_id', 'message'],\n",
       "        num_rows: 268\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e1cecc948942e2bd691557057e211e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/692 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 4.87M/4.87M [00:00<00:00, 5.51MB/s]\n",
      "Downloading data: 100%|██████████| 1.29M/1.29M [00:00<00:00, 3.16MB/s]\n",
      "Downloading data: 100%|██████████| 262k/262k [00:00<00:00, 837kB/s]\n",
      "Downloading data: 100%|██████████| 71.4k/71.4k [00:00<00:00, 273kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490460f2abff4cd9a3de8d22d25e4dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d2fe9502cf4d9a8ce97a5752b9359b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5340 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f939ee942247069d7105209c82f8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/1068 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df8fada1d2440df90a2653679d84464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split:   0%|          | 0/268 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt_id', 'message'],\n",
       "        num_rows: 20028\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt_id', 'message'],\n",
       "        num_rows: 5340\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['prompt_id', 'message'],\n",
       "        num_rows: 1068\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['prompt_id', 'message'],\n",
       "        num_rows: 268\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset('FemkeBakker/AmsterdamGEITjeFormat200Tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AmsterdamInContextLearning",
   "language": "python",
   "name": "amsterdamincontextlearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
