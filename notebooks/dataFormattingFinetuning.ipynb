{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash /home/azureuser/cloudfiles/code/blobfuse/blobfuse_raadsinformatie.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Select where to run notebook: \"azure\" or \"local\"\n",
    "my_run = \"azure\"\n",
    "\n",
    "import my_secrets as sc\n",
    "import settings as st\n",
    "\n",
    "if my_run == \"azure\":\n",
    "    import config_azure as cf\n",
    "elif my_run == \"local\":\n",
    "    import config as cf\n",
    "\n",
    "\n",
    "import os\n",
    "if my_run == \"azure\":\n",
    "    if not os.path.exists(cf.HUGGING_CACHE):\n",
    "        os.mkdir(cf.HUGGING_CACHE)\n",
    "    os.environ[\"TRANSFORMERS_CACHE\"] = cf.HUGGING_CACHE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load example data\n",
    "Datasets used in Finetuning.py example of the GitHub of GEITje. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test_sft: Dataset({\n",
      "        features: ['prompt', 'prompt_id', 'messages', 'category', 'messages_nl'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    train_sft: Dataset({\n",
      "        features: ['prompt', 'prompt_id', 'messages', 'category', 'messages_nl'],\n",
      "        num_rows: 9500\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    test_sft: Dataset({\n",
      "        features: ['prompt', 'prompt_id', 'messages', 'messages_nl'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    train_sft: Dataset({\n",
      "        features: ['prompt', 'prompt_id', 'messages', 'messages_nl'],\n",
      "        num_rows: 9500\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import DatasetDict, load_dataset, concatenate_datasets\n",
    "\n",
    "\n",
    "no_robots_nl = load_dataset('Rijgersberg/no_robots_nl')\n",
    "print(no_robots_nl)\n",
    "no_robots_nl[\"train_sft\"]=no_robots_nl[\"train_sft\"].select(range(2))\n",
    "no_robots_nl[\"test_sft\"]=no_robots_nl[\"test_sft\"].select(range(2))\n",
    "\n",
    "ultrachat_nl = load_dataset('Rijgersberg/ultrachat_10k_nl')\n",
    "print(ultrachat_nl)\n",
    "ultrachat_nl[\"train_sft\"]=ultrachat_nl[\"train_sft\"].select(range(2))\n",
    "ultrachat_nl[\"test_sft\"]=ultrachat_nl[\"test_sft\"].select(range(2))\n",
    "\n",
    "chat_dataset = DatasetDict({\n",
    "    'train_sft': concatenate_datasets([no_robots_nl['train_sft'],\n",
    "                                        ultrachat_nl['train_sft']]).shuffle(seed=42),\n",
    "    'test_sft': concatenate_datasets([no_robots_nl['test_sft'],\n",
    "                                        ultrachat_nl['test_sft']]).shuffle(seed=42),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspection: we only need the columns prompt_id (equal to doc id) and messages_nl. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Amsterdam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(f\"{cf.output_path}/txtfiles.pkl\")\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize text using GEITje/Mistral tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def get_tokens(model_name, df, text_col, new_col_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    all_texts = list(df[text_col].values)\n",
    "\n",
    "    all_len_tokens = []\n",
    "    for txt in all_texts:\n",
    "        tokens = tokenizer.tokenize(txt)\n",
    "        all_len_tokens.append(tokens)\n",
    "\n",
    "    df[new_col_name] = all_len_tokens\n",
    "    return df\n",
    "\n",
    "tokens_df = get_tokens('Rijgersberg/GEITje-7B-chat-v2', df, 'text', 'GEITjeTokens')\n",
    "# display(tokens_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b73b959e7f2487f8b85ada601ba6653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd01e59ed3d4f4aa2283eccf9b9ec8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45728cd5d34e4554863afa2aca93912b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b7632510c443669fea2cb29e1da695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed400505ed64dd39700a7981fbc8a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cf8a1c69f442a4b80c882c2135558a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee0e9ce88ef4f02a92622a2673bac51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a24ded28fe34f27b1bf55fa36eead91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac57b0243ead4150a16de0173c4530c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/FemkeBakker/trialdataet/commit/343b8b8f01dbdb7e18d63ee38d602aa954021a47', commit_message='Upload dataset', commit_description='', oid='343b8b8f01dbdb7e18d63ee38d602aa954021a47', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_message(input_txt, label):\n",
    "    message_user = {\n",
    "        \"content\":input_txt,\n",
    "        'role':'user'\n",
    "    }\n",
    "\n",
    "    message_model = {\n",
    "        \"content\":label,\n",
    "        'role':'assistant'\n",
    "    }\n",
    "\n",
    "    return [message_user, message_model]\n",
    "\n",
    "\n",
    "\n",
    "def format_data(df, text_col, model_token_col, label_col, split_col,  token_threshold='full_text'):\n",
    "    format_df = pd.DataFrame(columns=['prompt_id', 'message', split_col])\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        # select whole text\n",
    "        if token_threshold == 'full_text':\n",
    "            input_txt = row[text_col]\n",
    "\n",
    "        # else select text according to the token threshold\n",
    "        else:\n",
    "            # select first n (= token_theshold) tokens using the model tokenizer\n",
    "            tokens = row[model_token_col][0:token_threshold]\n",
    "\n",
    "            # combine tokens into txt\n",
    "            tokens_txt = ''.join(tokens)\n",
    "\n",
    "            # \\n is converted by tokenizer to <0x0A>, we reverse this to get original length\n",
    "            len_char = len(tokens_txt.replace(\"<0x0A>\", \"\\n\")) # get character length\n",
    "\n",
    "            # select the same amount of characters as the tokens\n",
    "            input_txt = row[text_col][0:len_char]\n",
    "\n",
    "        \n",
    "        # format message\n",
    "        label = row[label_col]\n",
    "        message = format_message(input_txt, label)\n",
    "\n",
    "        # save in dataframe\n",
    "        format_df.loc[len(format_df)] = {'prompt_id':row['id'], 'message':message, split_col:row[split_col]}\n",
    "\n",
    "    # split data\n",
    "    # if split_col = 4split -> split into dev, train, val and test\n",
    "    # if split_col = 2split -> split into train and test. Dev and val will be left empty\n",
    "    train_set = format_df.loc[format_df[split_col]=='train'].drop(columns=[split_col])\n",
    "    test_set = format_df.loc[format_df[split_col]=='test'].drop(columns=[split_col])\n",
    "\n",
    "    if split_col == '4split':\n",
    "        dev_set = format_df.loc[format_df[split_col]=='dev'].drop(columns=[split_col])\n",
    "        val_set = format_df.loc[format_df[split_col]=='val'].drop(columns=[split_col])\n",
    "\n",
    "        chat_dataset = DatasetDict({\n",
    "            'train': Dataset.from_pandas(train_set).remove_columns('__index_level_0__'),\n",
    "            'test': Dataset.from_pandas(test_set).remove_columns('__index_level_0__'),\n",
    "            'dev': Dataset.from_pandas(dev_set).remove_columns('__index_level_0__'),\n",
    "            'val': Dataset.from_pandas(val_set).remove_columns('__index_level_0__')\n",
    "        })\n",
    "\n",
    "    elif split_col == '2split':\n",
    "            chat_dataset = DatasetDict({\n",
    "            'train': Dataset.from_pandas(train_set).remove_columns('__index_level_0__'),\n",
    "            'test': Dataset.from_pandas(test_set).remove_columns('__index_level_0__'),\n",
    "        })\n",
    "\n",
    "\n",
    "    return chat_dataset\n",
    "     \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "data = format_data(tokens_df, 'text', 'GEITjeTokens', 'label', '4split', 200)\n",
    "data.push_to_hub(\"FemkeBakker/AmsterdamGEITjeFormat200Tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt_id', 'message'],\n",
       "        num_rows: 38\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt_id', 'message'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['prompt_id', 'message'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['prompt_id', 'message'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a436ae62c6547569271a46ef18bb637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/38 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea707d0ff4c343c1b9455f4b388a0bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d276308c249f40649b3892fca7cd5e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6949790cf36442aba53c00eaaa4fe7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.save_to_disk(f\"{cf.output_path}/trialdataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b53fd0441e4507929ce18bef57d82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c3e6bdab4947d4b3315d413f79aa3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623292e5fc1949bc9717af14e82f76a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60713266ad244583a384fcb7b13fa39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a05dc2d314f42ca88f7e5a7b18ab76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0ef2367aab46cb841c142ab00cb088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2fb865ef9d42b5bc5685a358dce982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30300e1cae649d897e7319ea25ccabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7414e357474725be061ab7b7d2c4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/FemkeBakker/trialdataet/commit/5e1cc8684a76d55561867203620fb87d73098818', commit_message='Upload dataset', commit_description='', oid='5e1cc8684a76d55561867203620fb87d73098818', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.push_to_hub(\"FemkeBakker/trialdataet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2b1c302876417888d7d23145168165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 15.3k/15.3k [00:00<00:00, 47.0kB/s]\n",
      "Downloading data: 100%|██████████| 6.65k/6.65k [00:00<00:00, 22.7kB/s]\n",
      "Downloading data: 100%|██████████| 4.72k/4.72k [00:00<00:00, 18.0kB/s]\n",
      "Downloading data: 100%|██████████| 4.82k/4.82k [00:00<00:00, 19.3kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514e3b8fc3e74de197d5ade970c2f677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/38 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4ea8fe8c614bcba895782371848fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6f38c4dff247f08d9067d07c7a5b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5431bc83e254e4ab0ddb32b5950556a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt_id', 'message'],\n",
       "        num_rows: 38\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt_id', 'message'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['prompt_id', 'message'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['prompt_id', 'message'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset('FemkeBakker/trialdataet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AmsterdamInContextLearning",
   "language": "python",
   "name": "amsterdamincontextlearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
