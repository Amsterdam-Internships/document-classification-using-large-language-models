{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash /home/azureuser/cloudfiles/code/blobfuse/blobfuse_raadsinformatie.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Select where to run notebook: \"azure\" or \"local\"\n",
    "my_run = \"azure\"\n",
    "\n",
    "# import my_secrets as sc\n",
    "import settings as st\n",
    "\n",
    "if my_run == \"azure\":\n",
    "    import config_azure as cf\n",
    "elif my_run == \"local\":\n",
    "    import config as cf\n",
    "\n",
    "\n",
    "import os\n",
    "if my_run == \"azure\":\n",
    "    if not os.path.exists(cf.HUGGING_CACHE):\n",
    "        os.mkdir(cf.HUGGING_CACHE)\n",
    "    os.environ[\"TRANSFORMERS_CACHE\"] = cf.HUGGING_CACHE\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# setup environment GEITje-7B Finetuning\n",
    "# - pip install torch\n",
    "# - pip install datasets\n",
    "# - pip install transformers\n",
    "# - pip install trl\n",
    "# - pip install accelerate (restart after)\n",
    "# - switch device_map='auto' to avaoid memory error\n",
    "\n",
    "# - pip install sentencepiece\n",
    "# - pip install jupyter\n",
    "# - pip install protobuf \n",
    "# pip install bitsandbytes\n",
    "# pip install bnb\n",
    "# pip install wandb==0.13.3 --upgrade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Overview\n",
    "Goal: get predictions of the finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../scripts/') \n",
    "import prompt_template as pt\n",
    "import prediction_helperfunctions as ph\n",
    "import truncation as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2024-05-02 08:59:53.899858: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-02 08:59:54.734507: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bd9471c4ce43e6bfff3edd02397c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f69e8dfde0647239f01247079f749b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model\n",
    "from transformers import pipeline, Conversation\n",
    "\n",
    "chatbot = pipeline(task='conversational', model='FemkeBakker/LlamaSmallData200Tokens',\n",
    "                   device_map='cpu', model_kwargs={'offload_buffers':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from bm25 import BM25\n",
    "\n",
    "\"\"\" Given a dataframe with txt, return a df with predictions \"\"\"\n",
    "# docs_df = dataframe with the documents that need to be predicted\n",
    "# text_column = name of the column that includes the input_text. Can be different based on the text representation method. \n",
    "# prompt_function = prompt template \n",
    "# train_df = dataframe with docs, which can be used as examples/training data/context data\n",
    "# num_examples = number of examples in the prompt\n",
    "\n",
    "def predictions_incontextlearning(chatbot, docs_df, text_column, prompt_function, train_df, num_examples):\n",
    "    results_df = pd.DataFrame(columns = ['id', 'path', 'text_column', 'prompt_function', 'response', 'prediction', 'label', 'runtime', 'date', 'prompt'])\n",
    "\n",
    "\n",
    "    if prompt_function == pt.fewshot_prompt_bm25:\n",
    "        BM25_model = BM25()\n",
    "        BM25_model.fit(train_df[text_column])\n",
    "\n",
    "    \n",
    "    # prompt each document\n",
    "    for index, row in docs_df.iterrows():\n",
    "        if (index + 1) % 200 == 0:\n",
    "            print(f\"Iteration {index +1}/{len(docs_df)} completed.\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # get the prompt, with the doc filled in\n",
    "        txt = row[text_column]\n",
    "\n",
    "        # each prompt function takes different arguments\n",
    "        # simple function is zeroshot+simple instruction\n",
    "        if prompt_function == pt.simple_prompt:\n",
    "            prompt = prompt_function(txt)\n",
    "      \n",
    "        # select fewshot examples using bm25\n",
    "        elif prompt_function == pt.fewshot_prompt_bm25:\n",
    "            prompt = prompt_function(txt, train_df, num_examples, text_column, BM25_model)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Prompt function not recognised. Check if prompt function is in prompt_template.py and included in the options above.\")\n",
    "\n",
    "        # prompt and get the response\n",
    "        converse = chatbot(Conversation(prompt))\n",
    "        response = converse[1]['content']\n",
    "        print(\"label: \", row['label'].lower())\n",
    "        print(\"response: \", response)\n",
    "\n",
    "        # extract prediction from response\n",
    "        prediction = ph.get_prediction_from_response(response)\n",
    "        print(\"prediction:\", prediction)\n",
    "\n",
    "        # save results in dataframe\n",
    "        results_df.loc[len(results_df)] = {\n",
    "            'id': row['id'],\n",
    "            'path' : row['path'],\n",
    "            'text_column' : docs_df.iloc[0]['trunc_col'],\n",
    "            'prompt_function': ph.get_promptfunction_name(prompt_function),\n",
    "            'response':response,\n",
    "            'prediction':prediction,\n",
    "            'label':row['label'].lower(),\n",
    "            'runtime':time.time()-start_time,\n",
    "            'date': ph.get_datetime(),\n",
    "            'prompt':prompt\n",
    "        }\n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\"\"\"\n",
    "Function to run GEITje In-Context Learning experiment. \n",
    "The function allows to resume experiment, if run_id matches.\n",
    "\"\"\"\n",
    "# df = dataframe with all docs that need to have a prediction (docs still need to be predict + already predicted)\n",
    "# run_id = unqiue for each experiment. \n",
    "# prompt_function = which prompt from prompt_template.py to use\n",
    "# text_col = colum in df where the text is. (Needs to be already truncated)\n",
    "# split_col = column with the dataset split. Either '2split' (train and test)or '4split'(train, test, dev and val)\n",
    "# subset_train = indicates which subset to use as training. either 'train' or 'dev'\n",
    "# subset_test = indicates which subset to use for testing. either 'test' or 'val'\n",
    "# label_col = column with the true label\n",
    "# prediction_path = path to file where predictions need to be saved.\n",
    "# overview_path = path to file where results of each run need to be saved.\n",
    "# model_name = name of the model. string.\n",
    "# num_exmples = number of exaples given to prompt. zero in case of zeroshot. \n",
    "\n",
    "def run_experiment(chatbot, df, run_id, prompt_function, text_col, split_col, subset_train, subset_test, label_col, prediction_path, overview_path, model_name, num_examples=0):\n",
    "    print(num_examples)\n",
    "    start_time = time.time()\n",
    "    test_df = df.loc[df[split_col]==subset_test]\n",
    "    train_df = df.loc[df[split_col]==subset_train]\n",
    "    \n",
    "    # get rows of df that still need to be predicted for the specific run_id\n",
    "    to_predict, previous_predictions = ph.get_rows_to_predict(test_df, prediction_path, run_id)\n",
    "\n",
    "    # devide to_predict into subsection of 50 predictions at a time. \n",
    "    # Allows to rerun without problem. And save subsections of 50 predictions.\n",
    "    step_range = list(range(0, len(to_predict), 25))\n",
    "\n",
    "    for i in range(len(step_range)):\n",
    "        try:\n",
    "            sub_to_predict = to_predict.iloc[step_range[i]:step_range[i+1]]\n",
    "            print(f'Starting...{step_range[i]}:{step_range[i+1]} out of {len(to_predict)}')\n",
    "        except Exception as e:\n",
    "            sub_to_predict = to_predict[step_range[i]:]\n",
    "            print(f'Starting...last {len(sub_to_predict)} docs')\n",
    "\n",
    "        # prompt geitje\n",
    "        predictions = predictions_incontextlearning(chatbot, sub_to_predict, text_col, prompt_function, train_df, num_examples)\n",
    "\n",
    "        # save info\n",
    "        predictions['run_id'] = run_id\n",
    "        predictions['train_set'] = subset_train\n",
    "        predictions['test_set'] = subset_test\n",
    "        predictions['shots'] = num_examples\n",
    "\n",
    "        # save new combinations in file\n",
    "        # ph.combine_and_save_df(predictions, prediction_path)\n",
    "\n",
    "        # if previous predictions, combine previous with new predictions, to get update classification report\n",
    "        try:\n",
    "            predictions = pd.concat([predictions, previous_predictions])\n",
    "\n",
    "            # set previous predictions to all predictions made until now. Necessary for next loop\n",
    "            previous_predictions = predictions\n",
    "        except Exception as e:\n",
    "            # set previous predictions to all predictions made until now. Necessary for next loop\n",
    "            previous_predictions = predictions\n",
    "\n",
    "        # save results in overview file\n",
    "        date = ph.get_datetime()\n",
    "        y_test = predictions['label']\n",
    "        y_pred = predictions['prediction']\n",
    "        report = classification_report(y_test, y_pred)\n",
    "\n",
    "        overview = pd.DataFrame(\n",
    "            [{\n",
    "                'model':model_name,\n",
    "                'run_id':run_id,\n",
    "                'date': date,\n",
    "                'train_set': subset_train,\n",
    "                'test_set': subset_test,\n",
    "                'train_set_support':len(df.loc[df[split_col]==subset_train]),\n",
    "                'test_set_support':len(predictions),\n",
    "                'split_col':split_col,\n",
    "                'text_col':df.iloc[0]['trunc_col'],\n",
    "                'runtime':sum(predictions['runtime']),\n",
    "                'accuracy': accuracy_score(y_test, y_pred),\n",
    "                'macro_avg_precision': precision_score(y_test, y_pred, average='macro'),\n",
    "                'macro_avg_recall': recall_score(y_test, y_pred, average='macro'),\n",
    "                'macro_avg_f1': f1_score(y_test, y_pred, average='macro'),\n",
    "                'classification_report':report\n",
    "            }   ]\n",
    "        )\n",
    "        # remove previous results of run_id, replace with new/updated results\n",
    "        # ph.replace_and_save_df(overview, overview_path, run_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set  variables, same for each model\n",
    "TRAIN_SET = 'dev' # must be dev or train\n",
    "TEST_SET = 'val' # must be val or test\n",
    "SPLIT_COLUMN = '4split' #must be either 2split or 4split. 2split = data split into train and test. 4split = data split into train, test, dev and val. \n",
    "LABEL_COLUMN = 'label'\n",
    "TEXT_COLUMN = 'trunc_txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = pd.read_pickle(f\"{cf.output_path}/txtfiles_tokenizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT_LlamaSmallData200Tokenssimple_promptLlamaTokens200_0devval_numEx0\n",
      "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsVal/finetuning/Llama/simple_prompt/predictions.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "MODEL_NAME = 'LlamaSmallData200Tokens'\n",
    "PROMPT = pt.simple_prompt\n",
    "PROMPT_NAME = ph.get_promptfunction_name(PROMPT)\n",
    "TOKENS_COL = 'LlamaTokens' # column with text split using tokenizer of either mistral (MistralTokens) or Llama (LlamaTokens). Using Llama, because Llama split into more tokens. \n",
    "FRONT_THRESHOLD = 200\n",
    "BACK_THRESHOLD = 0\n",
    "NUMBER_EXAMPLES = 0\n",
    "run_id = f'FT_{MODEL_NAME}{PROMPT_NAME}{TOKENS_COL}{FRONT_THRESHOLD}_{BACK_THRESHOLD}{TRAIN_SET}{TEST_SET}_numEx{NUMBER_EXAMPLES}'\n",
    "PREDICTION_PATH = f\"{cf.output_path}/predictionsVal/finetuning/Llama/{PROMPT_NAME}/predictions.pkl\"\n",
    "OVERVIEW_PATH = f\"{cf.output_path}/predictionsVal/finetuning/Llama/{PROMPT_NAME}/overview.pkl\"\n",
    "\n",
    "print(run_id)\n",
    "print(PREDICTION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "No chat template is defined for this tokenizer - using the default template for the LlamaTokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...0:25 out of 209\n",
      "label:  agenda\n",
      "response:  {'categorie': Agenda} \n",
      "prediction: agenda\n",
      "label:  brief\n",
      "response:  {'categorie': Gemeente Raadsadres} \n",
      "prediction: raadsadres\n",
      "label:  agenda\n",
      "response:  {'categorie': Agenda} \n",
      "prediction: agenda\n",
      "label:  onderzoeksrapport\n",
      "response:  {'categorie': Agenda} \n",
      "prediction: agenda\n",
      "label:  factsheet\n",
      "response:  {'categorie': Factsheet} \n",
      "prediction: factsheet\n",
      "label:  voordracht\n",
      "response:  {'categorie': Voordracht} \n",
      "prediction: voordracht\n",
      "label:  motie\n",
      "response:  {'categorie': Motie} \n",
      "prediction: motie\n",
      "label:  motie\n",
      "response:  {'categorie': Amendement} \n",
      "prediction: NoPredictionInOutput\n",
      "label:  schriftelijke vraag\n",
      "response:  {'categorie': Schriftelijke Vraag} \n",
      "prediction: schriftelijke vraag\n",
      "label:  motie\n",
      "response:  {'categorie': Raadsadres} \n",
      "prediction: raadsadres\n",
      "label:  raadsadres\n",
      "response:  {'categorie': Motie} \n",
      "prediction: motie\n",
      "label:  raadsadres\n",
      "response:  {'categorie': Agenda} \n",
      "prediction: agenda\n",
      "label:  schriftelijke vraag\n",
      "response:  {'categorie': Schriftelijke Vraag} \n",
      "prediction: schriftelijke vraag\n",
      "label:  brief\n",
      "response:  {'categorie': Brief} \n",
      "prediction: brief\n",
      "label:  agenda\n",
      "response:  {'categorie': Agenda} \n",
      "prediction: agenda\n",
      "label:  agenda\n",
      "response:  {'categorie': Agenda} \n",
      "prediction: agenda\n",
      "label:  schriftelijke vraag\n",
      "response:  {'categorie': Schriftelijke Vraag} \n",
      "prediction: schriftelijke vraag\n",
      "label:  voordracht\n",
      "response:  {'categorie': Voordracht} \n",
      "prediction: voordracht\n",
      "label:  schriftelijke vraag\n",
      "response:  {'categorie': Schriftelijke Vraag} \n",
      "prediction: schriftelijke vraag\n",
      "label:  motie\n",
      "response:  {'categorie': Motie} \n",
      "prediction: motie\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m trunc_df \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39madd_truncation_column(txt,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, TOKENS_COL, FRONT_THRESHOLD, BACK_THRESHOLD)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# # if new run MAKE SURE RUN_ID IS UNIQUE, if want to resume run, pass in that run_id\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchatbot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrunc_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFinetuning\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mPROMPT_NAME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mTOKENS_COL\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mFRONT_THRESHOLD\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBACK_THRESHOLD\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mTRAIN_SET\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mTEST_SET\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_numEx\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mNUMBER_EXAMPLES\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPROMPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTEXT_COLUMN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSPLIT_COLUMN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTRAIN_SET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTEST_SET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLABEL_COLUMN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPREDICTION_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOVERVIEW_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUMBER_EXAMPLES\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 44\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(chatbot, df, run_id, prompt_function, text_col, split_col, subset_train, subset_test, label_col, prediction_path, overview_path, model_name, num_examples)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting...last \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(sub_to_predict)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m docs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# prompt geitje\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions_incontextlearning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchatbot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_to_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# save info\u001b[39;00m\n\u001b[1;32m     47\u001b[0m predictions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m run_id\n",
      "Cell \u001b[0;32mIn[4], line 45\u001b[0m, in \u001b[0;36mpredictions_incontextlearning\u001b[0;34m(chatbot, docs_df, text_column, prompt_function, train_df, num_examples)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt function not recognised. Check if prompt function is in prompt_template.py and included in the options above.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# prompt and get the response\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m converse \u001b[38;5;241m=\u001b[39m \u001b[43mchatbot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConversation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m response \u001b[38;5;241m=\u001b[39m converse[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel: \u001b[39m\u001b[38;5;124m\"\u001b[39m, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mlower())\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/transformers/pipelines/conversational.py:287\u001b[0m, in \u001b[0;36mConversationalPipeline.__call__\u001b[0;34m(self, conversations, num_workers, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(conversations, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(conversations[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    286\u001b[0m     conversations \u001b[38;5;241m=\u001b[39m [Conversation(conv) \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m conversations]\n\u001b[0;32m--> 287\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconversations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/transformers/pipelines/base.py:1206\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1199\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1200\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1203\u001b[0m         )\n\u001b[1;32m   1204\u001b[0m     )\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/transformers/pipelines/base.py:1213\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1212\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1213\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1214\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/transformers/pipelines/base.py:1112\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1111\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1112\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/transformers/pipelines/conversational.py:306\u001b[0m, in \u001b[0;36mConversationalPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_new_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[1;32m    305\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_new_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[0;32m--> 306\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n\u001b[1;32m    308\u001b[0m     start_position \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/transformers/generation/utils.py:1575\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1567\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1568\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1569\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1570\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1572\u001b[0m     )\n\u001b[1;32m   1574\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1575\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1593\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1594\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1599\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1600\u001b[0m     )\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/transformers/generation/utils.py:2697\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2694\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2696\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2697\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2698\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2700\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2701\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2705\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1196\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1193\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1196\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1016\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1006\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1007\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1013\u001b[0m         cache_position,\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1016\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:739\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 739\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    749\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:670\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    667\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m key_states\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    668\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m--> 670\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_dropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    678\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    679\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # ----- EXPERIMENT --------\n",
    "\n",
    "# add new column with truncated text -> new dataframe with column + new column name\n",
    "trunc_df = tf.add_truncation_column(txt,'text', TOKENS_COL, FRONT_THRESHOLD, BACK_THRESHOLD)\n",
    "\n",
    "# # if new run MAKE SURE RUN_ID IS UNIQUE, if want to resume run, pass in that run_id\n",
    "run_experiment(chatbot, trunc_df, f'Finetuning{PROMPT_NAME}{TOKENS_COL}{FRONT_THRESHOLD}_{BACK_THRESHOLD}{TRAIN_SET}{TEST_SET}_numEx{NUMBER_EXAMPLES}', PROMPT, TEXT_COLUMN, SPLIT_COLUMN, TRAIN_SET, TEST_SET, LABEL_COLUMN, PREDICTION_PATH, OVERVIEW_PATH, MODEL_NAME, NUMBER_EXAMPLES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>text_column</th>\n",
       "      <th>prompt_function</th>\n",
       "      <th>response</th>\n",
       "      <th>prediction</th>\n",
       "      <th>label</th>\n",
       "      <th>runtime</th>\n",
       "      <th>date</th>\n",
       "      <th>prompt</th>\n",
       "      <th>run_id</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>shots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25976</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>{'categorie': Agenda}</td>\n",
       "      <td>agenda</td>\n",
       "      <td>agenda</td>\n",
       "      <td>18.792697</td>\n",
       "      <td>2024-04-29 13:33:42.405623+02:00</td>\n",
       "      <td>\\n    Classificeer het document in één van de ...</td>\n",
       "      <td>FT_GEITjeSmallData200Tokenssimple_promptLlamaT...</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22516</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>{'categorie': Brief}</td>\n",
       "      <td>brief</td>\n",
       "      <td>brief</td>\n",
       "      <td>14.238767</td>\n",
       "      <td>2024-04-29 13:33:56.714152+02:00</td>\n",
       "      <td>\\n    Classificeer het document in één van de ...</td>\n",
       "      <td>FT_GEITjeSmallData200Tokenssimple_promptLlamaT...</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15708</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>{'categorie': Agenda}</td>\n",
       "      <td>agenda</td>\n",
       "      <td>agenda</td>\n",
       "      <td>14.273011</td>\n",
       "      <td>2024-04-29 13:34:10.996600+02:00</td>\n",
       "      <td>\\n    Classificeer het document in één van de ...</td>\n",
       "      <td>FT_GEITjeSmallData200Tokenssimple_promptLlamaT...</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8810</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>{'categorie': Onderzoeksrapport}</td>\n",
       "      <td>onderzoeksrapport</td>\n",
       "      <td>onderzoeksrapport</td>\n",
       "      <td>20.118762</td>\n",
       "      <td>2024-04-29 13:34:31.117243+02:00</td>\n",
       "      <td>\\n    Classificeer het document in één van de ...</td>\n",
       "      <td>FT_GEITjeSmallData200Tokenssimple_promptLlamaT...</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32980</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>{'categorie': Factsheet}</td>\n",
       "      <td>factsheet</td>\n",
       "      <td>factsheet</td>\n",
       "      <td>16.799716</td>\n",
       "      <td>2024-04-29 13:34:47.918599+02:00</td>\n",
       "      <td>\\n    Classificeer het document in één van de ...</td>\n",
       "      <td>FT_GEITjeSmallData200Tokenssimple_promptLlamaT...</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>849</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>{'categorie': Motie}</td>\n",
       "      <td>motie</td>\n",
       "      <td>motie</td>\n",
       "      <td>14.255849</td>\n",
       "      <td>2024-04-29 14:31:11.698306+02:00</td>\n",
       "      <td>\\n    Classificeer het document in één van de ...</td>\n",
       "      <td>FT_GEITjeSmallData200Tokenssimple_promptLlamaT...</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29591</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>{'categorie': Voordracht}</td>\n",
       "      <td>voordracht</td>\n",
       "      <td>voordracht</td>\n",
       "      <td>17.181545</td>\n",
       "      <td>2024-04-29 14:31:28.881780+02:00</td>\n",
       "      <td>\\n    Classificeer het document in één van de ...</td>\n",
       "      <td>FT_GEITjeSmallData200Tokenssimple_promptLlamaT...</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26434</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>{'categorie': Raadsnotulen}</td>\n",
       "      <td>raadsnotulen</td>\n",
       "      <td>raadsnotulen</td>\n",
       "      <td>20.037838</td>\n",
       "      <td>2024-04-29 14:31:48.921263+02:00</td>\n",
       "      <td>\\n    Classificeer het document in één van de ...</td>\n",
       "      <td>FT_GEITjeSmallData200Tokenssimple_promptLlamaT...</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10269</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>{'categorie': Actualiteit}</td>\n",
       "      <td>actualiteit</td>\n",
       "      <td>actualiteit</td>\n",
       "      <td>17.375131</td>\n",
       "      <td>2024-04-29 14:32:06.298052+02:00</td>\n",
       "      <td>\\n    Classificeer het document in één van de ...</td>\n",
       "      <td>FT_GEITjeSmallData200Tokenssimple_promptLlamaT...</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30098</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>{'categorie': Schriftelijke Vraag}</td>\n",
       "      <td>schriftelijke vraag</td>\n",
       "      <td>schriftelijke vraag</td>\n",
       "      <td>21.608514</td>\n",
       "      <td>2024-04-29 14:32:27.908434+02:00</td>\n",
       "      <td>\\n    Classificeer het document in één van de ...</td>\n",
       "      <td>FT_GEITjeSmallData200Tokenssimple_promptLlamaT...</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               path  \\\n",
       "0   25976  /home/azureuser/cloudfiles/code/blobfuse/raads...   \n",
       "1   22516  /home/azureuser/cloudfiles/code/blobfuse/raads...   \n",
       "2   15708  /home/azureuser/cloudfiles/code/blobfuse/raads...   \n",
       "3    8810  /home/azureuser/cloudfiles/code/blobfuse/raads...   \n",
       "4   32980  /home/azureuser/cloudfiles/code/blobfuse/raads...   \n",
       "..    ...                                                ...   \n",
       "4     849  /home/azureuser/cloudfiles/code/blobfuse/raads...   \n",
       "5   29591  /home/azureuser/cloudfiles/code/blobfuse/raads...   \n",
       "6   26434  /home/azureuser/cloudfiles/code/blobfuse/raads...   \n",
       "7   10269  /home/azureuser/cloudfiles/code/blobfuse/raads...   \n",
       "8   30098  /home/azureuser/cloudfiles/code/blobfuse/raads...   \n",
       "\n",
       "                           text_column prompt_function  \\\n",
       "0   TruncationLlamaTokensFront200Back0   simple_prompt   \n",
       "1   TruncationLlamaTokensFront200Back0   simple_prompt   \n",
       "2   TruncationLlamaTokensFront200Back0   simple_prompt   \n",
       "3   TruncationLlamaTokensFront200Back0   simple_prompt   \n",
       "4   TruncationLlamaTokensFront200Back0   simple_prompt   \n",
       "..                                 ...             ...   \n",
       "4   TruncationLlamaTokensFront200Back0   simple_prompt   \n",
       "5   TruncationLlamaTokensFront200Back0   simple_prompt   \n",
       "6   TruncationLlamaTokensFront200Back0   simple_prompt   \n",
       "7   TruncationLlamaTokensFront200Back0   simple_prompt   \n",
       "8   TruncationLlamaTokensFront200Back0   simple_prompt   \n",
       "\n",
       "                              response           prediction  \\\n",
       "0                {'categorie': Agenda}               agenda   \n",
       "1                 {'categorie': Brief}                brief   \n",
       "2                {'categorie': Agenda}               agenda   \n",
       "3     {'categorie': Onderzoeksrapport}    onderzoeksrapport   \n",
       "4             {'categorie': Factsheet}            factsheet   \n",
       "..                                 ...                  ...   \n",
       "4                 {'categorie': Motie}                motie   \n",
       "5            {'categorie': Voordracht}           voordracht   \n",
       "6          {'categorie': Raadsnotulen}         raadsnotulen   \n",
       "7           {'categorie': Actualiteit}          actualiteit   \n",
       "8   {'categorie': Schriftelijke Vraag}  schriftelijke vraag   \n",
       "\n",
       "                  label    runtime                             date  \\\n",
       "0                agenda  18.792697 2024-04-29 13:33:42.405623+02:00   \n",
       "1                 brief  14.238767 2024-04-29 13:33:56.714152+02:00   \n",
       "2                agenda  14.273011 2024-04-29 13:34:10.996600+02:00   \n",
       "3     onderzoeksrapport  20.118762 2024-04-29 13:34:31.117243+02:00   \n",
       "4             factsheet  16.799716 2024-04-29 13:34:47.918599+02:00   \n",
       "..                  ...        ...                              ...   \n",
       "4                 motie  14.255849 2024-04-29 14:31:11.698306+02:00   \n",
       "5            voordracht  17.181545 2024-04-29 14:31:28.881780+02:00   \n",
       "6          raadsnotulen  20.037838 2024-04-29 14:31:48.921263+02:00   \n",
       "7           actualiteit  17.375131 2024-04-29 14:32:06.298052+02:00   \n",
       "8   schriftelijke vraag  21.608514 2024-04-29 14:32:27.908434+02:00   \n",
       "\n",
       "                                               prompt  \\\n",
       "0   \\n    Classificeer het document in één van de ...   \n",
       "1   \\n    Classificeer het document in één van de ...   \n",
       "2   \\n    Classificeer het document in één van de ...   \n",
       "3   \\n    Classificeer het document in één van de ...   \n",
       "4   \\n    Classificeer het document in één van de ...   \n",
       "..                                                ...   \n",
       "4   \\n    Classificeer het document in één van de ...   \n",
       "5   \\n    Classificeer het document in één van de ...   \n",
       "6   \\n    Classificeer het document in één van de ...   \n",
       "7   \\n    Classificeer het document in één van de ...   \n",
       "8   \\n    Classificeer het document in één van de ...   \n",
       "\n",
       "                                               run_id train_set test_set  \\\n",
       "0   FT_GEITjeSmallData200Tokenssimple_promptLlamaT...       dev      val   \n",
       "1   FT_GEITjeSmallData200Tokenssimple_promptLlamaT...       dev      val   \n",
       "2   FT_GEITjeSmallData200Tokenssimple_promptLlamaT...       dev      val   \n",
       "3   FT_GEITjeSmallData200Tokenssimple_promptLlamaT...       dev      val   \n",
       "4   FT_GEITjeSmallData200Tokenssimple_promptLlamaT...       dev      val   \n",
       "..                                                ...       ...      ...   \n",
       "4   FT_GEITjeSmallData200Tokenssimple_promptLlamaT...       dev      val   \n",
       "5   FT_GEITjeSmallData200Tokenssimple_promptLlamaT...       dev      val   \n",
       "6   FT_GEITjeSmallData200Tokenssimple_promptLlamaT...       dev      val   \n",
       "7   FT_GEITjeSmallData200Tokenssimple_promptLlamaT...       dev      val   \n",
       "8   FT_GEITjeSmallData200Tokenssimple_promptLlamaT...       dev      val   \n",
       "\n",
       "    shots  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "..    ...  \n",
       "4       0  \n",
       "5       0  \n",
       "6       0  \n",
       "7       0  \n",
       "8       0  \n",
       "\n",
       "[209 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = pd.read_pickle(PREDICTION_PATH)\n",
    "display(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prediction</th>\n",
       "      <th>NoPredictionInOutput</th>\n",
       "      <th>actualiteit</th>\n",
       "      <th>agenda</th>\n",
       "      <th>besluit</th>\n",
       "      <th>brief</th>\n",
       "      <th>factsheet</th>\n",
       "      <th>motie</th>\n",
       "      <th>onderzoeksrapport</th>\n",
       "      <th>raadsadres</th>\n",
       "      <th>raadsnotulen</th>\n",
       "      <th>schriftelijke vraag</th>\n",
       "      <th>voordracht</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actualiteit</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agenda</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>besluit</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brief</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>factsheet</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onderzoeksrapport</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raadsadres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raadsnotulen</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schriftelijke vraag</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voordracht</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prediction           NoPredictionInOutput  actualiteit  agenda  besluit  \\\n",
       "label                                                                     \n",
       "actualiteit                             0            4       4        0   \n",
       "agenda                                  0            0      22        0   \n",
       "besluit                                 0            0       0        4   \n",
       "brief                                   0            0       0        0   \n",
       "factsheet                               0            0       0        0   \n",
       "motie                                   0            0       0        0   \n",
       "onderzoeksrapport                       2            1       0        0   \n",
       "raadsadres                              1            1       0        0   \n",
       "raadsnotulen                            0            0       0        0   \n",
       "schriftelijke vraag                     1            0       0        0   \n",
       "voordracht                              0            0       0        0   \n",
       "\n",
       "prediction           brief  factsheet  motie  onderzoeksrapport  raadsadres  \\\n",
       "label                                                                         \n",
       "actualiteit              1          0      0                  0           0   \n",
       "agenda                   0          0      0                  1           0   \n",
       "besluit                  0          0      0                  0           0   \n",
       "brief                   10          0      2                  0           0   \n",
       "factsheet                0          2      0                  0           0   \n",
       "motie                    0          0     64                  0           1   \n",
       "onderzoeksrapport        0          2      0                 11           0   \n",
       "raadsadres               0          0      0                  0          16   \n",
       "raadsnotulen             0          0      0                  0           0   \n",
       "schriftelijke vraag      0          0      1                  1           0   \n",
       "voordracht               0          0      0                  0           0   \n",
       "\n",
       "prediction           raadsnotulen  schriftelijke vraag  voordracht  \n",
       "label                                                               \n",
       "actualiteit                     0                    1           0  \n",
       "agenda                          0                    0           0  \n",
       "besluit                         0                    0           0  \n",
       "brief                           0                    0           0  \n",
       "factsheet                       0                    0           0  \n",
       "motie                           0                    0           0  \n",
       "onderzoeksrapport               0                    0           0  \n",
       "raadsadres                      0                    0           0  \n",
       "raadsnotulen                    3                    0           0  \n",
       "schriftelijke vraag             0                   29           0  \n",
       "voordracht                      0                    0          24  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "NoPredictionInOutput       0.00      0.00      0.00         0\n",
      "         actualiteit       0.67      0.40      0.50        10\n",
      "              agenda       0.85      0.96      0.90        23\n",
      "             besluit       1.00      1.00      1.00         4\n",
      "               brief       0.91      0.83      0.87        12\n",
      "           factsheet       0.50      1.00      0.67         2\n",
      "               motie       0.96      0.98      0.97        65\n",
      "   onderzoeksrapport       0.85      0.69      0.76        16\n",
      "          raadsadres       0.94      0.89      0.91        18\n",
      "        raadsnotulen       1.00      1.00      1.00         3\n",
      " schriftelijke vraag       0.97      0.91      0.94        32\n",
      "          voordracht       1.00      1.00      1.00        24\n",
      "\n",
      "            accuracy                           0.90       209\n",
      "           macro avg       0.80      0.80      0.79       209\n",
      "        weighted avg       0.92      0.90      0.91       209\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "        actualiteit       0.67      0.40      0.50        10\n",
      "             agenda       0.85      0.96      0.90        23\n",
      "            besluit       1.00      1.00      1.00         4\n",
      "              brief       0.91      0.83      0.87        12\n",
      "          factsheet       0.50      1.00      0.67         2\n",
      "              motie       0.96      0.98      0.97        65\n",
      "  onderzoeksrapport       0.85      0.79      0.81        14\n",
      "         raadsadres       0.94      0.94      0.94        17\n",
      "       raadsnotulen       1.00      1.00      1.00         3\n",
      "schriftelijke vraag       0.97      0.94      0.95        31\n",
      "         voordracht       1.00      1.00      1.00        24\n",
      "\n",
      "           accuracy                           0.92       205\n",
      "          macro avg       0.88      0.89      0.87       205\n",
      "       weighted avg       0.92      0.92      0.92       205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "confusion_matrices = pd.crosstab(pred['label'], pred['prediction'])\n",
    "display(confusion_matrices)\n",
    "\n",
    "report = classification_report(pred['label'], pred['prediction']) \n",
    "print(report)\n",
    "\n",
    "report = classification_report(pred.loc[pred['prediction']!='NoPredictionInOutput']['label'], pred.loc[pred['prediction']!='NoPredictionInOutput']['prediction']) \n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table above we can see that many docs get correctly predicted. \n",
    "The classes besluit, raadsnotulen and voordracht are completely correct. However, besluit and raadsnotulen do not have many docs in the validation set. \n",
    "\n",
    "Additionally, there are no NoPredictionFormat errors, meaning that each time GEITje returned the output in the correct format, that of a json file.\n",
    "However, there are 4 NoPredictionInOutput errors, meaning that within the output format it could not find a class from the class list\n",
    "\n",
    "Let's take a closer look at NoPredictionInOutput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>response</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>schriftelijke vraag</td>\n",
       "      <td>{'categorie': Memo}</td>\n",
       "      <td>NoPredictionInOutput</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>onderzoeksrapport</td>\n",
       "      <td>{'categorie': Plan}</td>\n",
       "      <td>NoPredictionInOutput</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>raadsadres</td>\n",
       "      <td>{'categorie': Aanbiedingsformulier}</td>\n",
       "      <td>NoPredictionInOutput</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>onderzoeksrapport</td>\n",
       "      <td>{'categorie': Plan van aanpak}</td>\n",
       "      <td>NoPredictionInOutput</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  label                             response  \\\n",
       "4   schriftelijke vraag                  {'categorie': Memo}   \n",
       "12    onderzoeksrapport                  {'categorie': Plan}   \n",
       "2            raadsadres  {'categorie': Aanbiedingsformulier}   \n",
       "1     onderzoeksrapport       {'categorie': Plan van aanpak}   \n",
       "\n",
       "              prediction  \n",
       "4   NoPredictionInOutput  \n",
       "12  NoPredictionInOutput  \n",
       "2   NoPredictionInOutput  \n",
       "1   NoPredictionInOutput  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "no_prediction = pred.loc[pred['prediction']=='NoPredictionInOutput']\n",
    "no_prediction = no_prediction[['label', 'response', 'prediction']]\n",
    "display(no_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the response predicts clases that are not included in the class list. Thus GEITje creates new classes. One advantage: easy to add classes.\n",
    "\n",
    "Next, we take a closer look at the other mistakes in the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'motie': 67, 'schriftelijke vraag': 30, 'agenda': 26, 'voordracht': 24, 'raadsadres': 17, 'onderzoeksrapport': 13, 'brief': 11, 'actualiteit': 6, 'factsheet': 4, 'besluit': 4, 'raadsnotulen': 3})\n",
      "Counter({'motie': 65, 'schriftelijke vraag': 31, 'voordracht': 24, 'agenda': 23, 'raadsadres': 17, 'onderzoeksrapport': 14, 'brief': 12, 'actualiteit': 10, 'besluit': 4, 'raadsnotulen': 3, 'factsheet': 2})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "mistakes = pred.loc[pred['prediction']!=pred['label']]\n",
    "mistakes = pred.loc[pred['prediction']!='NoPredictionInOutput']\n",
    "print(Counter(mistakes['prediction']))\n",
    "print(Counter(mistakes['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>run_id</th>\n",
       "      <th>date</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>train_set_support</th>\n",
       "      <th>test_set_support</th>\n",
       "      <th>split_col</th>\n",
       "      <th>text_col</th>\n",
       "      <th>runtime</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro_avg_precision</th>\n",
       "      <th>macro_avg_recall</th>\n",
       "      <th>macro_avg_f1</th>\n",
       "      <th>classification_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GEITje-7B-chat-v2</td>\n",
       "      <td>IC_GEITje-7B-chat-v2simple_promptLlamaTokens20...</td>\n",
       "      <td>2024-04-29 19:00:27.021162+02:00</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>832</td>\n",
       "      <td>209</td>\n",
       "      <td>4split</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>5285.075402</td>\n",
       "      <td>0.674641</td>\n",
       "      <td>0.598501</td>\n",
       "      <td>0.595675</td>\n",
       "      <td>0.503742</td>\n",
       "      <td>precision    recall  f1-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model                                             run_id  \\\n",
       "0  GEITje-7B-chat-v2  IC_GEITje-7B-chat-v2simple_promptLlamaTokens20...   \n",
       "\n",
       "                              date train_set test_set  train_set_support  \\\n",
       "0 2024-04-29 19:00:27.021162+02:00       dev      val                832   \n",
       "\n",
       "   test_set_support split_col                            text_col  \\\n",
       "0               209    4split  TruncationLlamaTokensFront200Back0   \n",
       "\n",
       "       runtime  accuracy  macro_avg_precision  macro_avg_recall  macro_avg_f1  \\\n",
       "0  5285.075402  0.674641             0.598501          0.595675      0.503742   \n",
       "\n",
       "                               classification_report  \n",
       "0                        precision    recall  f1-...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yeet = pd.read_pickle(f'{cf.output_path}/predictionsVal/in_context/GEITje/simple_prompt/overview.pkl')\n",
    "display(yeet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'OutOfMemoryError' on <module 'torch.cuda' from '/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/cuda/__init__.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m yeet \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/overview_models.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m display(yeet)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/pandas/io/pickle.py:201\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/pandas/compat/pickle_compat.py:218\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# \"Unpickler\" has no attribute \"is_verbose\"  [attr-defined]\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     up\u001b[38;5;241m.\u001b[39mis_verbose \u001b[38;5;241m=\u001b[39m is_verbose  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/pickle.py:1210\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1210\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/pickle.py:1535\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1535\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/pandas/compat/pickle_compat.py:149\u001b[0m, in \u001b[0;36mUnpickler.find_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m    147\u001b[0m key \u001b[38;5;241m=\u001b[39m (module, name)\n\u001b[1;32m    148\u001b[0m module, name \u001b[38;5;241m=\u001b[39m _class_locations_map\u001b[38;5;241m.\u001b[39mget(key, key)\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/pickle.py:1579\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;28m__import__\u001b[39m(module, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m-> 1579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_getattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/pickle.py:331\u001b[0m, in \u001b[0;36m_getattribute\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m    329\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, subpath)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt get attribute \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m                              \u001b[38;5;241m.\u001b[39mformat(name, obj)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, parent\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'OutOfMemoryError' on <module 'torch.cuda' from '/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/cuda/__init__.py'>"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "yeet = pd.read_pickle(f'{cf.output_path}/overview_models.pkl')\n",
    "display(yeet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: psutil in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: huggingface-hub in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from accelerate) (1.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: typing_extensions in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: requests in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: filelock in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from huggingface-hub->accelerate) (3.13.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from huggingface-hub->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.29.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'OutOfMemoryError' on <module 'torch.cuda' from '/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/cuda/__init__.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m yeet \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/overview_models.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m display(yeet)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/pandas/io/pickle.py:201\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/pandas/compat/pickle_compat.py:218\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# \"Unpickler\" has no attribute \"is_verbose\"  [attr-defined]\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     up\u001b[38;5;241m.\u001b[39mis_verbose \u001b[38;5;241m=\u001b[39m is_verbose  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/pickle.py:1210\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1210\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/pickle.py:1535\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1535\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/pandas/compat/pickle_compat.py:149\u001b[0m, in \u001b[0;36mUnpickler.find_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m    147\u001b[0m key \u001b[38;5;241m=\u001b[39m (module, name)\n\u001b[1;32m    148\u001b[0m module, name \u001b[38;5;241m=\u001b[39m _class_locations_map\u001b[38;5;241m.\u001b[39mget(key, key)\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/pickle.py:1579\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;28m__import__\u001b[39m(module, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m-> 1579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_getattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/pickle.py:331\u001b[0m, in \u001b[0;36m_getattribute\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m    329\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, subpath)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt get attribute \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m                              \u001b[38;5;241m.\u001b[39mformat(name, obj)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, parent\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'OutOfMemoryError' on <module 'torch.cuda' from '/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/cuda/__init__.py'>"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>base_model</th>\n",
       "      <th>chat_dataset</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>training_args</th>\n",
       "      <th>resume_from_checkpoint</th>\n",
       "      <th>date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>Error</th>\n",
       "      <th>run_id</th>\n",
       "      <th>save_to_hub</th>\n",
       "      <th>output_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryOutFinetuningGeitje</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-25 13:21:46.201696+02:00</td>\n",
       "      <td>0.876791</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryOutFinetuningGeitje</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-04-25 13:24:59.884223+02:00</td>\n",
       "      <td>0.274652</td>\n",
       "      <td>Error(s) in loading state_dict for MistralForC...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryOutFinetuningGeitje</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-04-25 13:25:57.527833+02:00</td>\n",
       "      <td>0.362344</td>\n",
       "      <td>No valid checkpoint found in output directory ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryOutFinetuningGeitje</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-25 13:26:24.369492+02:00</td>\n",
       "      <td>0.319212</td>\n",
       "      <td>CUDA out of memory. Tried to allocate 112.00 M...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryOutFinetuningGeitje</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-04-26 08:47:21.945291+02:00</td>\n",
       "      <td>0.392476</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryOutFinetuningGeitje</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-04-26 08:47:57.151755+02:00</td>\n",
       "      <td>0.600505</td>\n",
       "      <td>string longer than 2147483647 bytes</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryoutGeitje2</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-26 08:56:52.283214+02:00</td>\n",
       "      <td>0.449522</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryoutGeitje2</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-04-26 09:26:12.329799+02:00</td>\n",
       "      <td>3.251497</td>\n",
       "      <td>[Errno 2] No such file or directory: '/home/az...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryoutGeitje2</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-04-26 09:29:06.636546+02:00</td>\n",
       "      <td>0.543515</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/tryoutstablelm</td>\n",
       "      <td>stabilityai/stablelm-2-1_6b</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-29 09:46:03.908296+02:00</td>\n",
       "      <td>0.364137</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/tryoutstablelm</td>\n",
       "      <td>stabilityai/stablelm-2-1_6b</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-29 09:48:18.644406+02:00</td>\n",
       "      <td>0.791530</td>\n",
       "      <td>Expected input batch_size (2) to match target ...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/GEITjeSmallData200Tokens</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-29 11:28:02.756504+02:00</td>\n",
       "      <td>1.342644</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/GEITjeSmallData200Tokens</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-29 11:48:12.624523+02:00</td>\n",
       "      <td>4.499735</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/GEITjeSmallData200Tokens</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-29 11:53:35.436951+02:00</td>\n",
       "      <td>0.519014</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  model                   base_model  \\\n",
       "0    FemkeBakker/TryOutFinetuningGeitje        Rijgersberg/GEITje-7B   \n",
       "0    FemkeBakker/TryOutFinetuningGeitje        Rijgersberg/GEITje-7B   \n",
       "0    FemkeBakker/TryOutFinetuningGeitje        Rijgersberg/GEITje-7B   \n",
       "0    FemkeBakker/TryOutFinetuningGeitje        Rijgersberg/GEITje-7B   \n",
       "0    FemkeBakker/TryOutFinetuningGeitje        Rijgersberg/GEITje-7B   \n",
       "0    FemkeBakker/TryOutFinetuningGeitje        Rijgersberg/GEITje-7B   \n",
       "0             FemkeBakker/TryoutGeitje2        Rijgersberg/GEITje-7B   \n",
       "0             FemkeBakker/TryoutGeitje2        Rijgersberg/GEITje-7B   \n",
       "0             FemkeBakker/TryoutGeitje2        Rijgersberg/GEITje-7B   \n",
       "0            FemkeBakker/tryoutstablelm  stabilityai/stablelm-2-1_6b   \n",
       "0            FemkeBakker/tryoutstablelm  stabilityai/stablelm-2-1_6b   \n",
       "0  FemkeBakker/GEITjeSmallData200Tokens        Rijgersberg/GEITje-7B   \n",
       "0  FemkeBakker/GEITjeSmallData200Tokens        Rijgersberg/GEITje-7B   \n",
       "0  FemkeBakker/GEITjeSmallData200Tokens        Rijgersberg/GEITje-7B   \n",
       "\n",
       "                                 chat_dataset train_set test_set  \\\n",
       "0  FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0  FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0  FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0  FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0  FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0  FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0  FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0  FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0  FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0  FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0  FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0  FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0  FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0  FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "\n",
       "                                       training_args  resume_from_checkpoint  \\\n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "\n",
       "                              date   runtime  \\\n",
       "0 2024-04-25 13:21:46.201696+02:00  0.876791   \n",
       "0 2024-04-25 13:24:59.884223+02:00  0.274652   \n",
       "0 2024-04-25 13:25:57.527833+02:00  0.362344   \n",
       "0 2024-04-25 13:26:24.369492+02:00  0.319212   \n",
       "0 2024-04-26 08:47:21.945291+02:00  0.392476   \n",
       "0 2024-04-26 08:47:57.151755+02:00  0.600505   \n",
       "0 2024-04-26 08:56:52.283214+02:00  0.449522   \n",
       "0 2024-04-26 09:26:12.329799+02:00  3.251497   \n",
       "0 2024-04-26 09:29:06.636546+02:00  0.543515   \n",
       "0 2024-04-29 09:46:03.908296+02:00  0.364137   \n",
       "0 2024-04-29 09:48:18.644406+02:00  0.791530   \n",
       "0 2024-04-29 11:28:02.756504+02:00  1.342644   \n",
       "0 2024-04-29 11:48:12.624523+02:00  4.499735   \n",
       "0 2024-04-29 11:53:35.436951+02:00  0.519014   \n",
       "\n",
       "                                               Error  run_id save_to_hub  \\\n",
       "0                                  KeyboardInterrupt       0         NaN   \n",
       "0  Error(s) in loading state_dict for MistralForC...       0         NaN   \n",
       "0  No valid checkpoint found in output directory ...       0         NaN   \n",
       "0  CUDA out of memory. Tried to allocate 112.00 M...       0         NaN   \n",
       "0                                  KeyboardInterrupt       0         NaN   \n",
       "0                string longer than 2147483647 bytes       0         NaN   \n",
       "0                                              False       1         NaN   \n",
       "0  [Errno 2] No such file or directory: '/home/az...       1         NaN   \n",
       "0                                              False       1         NaN   \n",
       "0                                  KeyboardInterrupt       2         NaN   \n",
       "0  Expected input batch_size (2) to match target ...       2       False   \n",
       "0                                  KeyboardInterrupt       3        True   \n",
       "0                                  KeyboardInterrupt       4        True   \n",
       "0                                              False       4        True   \n",
       "\n",
       "                                          output_dir  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yeet = pd.read_pickle(f'{cf.output_path}/overview_models.pkl')\n",
    "display(yeet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AmsterdamInContextLearning",
   "language": "python",
   "name": "amsterdamincontextlearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
