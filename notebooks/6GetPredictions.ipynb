{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "!bash /home/azureuser/cloudfiles/code/blobfuse/blobfuse_raadsinformatie.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1712584227159
        }
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "# Select where to run notebook: \"azure\" or \"local\"\n",
        "my_run = \"azure\"\n",
        "\n",
        "# import my_secrets as sc\n",
        "# import settings as st\n",
        "\n",
        "if my_run == \"azure\":\n",
        "    import config_azure as cf\n",
        "elif my_run == \"local\":\n",
        "    import config as cf\n",
        "\n",
        "\n",
        "import os\n",
        "if my_run == \"azure\":\n",
        "    if not os.path.exists(cf.HUGGING_CACHE):\n",
        "        os.mkdir(cf.HUGGING_CACHE)\n",
        "    os.environ[\"TRANSFORMERS_CACHE\"] = cf.HUGGING_CACHE\n",
        "\n",
        "# set-up environment - GEITje-7b-chat InContextLearning:\n",
        "# - install blobfuse -> sudo apt-get install blobfuse\n",
        "# - pip install transformers\n",
        "# - pip install torch\n",
        "# - pip install accelerate\n",
        "# - pip install jupyter\n",
        "# - pip install ipywidgets\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notebook overview\n",
        "- Goal: Run experiment for InContext Learning GEITje\n",
        "- Trial run model -> prompt GEITje using, example prompt\n",
        "- Zeroshot prompts\n",
        "- Fewshot prompts\n",
        "\n",
        "Load data and functions:\n",
        "- data is already split\n",
        "- text is already converted to tokens using model tokenizer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# df = pd.read_pickle(f\"{cf.output_path}/txtfiles_tokenizer.pkl\")\n",
        "\n",
        "import sys\n",
        "sys.path.append('../scripts/') \n",
        "import prompt_template as pt\n",
        "import prediction_helperfunctions as ph\n",
        "import truncation as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2fb238bcd7c40b69c2f30eeebd343e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Trial run Models \n",
        "Code to run the models with a simple prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_geitje = pipeline(task='conversational', model='Rijgersberg/GEITje-7B-chat-v2',\n",
        "                   device_map='auto', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "\n",
        "chatbot_llama = pipeline(task='conversational', model='meta-llama/Llama-2-7b-chat-hf',\n",
        "                   device_map='auto', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "chatbot_mistral = pipeline(task='conversational', model='mistralai/Mistral-7B-Instruct-v0.2',\n",
        "                   device_map='auto', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "## EXAMPLE PROMPT\n",
        "# print(chatbot(\n",
        "    # Conversation('Welk woord hoort er niet in dit rijtje thuis: \"auto, vliegtuig, geitje, bus\"?')\n",
        "# ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Experiment functions\n",
        "Prompt GEITje for each document and save the prediction, return response, response time and the prompt version\n",
        "\n",
        "Code structure:\n",
        "- 2 functions/cells:\n",
        "- predictions_incontextlearning -> given a df with docs that need to be predicted, prompt the model\n",
        "- run the experiment -> built in failsaves (df run in parts, with saves in between)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "from bm25 import BM25\n",
        "\n",
        "\n",
        "\"\"\" Given a dataframe with txt, return a df with predictions \"\"\"\n",
        "# docs_df = dataframe with the documents that need to be predicted\n",
        "# text_column = name of the column that includes the input_text. Can be different based on the text representation method. \n",
        "# prompt_function = prompt template \n",
        "# train_df = dataframe with docs, which can be used as examples/training data/context data\n",
        "# num_examples = number of examples in the prompt\n",
        "\n",
        "def predictions_incontextlearning(chatbot, docs_df, text_column, prompt_function, train_df, num_examples):\n",
        "    results_df = pd.DataFrame(columns = ['id', 'path', 'text_column', 'prompt_function', 'response', 'prediction', 'label', 'runtime', 'date', 'prompt'])\n",
        "\n",
        "\n",
        "    if prompt_function == pt.fewshot_prompt_with_template or prompt_function == pt.fewshot_prompt_no_template:\n",
        "        BM25_model = BM25()\n",
        "        BM25_model.fit(train_df[text_column])\n",
        "   \n",
        "\n",
        "    # prompt each document\n",
        "    for index, row in docs_df.iterrows():\n",
        "        # if (index + 1) % 200 == 0:\n",
        "        #     print(f\"Iteration {index +1}/{len(docs_df)} completed.\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # get the prompt, with the doc filled in\n",
        "        txt = row[text_column]\n",
        "\n",
        "        # each prompt function takes different arguments\n",
        "        # zeroshot prompt for geitje\n",
        "        if prompt_function == pt.zeroshot_prompt_geitje:\n",
        "            prompt = prompt_function(txt)\n",
        "\n",
        "        # zeroshot function for mistral and llama\n",
        "        elif prompt_function == pt.zeroshot_prompt_mistral_llama:\n",
        "            prompt = prompt_function(txt)\n",
        "\n",
        "        # select fewshot examples using bm25, fewshot is the same for all models\n",
        "        # elif prompt_function == pt.fewshot_prompt_bm25:\n",
        "        #     prompt = prompt_function(txt, train_df, num_examples, text_column, BM25_model)\n",
        "        \n",
        "        elif prompt_function == pt.fewshot_prompt_no_template:\n",
        "            prompt = prompt_function(txt, train_df, num_examples, text_column, BM25_model)\n",
        "\n",
        "        elif prompt_function == pt.fewshot_prompt_with_template:\n",
        "            prompt = prompt_function(txt, train_df, num_examples, text_column, BM25_model)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Prompt function not recognised. Check if prompt function is in prompt_template.py and included in the options above.\")\n",
        "\n",
        "        # prompt and get the response\n",
        "        # print(prompt)\n",
        "        converse = chatbot(Conversation(prompt))\n",
        "        response = converse[1]['content']\n",
        "        print(\"label: \", row['label'].lower())\n",
        "        print(\"response: \", response)\n",
        "\n",
        "        # extract prediction from response\n",
        "        prediction = ph.get_prediction_from_response(response)\n",
        "        print(\"prediction:\", prediction)\n",
        "\n",
        "        # save results in dataframe\n",
        "        results_df.loc[len(results_df)] = {\n",
        "            'id': row['id'],\n",
        "            'path' : row['path'],\n",
        "            'text_column' : docs_df.iloc[0]['trunc_col'],\n",
        "            'prompt_function': ph.get_promptfunction_name(prompt_function),\n",
        "            'response':response,\n",
        "            'prediction':prediction,\n",
        "            'label':row['label'].lower(),\n",
        "            'runtime':time.time()-start_time,\n",
        "            'date': ph.get_datetime(),\n",
        "            'prompt':prompt\n",
        "        }\n",
        "    return results_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\"\"\"\n",
        "Function to run GEITje In-Context Learning experiment. \n",
        "The function allows to resume experiment, if run_id matches.\n",
        "\"\"\"\n",
        "# df = dataframe with all docs that need to have a prediction (docs still need to be predict + already predicted)\n",
        "# run_id = unqiue for each experiment. \n",
        "# prompt_function = which prompt from prompt_template.py to use\n",
        "# text_col = colum in df where the text is. (Needs to be already truncated)\n",
        "# split_col = column with the dataset split. Either '2split' (train and test)or '4split'(train, test, dev and val)\n",
        "# subset_train = indicates which subset to use as training. either 'train' or 'dev'\n",
        "# subset_test = indicates which subset to use for testing. either 'test' or 'val'\n",
        "# label_col = column with the true label\n",
        "# prediction_path = path to file where predictions need to be saved.\n",
        "# overview_path = path to file where results of each run need to be saved.\n",
        "# model_name = name of the model. string.\n",
        "# num_exmples = number of exaples given to prompt. zero in case of zeroshot. \n",
        "\n",
        "def run_experiment(chatbot, df, run_id, prompt_function, text_col, split_col, subset_train, subset_test, label_col, prediction_path, overview_path, model_name, num_examples=0):\n",
        "    test_df = df.loc[df[split_col]==subset_test]\n",
        "    train_df = df.loc[df[split_col]==subset_train]\n",
        "    \n",
        "    # get rows of df that still need to be predicted for the specific run_id\n",
        "    to_predict, previous_predictions = ph.get_rows_to_predict(test_df, prediction_path, run_id)\n",
        "\n",
        "    # devide to_predict into subsection of 50 predictions at a time. \n",
        "    # Allows to rerun without problem. And save subsections of 50 predictions.\n",
        "    step_range = list(range(0, len(to_predict), 10))\n",
        "\n",
        "    for i in range(len(step_range)):\n",
        "        try:\n",
        "            sub_to_predict = to_predict.iloc[step_range[i]:step_range[i+1]]\n",
        "            print(f'Starting...{step_range[i]}:{step_range[i+1]} out of {len(to_predict)}')\n",
        "        except Exception as e:\n",
        "            sub_to_predict = to_predict[step_range[i]:]\n",
        "            print(f'Starting...last {len(sub_to_predict)} docs')\n",
        "\n",
        "        # prompt geitje\n",
        "        predictions = predictions_incontextlearning(chatbot, sub_to_predict, text_col, prompt_function, train_df, num_examples)\n",
        "\n",
        "        # save info\n",
        "        predictions['run_id'] = run_id\n",
        "        predictions['train_set'] = subset_train\n",
        "        predictions['test_set'] = subset_test\n",
        "        predictions['shots'] = num_examples\n",
        "\n",
        "        # save new combinations in file\n",
        "        print(\"Dont interrupt, saving predictions...\")\n",
        "        ph.combine_and_save_df(predictions, prediction_path)\n",
        "\n",
        "        # if previous predictions, combine previous with new predictions, to get update classification report\n",
        "        try:\n",
        "            predictions = pd.concat([predictions, previous_predictions])\n",
        "\n",
        "            # set previous predictions to all predictions made until now. Necessary for next loop\n",
        "            previous_predictions = predictions\n",
        "        except Exception as e:\n",
        "            # set previous predictions to all predictions made until now. Necessary for next loop\n",
        "            previous_predictions = predictions\n",
        "\n",
        "        # save results in overview file\n",
        "        date = ph.get_datetime()\n",
        "        y_test = predictions['label']\n",
        "        y_pred = predictions['prediction']\n",
        "\n",
        "        # change error predictions to one error\n",
        "        # error_names = ['NoPredictionInOutput', 'MultiplePredictionErrorInFormatting','NoPredictionFormat', 'MultiplePredictionErrorInOutput']\n",
        "        # y_pred = ['OutputError' if x in error_names else x for x in y_pred]\n",
        "\n",
        "        report = classification_report(y_test, y_pred)\n",
        "\n",
        "        overview = pd.DataFrame(\n",
        "            [{\n",
        "                'model':model_name,\n",
        "                'run_id':run_id,\n",
        "                'date': date,\n",
        "                'train_set': subset_train,\n",
        "                'test_set': subset_test,\n",
        "                'train_set_support':len(df.loc[df[split_col]==subset_train]),\n",
        "                'test_set_support':len(predictions),\n",
        "                'split_col':split_col,\n",
        "                'text_col':df.iloc[0]['trunc_col'],\n",
        "                'runtime':sum(predictions['runtime']),\n",
        "                'accuracy': accuracy_score(y_test, y_pred),\n",
        "                'macro_avg_precision': precision_score(y_test, y_pred, average='macro'),\n",
        "                'macro_avg_recall': recall_score(y_test, y_pred, average='macro'),\n",
        "                'macro_avg_f1': f1_score(y_test, y_pred, average='macro'),\n",
        "                'weighted_avg_precision': precision_score(y_test, y_pred, average='weighted'),\n",
        "                'weighted_avg_recall': recall_score(y_test, y_pred, average='weighted'),\n",
        "                'weighted_avg_f1': f1_score(y_test, y_pred, average='weighted'),\n",
        "                'classification_report':report\n",
        "            }   ]\n",
        "        )\n",
        "        # remove previous results of run_id, replace with new/updated results\n",
        "        ph.replace_and_save_df(overview, overview_path, run_id)\n",
        "        print(\"Saving done! Interrupting is allowed.\")\n",
        "        print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set up variables that are the same for each model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set  variables, same for each model\n",
        "TRAIN_SET = 'train' # must be dev or train\n",
        "TEST_SET = 'test' # must be val or test\n",
        "SPLIT_COLUMN = 'balanced_split' #must be either 2split or 4split. 2split = data split into train and test. 4split = data split into train, test, dev and val. \n",
        "LABEL_COLUMN = 'label'\n",
        "TEXT_COLUMN = 'trunc_txt'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = pd.read_pickle(f\"{cf.output_path}/txtfiles_tokenizer.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GEITje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SHORT_MODEL_NAME = 'GEITje'\n",
        "PROMPT = pt.zeroshot_prompt_geitje\n",
        "PROMPT_NAME = ph.get_promptfunction_name(PROMPT)\n",
        "TOKENS_COL = 'LlamaTokens' # column with text split using tokenizer of either mistral (MistralTokens) or Llama (LlamaTokens). Using Llama, because Llama split into more tokens. \n",
        "FRONT_THRESHOLD = 200\n",
        "BACK_THRESHOLD = 0\n",
        "\n",
        "if PROMPT==pt.zeroshot_prompt_geitje:\n",
        "    NUMBER_EXAMPLES = 0\n",
        "elif PROMPT == pt.fewshot_prompt_no_template or PROMPT == pt.fewshot_prompt_with_template:\n",
        "    NUMBER_EXAMPLES = 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load model - In-context learning\n",
        "Note - ONLY load one model: either in-context or fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_geitje = pipeline(task='conversational', model='Rijgersberg/GEITje-7B-chat-v2',\n",
        "                    device_map='cpu', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "MODEL_NAME = 'GEITje-7B-chat-v2'\n",
        "SUBFOLDER = 'in_context'\n",
        "SHORT_ID = 'IC'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load model - Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_geitje = pipeline(task='conversational', model='FemkeBakker/AmsterdamDocClassificationGEITje200T1Epochs',\n",
        "                   device_map='cpu', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "MODEL_NAME = 'AmsterdamDocClassificationGEITje200T1Epochs'\n",
        "SUBFOLDER = 'finetuning'\n",
        "SHORT_ID = 'FT'\n",
        "EPOCHS = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set-up paths to save predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if SPLIT_COLUMN == '4split' or SPLIT_COLUMN == '2split':\n",
        "    OVERVIEW_PATH = f\"{cf.output_path}/predictionsVal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/overview.pkl\"\n",
        "    PREDICTION_PATH = f\"{cf.output_path}/predictionsVal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/predictions.pkl\"\n",
        "    \n",
        "elif SPLIT_COLUMN == 'balanced_split':\n",
        "    if SUBFOLDER == 'finetuning':\n",
        "        OVERVIEW_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{EPOCHS}epochs/overview.pkl\"\n",
        "        PREDICTION_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{EPOCHS}epochs/{SHORT_MODEL_NAME}First{FRONT_THRESHOLD}Last{BACK_THRESHOLD}Predictions.pkl\"\n",
        "\n",
        "    elif SUBFOLDER == 'in_context':\n",
        "        OVERVIEW_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{SHORT_MODEL_NAME}/overview.pkl\"\n",
        "        PREDICTION_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/First{FRONT_THRESHOLD}Last{BACK_THRESHOLD}Predictions.pkl\"\n",
        "\n",
        "print(OVERVIEW_PATH)\n",
        "print(PREDICTION_PATH)\n",
        "\n",
        "if not os.path.isdir(os.path.dirname(os.path.abspath(OVERVIEW_PATH))):\n",
        "    raise ValueError(\"Folder to OVERVIEW_PATH does not exist\") \n",
        "if not os.path.isdir(os.path.dirname(os.path.abspath(PREDICTION_PATH))):\n",
        "    raise ValueError(\"Folder to PREDICTION_PATH does not exist\") \n",
        "\n",
        "run_id = f'{SHORT_ID}_{MODEL_NAME}{PROMPT_NAME}{TOKENS_COL}{FRONT_THRESHOLD}_{BACK_THRESHOLD}{TRAIN_SET}{TEST_SET}_numEx{NUMBER_EXAMPLES}'\n",
        "print ('\\n', run_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----- EXPERIMENT --------\n",
        "# add new column with truncated text -> new dataframe with column + new column name\n",
        "trunc_df = tf.add_truncation_column(txt,'text', TOKENS_COL, FRONT_THRESHOLD, BACK_THRESHOLD)\n",
        "\n",
        "\n",
        "# if new run MAKE SURE RUN_ID IS UNIQUE, if want to resume run, pass in that run_id\n",
        "run_experiment(chatbot_geitje, trunc_df, run_id, PROMPT, TEXT_COLUMN, SPLIT_COLUMN, TRAIN_SET, TEST_SET, LABEL_COLUMN, PREDICTION_PATH, OVERVIEW_PATH, MODEL_NAME, NUMBER_EXAMPLES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = pd.read_pickle(OVERVIEW_PATH)\n",
        "display(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Llama\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "SHORT_MODEL_NAME = 'Llama'\n",
        "PROMPT = pt.fewshot_prompt_with_template\n",
        "PROMPT_NAME = ph.get_promptfunction_name(PROMPT)\n",
        "TOKENS_COL = 'LlamaTokens' # column with text split using tokenizer of either mistral (MistralTokens) or Llama (LlamaTokens). Using Llama, because Llama split into more tokens. \n",
        "FRONT_THRESHOLD = 200\n",
        "BACK_THRESHOLD = 0\n",
        "\n",
        "if PROMPT==pt.zeroshot_prompt_mistral_llama:\n",
        "    NUMBER_EXAMPLES = 0\n",
        "elif PROMPT == pt.fewshot_prompt_with_template or PROMPT == pt.fewshot_prompt_no_template:\n",
        "    NUMBER_EXAMPLES = 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load model - In-context learning\n",
        "Note - ONLY load one model: either in-context or fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05f583e6949f484cb7c6aafb7e144df0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1c22dd8cb544238acdb07cb8d897931",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_llama = pipeline(task='conversational', model='meta-llama/Llama-2-7b-chat-hf',\n",
        "                   device_map='cpu', model_kwargs={'offload_buffers':True})\n",
        "# load llama using cpu, else will give cuda out of memory error when running fewshot bm25 prompt.\n",
        "\n",
        "MODEL_NAME = 'Llama-2-7b-chat-hf'\n",
        "SUBFOLDER = 'in_context'\n",
        "SHORT_ID = 'IC'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load model - finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a00085de3f814d80b2fbca8a89e22ff8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/732 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e18009476e849028ee799e3424e1ff3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d73941c8b7dc42cbae391290149c92b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d03f302b6ce43e1abaff05c8e57bbdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dbf777e5cf24e099a7cfb05f0d8ae55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35619f1925fa47eeb6b085cf08aaff8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98e5c48227c84257be0352310a2e7128",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5b7a2549d5f46f0891036bf221d619a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/183 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "003520c8220f49f98e2eb60945b52834",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.76k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26bef3d5975342c480b2d60199ec07d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "567e30b077ce4606819843f3bfc2070a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f48f196b998f497285e18b41576fa424",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_llama = pipeline(task='conversational', model='FemkeBakker/AmsterdamDocClassificationLlama200T3Epochs',\n",
        "                   device_map='cpu', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "MODEL_NAME = 'AmsterdamDocClassificationLlama200T1Epochs'\n",
        "SUBFOLDER = 'finetuning'\n",
        "SHORT_ID = 'FT'\n",
        "EPOCHS = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set-up paths to save predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/in_context/Llama/overview.pkl\n",
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/in_context/Llama/fewshot_prompt_with_template/First200Last0Predictions.pkl\n",
            "\n",
            " IC_Llama-2-7b-chat-hffewshot_prompt_with_templateLlamaTokens200_0traintest_numEx2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if SPLIT_COLUMN == '4split' or SPLIT_COLUMN == '2split':\n",
        "    OVERVIEW_PATH = f\"{cf.output_path}/predictionsVal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/overview.pkl\"\n",
        "    PREDICTION_PATH = f\"{cf.output_path}/predictionsVal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/predictions.pkl\"\n",
        "    \n",
        "elif SPLIT_COLUMN == 'balanced_split':\n",
        "    if SUBFOLDER == 'finetuning':\n",
        "        OVERVIEW_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{EPOCHS}epochs/overview.pkl\"\n",
        "        PREDICTION_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{EPOCHS}epochs/{SHORT_MODEL_NAME}First{FRONT_THRESHOLD}Last{BACK_THRESHOLD}Predictions.pkl\"\n",
        "\n",
        "    elif SUBFOLDER == 'in_context':\n",
        "        OVERVIEW_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{SHORT_MODEL_NAME}/overview.pkl\"\n",
        "        PREDICTION_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/First{FRONT_THRESHOLD}Last{BACK_THRESHOLD}Predictions.pkl\"\n",
        "\n",
        "print(OVERVIEW_PATH)\n",
        "print(PREDICTION_PATH)\n",
        "\n",
        "if not os.path.isdir(os.path.dirname(os.path.abspath(OVERVIEW_PATH))):\n",
        "    raise ValueError(\"Folder to OVERVIEW_PATH does not exist\") \n",
        "if not os.path.isdir(os.path.dirname(os.path.abspath(PREDICTION_PATH))):\n",
        "    raise ValueError(\"Folder to PREDICTION_PATH does not exist\") \n",
        "\n",
        "run_id = f'{SHORT_ID}_{MODEL_NAME}{PROMPT_NAME}{TOKENS_COL}{FRONT_THRESHOLD}_{BACK_THRESHOLD}{TRAIN_SET}{TEST_SET}_numEx{NUMBER_EXAMPLES}'\n",
        "print ('\\n', run_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run-id already known, resuming predictions...\n",
            "Starting...0:10 out of 930\n",
            "label:  factsheet\n",
            "response:   Based on the provided examples and the document that needs to be categorized, I would classify it under the category of \"Onderzoeksrapport\".\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Onderzoeksrapport\"\n",
            "}\n",
            "\n",
            "Explanation:\n",
            "\n",
            "The document provides an overview of the development of the social assistance budget in Amsterdam, including the number of recipients and the amount of outlays. It also presents data on the number of applications and the proportion of unprocessed applications. The document is written in a formal and structured tone, indicating that it is a research report rather than a brief or a letter. Additionally, the document includes tables and figures, which are commonly used in research reports to present data and analysis.\n",
            "prediction: onderzoeksrapport\n",
            "label:  agenda\n",
            "response:   Sure, I can help you classify the document. Based on the provided examples and the content of the document you provided, I would categorize it as:\n",
            "\n",
            "{'categorie': 'Agenda'}\n",
            "\n",
            "The document contains the agenda for a meeting of the Raadscommissie voor Zorg, Milieu, Personeel en Organisatie, Openbare ruimte en Groen, including the time, location, and items to be discussed. This matches the format and content of the example documents you provided, which were both classified as Agendas. Therefore, I classify the document you provided as an Agenda as well.\n",
            "prediction: agenda\n",
            "label:  agenda\n",
            "response:   Sure, I can help you with that! Based on the provided examples and the document you want to categorize, I would classify it under the category of \"Agenda\".\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Agenda\"\n",
            "}\n",
            "\n",
            "The reason for this classification is that the document appears to be an agenda for a meeting of the Raadscommissie voor Algemene Zaken, Openbare Orde en Veiligheid, Juridische Zaken, Communicatie, Project 1012, Dienstverlening, Bestuurlijk Stelsel en Raadsaangelegenheden. The document lists the items to be discussed during the meeting, including the time and date of the meeting.\n",
            "\n",
            "I hope this helps! Let me know if you have any other questions.\n",
            "prediction: agenda\n",
            "label:  raadsnotulen\n",
            "response:   Sure, I can help you categorize the given document. Based on the information provided, I would classify the document as a 'Raadsnotulen'.\n",
            "\n",
            "Here is the output in the form of a JSON file:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Raadsnotulen\"\n",
            "}\n",
            "\n",
            "The reason for this classification is that the document appears to be a meeting minutes or agenda of a municipal council, which is a common type of document that is used to keep track of the decisions and discussions of a council meeting. The document includes information such as the date, time, and location of the meeting, as well as the names of the council members present and the topics discussed. This information is typically found in Raadsnotulen, which are official documents that record the proceedings of a municipal council meeting.\n",
            "prediction: raadsnotulen\n",
            "label:  raadsnotulen\n",
            "response:   Sure, I can help you categorize the given document. Based on the content and structure of the document, I would categorize it under the category of 'Raadsnotulen'.\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Raadsnotulen\"\n",
            "}\n",
            "\n",
            "The reason for this categorization is that the document contains information about a municipal council meeting, including the agenda, minutes, and reports. This is a typical structure for a Raadsnotulen, which is a document that records the proceedings of a municipal council meeting in the Netherlands.\n",
            "prediction: raadsnotulen\n",
            "label:  schriftelijke vraag\n",
            "response:   Sure, I can help you classify the given document. Based on the information provided, I would categorize the document as follows:\n",
            "\n",
            "{ 'categorie': 'Schriftelijke Vraag' }\n",
            "\n",
            "This is because the document appears to be a response to written questions submitted by members of the Gemeente Amsterdam council, as mentioned in the introduction. The document provides a detailed answer to the questions, including a toelichting (explanation) of the questions and the responses. Therefore, it falls under the category of 'Schriftelijke Vraag' (Written Question).\n",
            "prediction: schriftelijke vraag\n",
            "label:  schriftelijke vraag\n",
            "response:   Sure, I can help you categorize the given document. Based on the content and structure of the document, I would categorize it as a 'Schriftelijke Vraag'.\n",
            "\n",
            "Here is the output in the form of a JSON file:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Schriftelijke Vraag\"\n",
            "}\n",
            "\n",
            "The reason for this categorization is that the document appears to be a written question addressed to the Amsterdam city council, with a clear topic and format. The document includes the name of the council, the year, and the number of the question, as well as the date of indirection and agreement, and the publicatiedatum. The content of the document is a written question from a council member to the council, seeking answers to specific questions related to a particular topic. Therefore, it fits best into the category of 'Schriftelijke Vraag'.\n",
            "prediction: schriftelijke vraag\n",
            "label:  schriftelijke vraag\n",
            "response:   Based on the provided examples and the document that needs to be categorized, I would classify it under the category of \"Schriftelijke Vraag\" (Written Question).\n",
            "\n",
            "The document is a written question submitted to the Gemeente Amsterdam by a member of the council, containing several questions related to the handling of erfpacht (ground rent) on the municipal balance. The document includes information on the number of private erfpacht holders who have already availed themselves of the opportunity to purchase the perpetual and irrevocable ground rent, and requests information on the current status of the matter.\n",
            "\n",
            "Therefore, the category \"Schriftelijke Vraag\" is the most appropriate for this document.\n",
            "\n",
            "Output: {'categorie': 'Schriftelijke Vraag'}\n",
            "prediction: schriftelijke vraag\n",
            "label:  motie\n",
            "response:   Sure, I can help you with that! Based on the examples you provided, I would categorize the third document as a \"Motie\".\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Motie\"\n",
            "}\n",
            "\n",
            "The reason for this categorization is that the document is a proposal or motion put forward by a raadslid (council member) to the gemeenteraad (city council) for discussion and decision-making. The document contains a detailed explanation of the proposal, including the reasons for it and the potential impact it could have on the city's budget and policies.\n",
            "\n",
            "I hope this helps! Let me know if you have any other questions.\n",
            "prediction: motie\n",
            "label:  voordracht\n",
            "response:   Sure, I can help you classify the document! Based on the information provided, I would categorize VN2021-023012 as:\n",
            "\n",
            "{'categorie': 'Voordracht'}\n",
            "\n",
            "The document appears to be a speech or presentation given to the Gemeente Raadscommissie voor Algemene Zaken, Openbare Orde en Veiligheid (City Council Committee for General Affairs, Public Order and Safety) on September 2, 2021, regarding the topic of public safety and order. The document includes information on the speaker's agenda points, as well as notes and recommendations for the committee. Based on this information, it seems that the document is a preparatory document for a committee meeting and does not contain any formal decisions or actions. Therefore, it is classified as a 'Voordracht' (speech or presentation) rather than a 'Besluit' (decision) or 'Schriftelijke Vraag' (written question).\n",
            "prediction: voordracht\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.7833333333333333\n",
            "Starting...10:20 out of 930\n",
            "label:  raadsadres\n",
            "response:   Based on the provided examples and the category list, I would categorize the third document as:\n",
            "\n",
            "{'categorie': 'Raadsadres'}\n",
            "\n",
            "The document is a formal letter addressed to the Gemeente Amsterdam, requesting attention for a specific issue regarding the protection and support of the green edges in the Burgwallengebied. It contains the name, email address, and address of the sender, as well as a brief message. The document is written in a formal and professional tone, and it appears to be a standard raadsadres (council address) format.\n",
            "prediction: raadsadres\n",
            "label:  voordracht\n",
            "response:   Sure! Based on the provided documents and the category options you provided, I can categorize the document VN2023-023417 Raadscommissie voor Ruimtelijke Ordening en Grond en Ontwikkeling RO. Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Voordracht\"\n",
            "}\n",
            "\n",
            "Explanation:\n",
            "\n",
            "Based on the content of the document, it appears to be a speech or presentation given to the Raadscommissie voor Ruimtelijke Ordening en Grond en Ontwikkeling RO on December 6, 2023, regarding the results of additional soil investigation for dioxins around the Volgermeerpolder in Amsterdam Noord. The document contains information on the agenda point, date of the decision, and the topic of the presentation, which suggests that it is a voordracht (speech or presentation) rather than a besluit (decision) or a schriftelijke vraag (written question).\n",
            "prediction: voordracht\n",
            "label:  factsheet\n",
            "response:   Based on the provided examples and the text of the document you want to categorize, I would classify it under the category of \"Onderzoeksrapport\".\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Onderzoeksrapport\"\n",
            "}\n",
            "\n",
            "The reason for this classification is that the document appears to be a research report, with a clear structure and language that is typical of this category. The document includes sections on the purpose and scope of the research, the methodology used, the results obtained, and conclusions drawn. These elements are all typical of a research report, and suggest that the document is intended to present the findings of a systematic investigation or study.\n",
            "prediction: onderzoeksrapport\n",
            "label:  onderzoeksrapport\n",
            "response:   Sure, I can help you classify the document \"Panteia\". Based on the examples provided and the categories you've given, I would categorize the document as:\n",
            "\n",
            "{ \"categorie\": \"Onderzoeksrapport\" }\n",
            "\n",
            "Here's why:\n",
            "\n",
            "The document \"Panteia\" appears to be an research report, as it contains research findings and results related to a specific topic. The document includes data and analysis, and it is written in a formal and structured manner, which is typical of research reports. The use of abbreviations and acronyms, such as \"EIM\", \"NEA\", and \"IPM\", suggests that the document is related to policy research or analysis.\n",
            "\n",
            "Therefore, based on the examples provided and the categories you've given, I would categorize the document \"Panteia\" as an research report.\n",
            "prediction: onderzoeksrapport\n",
            "label:  agenda\n",
            "response:   Sure, I can help you classify the document! Based on the examples provided, I would categorize the document as:\n",
            "\n",
            "{'categorie': 'Agenda'}\n",
            "\n",
            "The document appears to be an agenda for a meeting of the Raadscommissie voor Kunst en Cultuur Monumenten en Erfgoed, Diversiteit en Antidiscriminatiebeleid, Democratisering, Gemeentelijk Vastgoed, ICT en Digitale Stad, Dienstverlening, Personeel en Organisatie, CoÃ¶rdinatie bedrijfsvoering, Inkoop. The agenda includes items such as \"Raadscommissievergadering\" and \"CoÃ¶rdinatie bedrijfsvoering\", which suggest that the document is related to the organization and coordination of a meeting or series of meetings.\n",
            "prediction: agenda\n",
            "label:  besluit\n",
            "response:   Sure, I can help you classify the document! Based on the provided examples and the list of categories, I would categorize the given document as:\n",
            "\n",
            "{'categorie': 'Besluit'}\n",
            "\n",
            "The document appears to be a municipal decision or resolution, as it contains a formal decision or resolution made by the General Meeting of the General Assembly of Amsterdam. The document includes the date, location, and topic of the meeting, as well as the outcome of the decision-making process. The language used is formal and bureaucratic, indicating that it is an official document. Therefore, I would classify it as a 'Besluit' or 'Decision'.\n",
            "prediction: besluit\n",
            "label:  besluit\n",
            "response:   Sure, I can help you classify the document! Based on the information provided, the document can be categorized as a 'Besluit' (Dutch for 'Decision').\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Besluit\"\n",
            "}\n",
            "\n",
            "The reason for this classification is that the document appears to be a formal decision made by the General Meeting of the Amsterdam East District, with a specific subject matter (plan of action for updating zoning plans) and a clear introduction and conclusion. The document also includes a registration number and date, which are typical features of formal Dutch documents.\n",
            "prediction: besluit\n",
            "label:  schriftelijke vraag\n",
            "response:   Sure, I can help you classify the given document. Based on the information provided, I would categorize the document as:\n",
            "\n",
            "{'categorie': 'Schriftelijke Vraag'}\n",
            "\n",
            "The document appears to be a response to a written question posed by a council member, containing the answer to the question and relevant information. The document is written in a formal and structured tone, and includes information such as the date of the council meeting, the number of the question, and the name of the council member who posed the question. The document also includes an introduction by the council member who wrote the answer.\n",
            "\n",
            "Therefore, the category that best fits this document is 'Schriftelijke Vraag'.\n",
            "prediction: schriftelijke vraag\n",
            "label:  motie\n",
            "response:   Sure, I can help you with that! Based on the two examples provided, I would categorize the third document as follows:\n",
            "\n",
            "{'categorie': 'Motie'}\n",
            "\n",
            "Here's why:\n",
            "\n",
            "The document is an agenda item for a municipal council meeting, and it contains a motion proposed by a council member. The motion is related to the Amsterdamse Aanpak Volkshuisvesting and the sale and liberalization of social housing. The document includes a summary of the motion, the status of the motion, and the council member's signature.\n",
            "\n",
            "From the content of the document, it is clear that the motion is aimed at addressing a specific issue related to social housing in Amsterdam, and it is intended to be discussed and voted on by the council. Therefore, the appropriate category for this document is \"Motie\".\n",
            "prediction: motie\n",
            "label:  actualiteit\n",
            "response:   Sure, I can help you categorize the document! Based on the information provided, I would categorize the document as:\n",
            "\n",
            "{'categorie': 'Actualiteit'}\n",
            "\n",
            "The document appears to be a municipal council agenda for a meeting on October 10 and 11, 2018, and it contains information about an actuality item raised by a councilor regarding the expansion plans of RAI Amsterdam and the noise pollution experienced by residents due to large events. Therefore, it falls under the category of 'Actualiteit' (Dutch for 'Actuality'), which refers to matters of current interest or importance.\n",
            "prediction: actualiteit\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.7894736842105263\n",
            "Starting...20:30 out of 930\n",
            "label:  factsheet\n",
            "response:   Sure! Based on the provided examples and the information provided in the document, I would categorize the document as:\n",
            "\n",
            "{'categorie': 'Factsheet'}\n",
            "\n",
            "The document provides a summary of the Regiobeeld Amsterdam Vitaal & Gezond, including its content and focus areas, and provides information on the preventive health care in the city of Amsterdam. It is a factual document that provides a brief overview of the topic, making it a good fit for the 'Factsheet' category.\n",
            "prediction: factsheet\n",
            "label:  brief\n",
            "response:   Sure, I can help you with that! Based on the provided examples and the information provided in the question, I would categorize the third document as follows:\n",
            "\n",
            "{ 'categorie': 'Brief' }\n",
            "\n",
            "The document appears to be a brief informing the members of the city council of Amsterdam about an errata note regarding the answer to the city center development project Osdorpplein phase 2a. The document is addressed to the members of the city council, and it is written in a formal and professional tone. The content of the document is related to the city's development and planning, which suggests that it belongs to the category of 'Brief'.\n",
            "prediction: brief\n",
            "label:  actualiteit\n",
            "response:   Sure, I can help you with that! Based on the provided examples and the information given in the document, I would categorize the document as a 'Brief'.\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Brief\"\n",
            "}\n",
            "\n",
            "The reason for this categorization is that the document appears to be a formal communication or message from a government official or department to other officials or stakeholders, containing information or updates on a specific topic or issue. The format and content of the document, including the use of formal language and the inclusion of specific details and requests, are also consistent with a brief.\n",
            "prediction: brief\n",
            "label:  factsheet\n",
            "response:   Sure, I can help you with that! Based on the two examples provided, I would categorize the third document as a Factsheet. Here's the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Factsheet\"\n",
            "}\n",
            "\n",
            "The reason for this categorization is that the document provides information on a specific topic (ouderenhuisvesting in Amsterdam in 2019) in a concise and structured format, with a clear objective of providing data and statistics on the subject matter. The document includes tables, charts, and other visual aids to help present the information in an easy-to-understand format, which is typical of a Factsheet.\n",
            "prediction: factsheet\n",
            "label:  onderzoeksrapport\n",
            "response:   Sure, I can help you classify the given document. Please provide the document text, and I will output the category of the document in the format of a JSON file.\n",
            "\n",
            "---\n",
            "\n",
            "Please provide the text of the document you want to classify:\n",
            "\n",
            "---\n",
            "\n",
            "I have read the text of the document you provided, and based on the content, I would categorize it as an \"Onderzoeksrapport\". Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Onderzoeksrapport\"\n",
            "}\n",
            "\n",
            "---\n",
            "\n",
            "Please let me know if you have any other document you want to classify.\n",
            "prediction: onderzoeksrapport\n",
            "label:  actualiteit\n",
            "response:   Sure, I can help you classify the document. Based on the content and structure of the document you provided, I would categorize it as a \"Voordracht\" (Dutch for \"Vote\") document.\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Voordracht\"\n",
            "}\n",
            "\n",
            "The reason for this classification is that the document contains a formal proposal or vote for the Amsterdam city council to establish a new regulation on waste management and cleaning services for 2022. The document includes a detailed explanation of the proposal, the reasons for it, and the possible consequences of not adopting it. It also includes a list of agenda points and a date for the vote. All of these elements indicate that the document is a formal vote or proposal for the city council, which is why I have categorized it as a \"Voordracht\" document.\n",
            "prediction: voordracht\n",
            "label:  onderzoeksrapport\n",
            "response:   Sure, I can help you categorize the document! Based on the examples provided and the content of the document you provided, I would categorize it under the category of \"Onderzoeksrapport\".\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Onderzoeksrapport\"\n",
            "}\n",
            "\n",
            "The reason for this categorization is that the document appears to be a quarterly report on the progress of a research project, with a clear structure and content that is typical of an academic research report. The document includes sections on the program's approach, the results of the research, and the conclusions drawn from the findings. The language used is formal and technical, which is typical of academic writing.\n",
            "\n",
            "I hope this helps! Let me know if you have any other questions.\n",
            "prediction: onderzoeksrapport\n",
            "label:  raadsadres\n",
            "response:   Sure, I can help you with that! Based on the examples provided, I would categorize the third document as follows:\n",
            "\n",
            "{'categorie': 'Raadsadres'}\n",
            "\n",
            "The document appears to be a letter addressed to the Gemeenteraad (City Council) of Amsterdam, expressing a concern or objection to a recent decision made by the municipality. The letter contains specific details and arguments related to the issue, and is written in a formal and professional tone. Therefore, I would classify it as a 'Raadsadres' (Council Address) document.\n",
            "prediction: raadsadres\n",
            "label:  actualiteit\n",
            "response:   Sure, I can help you classify the document! Based on the examples provided and the information given about the document to be classified, I would categorize it as:\n",
            "\n",
            "{'categorie': 'Actualiteit'}\n",
            "\n",
            "The document appears to be a report or agenda item from a Gemeente Amsterdam council meeting, discussing actual issues and threats faced by the community, particularly against a Kamerlid (Member of Parliament) during an anti-racism demonstration. The document mentions the names of several council members and their opinions on the matter, indicating that it is a contemporary and relevant issue for the community. Therefore, I would categorize it as Actualiteit (Actuality).\n",
            "prediction: actualiteit\n",
            "label:  voordracht\n",
            "response:   Sure! Based on the provided examples and the document that needs to be categorized, I would categorize VN2022-006542 idelij issi as a 'Voordracht'.\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Voordracht\"\n",
            "}\n",
            "\n",
            "The document is a presentation for the Tijdelijke Algemene Raadscommissie of April 7, 2022, and it contains information on the agenda, including an item related to the return of the Thrive Amsterdam Mental Health program. Since the document is primarily focused on presenting information and providing context for a discussion or decision, it falls under the category of 'Voordracht'.\n",
            "prediction: voordracht\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.79\n",
            "Starting...30:40 out of 930\n",
            "label:  raadsadres\n",
            "response:   Sure, I can help you categorize the document! Based on the provided examples and the list of categories, I would categorize the given document as:\n",
            "\n",
            "{'categorie': 'Raadsadres'}\n",
            "\n",
            "The document appears to be a letter addressed to the municipal council, requesting them to take action regarding the problem of Zwarte Piet. It mentions that there is a growing understanding among Amsterdammers that it is not appropriate to present Zwarte Piet as he has been depicted for generations, and that there is a need to address this issue. The document also mentions that 6% of the population wants to abolish Zwarte Piet completely, while 8% wants to keep him but in a different form.\n",
            "\n",
            "Therefore, based on the content and tone of the document, it seems to fit best into the category of a 'Raadsadres' (Council Address).\n",
            "prediction: raadsadres\n",
            "label:  motie\n",
            "response:   Sure, I can help you categorize the document. Based on the content provided, I would categorize the document as a \"Motie\" (Dutch for \"Motion\").\n",
            "\n",
            "Here is the output in the form of a JSON file:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Motie\"\n",
            "}\n",
            "\n",
            "The reason for this categorization is that the document appears to be a proposal or a request to the city council (Gemeente Amsterdam) to take a particular action or to consider a specific issue. The document includes a formal introduction, a statement of the problem, and a recommendation or proposal for action. The language used is formal and official, which is typical of moties.\n",
            "prediction: motie\n",
            "label:  agenda\n",
            "response:   Sure, I can help you classify the document! Based on the examples provided and the information given, I would categorize the document as:\n",
            "\n",
            "{'categorie': 'Agenda'}\n",
            "\n",
            "Here's the output in JSON format:\n",
            "\n",
            "{ \"categorie\": \"Agenda\" }\n",
            "\n",
            "The document contains the agenda for a meeting of the Stadsdeelcommissie, including the location, time, and participants. The agenda includes items such as opening, agenda setting, announcements, and a round of questions. Based on this information, the document can be classified as an agenda for a meeting.\n",
            "prediction: MultiplePredictionErrorInFormatting\n",
            "label:  besluit\n",
            "response:   Sure, I can help you with that! Based on the information provided, I would categorize the given document as:\n",
            "\n",
            "{ 'categorie': 'Besluit' }\n",
            "\n",
            "The reason for this categorization is that the document appears to be a formal decision made by the General Meeting of the Amsterdam city council, as it bears the official stamp and registration number of the city council. The document outlines a decision regarding the designation of a specific area for development, which is a typical function of a municipal council. Therefore, it falls under the category of 'Besluit' (Dutch for 'Decision').\n",
            "prediction: besluit\n",
            "label:  raadsnotulen\n",
            "response:   Sure, I can help you categorize the given document. Based on the provided information, I would categorize the document as:\n",
            "\n",
            "{'categorie': 'Raadsnotulen'}\n",
            "\n",
            "Here's why:\n",
            "\n",
            "The document is a meeting minutes of a municipal council in Amsterdam, Netherlands. It contains information about the agenda, decisions made, and actions taken during a meeting of the council. The document is written in Dutch and includes the names of the council members, the mayor, and the secretary.\n",
            "\n",
            "The document contains several sections, including an opening statement by the chairperson, a report on the agenda items, and a summary of the decisions made during the meeting. The document also includes information about the council's internal procedures and rules of order.\n",
            "\n",
            "Based on these features, I would classify the document as a municipal council meeting minutes, which is a type of official document that is commonly used in local governance. Therefore, the category for this document is 'Raadsnotulen'.\n",
            "prediction: raadsnotulen\n",
            "label:  actualiteit\n",
            "response:   Sure, I can help you classify the document! Based on the information provided, I would categorize the document as:\n",
            "\n",
            "{'categorie': 'Agenda'}\n",
            "\n",
            "The document appears to be an agenda for a meeting of the Raadscommissie voor Onderwijs, Jeugd, Diversiteit en Integratie, Kunst en Cultuur, Lokale Media en Monumenten in Amsterdam, to be held on January 17, 2017. The agenda includes several items, such as an opening, mededelingen (announcements), vaststelling agenda (establishing the agenda), and a conceptverslag (concept report) of the previous meeting of the committee. Therefore, the document can be classified as an agenda for a meeting of a municipal committee.\n",
            "prediction: agenda\n",
            "label:  factsheet\n",
            "response:   Sure, I can help you classify the document! Based on the provided examples and the list of categories, I would categorize the document as:\n",
            "\n",
            "{'categorie': 'Onderzoeksrapport'}\n",
            "\n",
            "The document appears to be an research report, as it presents findings and results from a study on the effectiveness of a particular approach to improving the employability of young people with a migration background and/or low socio-economic status. The document includes a description of the methodology used, the results of the study, and conclusions and recommendations for future research. This aligns with the definition of an onderzoeksrapport in the provided list of categories.\n",
            "prediction: onderzoeksrapport\n",
            "label:  factsheet\n",
            "response:   Sure, I can help you classify the document! Based on the provided examples and the list of categories, I would categorize the document as follows:\n",
            "\n",
            " {'categorie': 'Onderzoeksrapport'}\n",
            "\n",
            "The document appears to be an analysis of the development of youth unemployment in Amsterdam from 2014 to 2017. It includes data and statistics on the number of young people who are workless, the percentage of them who are not in education, and the percentage who are still searching for a job. The document also compares Amsterdam's youth unemployment rate to that of other cities in the Netherlands.\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Onderzoeksrapport\"\n",
            "}\n",
            "prediction: MultiplePredictionErrorInFormatting\n",
            "label:  factsheet\n",
            "response:   Sure, I can help you categorize the document. Based on the content and structure of the document, I would categorize it under the category of \"Factsheet\".\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Factsheet\"\n",
            "}\n",
            "\n",
            "The reason for this categorization is that the document provides information on a specific topic (preventive healthcare in Amsterdam) in a concise and structured format, with a clear and consistent structure. It includes tables, figures, and other visual elements to present data and information in a clear and easy-to-understand manner, which is typical of a factsheet.\n",
            "\n",
            "The document also includes a brief introduction and conclusion, but the main focus is on presenting data and information in a concise and structured format, which is another characteristic of a factsheet.\n",
            "\n",
            "I hope this helps! Let me know if you have any other questions.\n",
            "prediction: factsheet\n",
            "label:  agenda\n",
            "response:   Sure, I can help you classify the document! Based on the information provided, the document can be categorized as an Agenda.\n",
            "\n",
            "Here is the output in the form of a JSON file:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Agenda\"\n",
            "}\n",
            "\n",
            "The document is an agenda for a meeting of the Raadscommissie voor Zorg, Jeugd, Mbo-agenda Beroepsonderwijs en Toeleiding in Amsterdam, which includes the date, time, location, and items to be discussed. This is a common type of document used in government and administrative settings to organize meetings and decide on matters of importance.\n",
            "prediction: agenda\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.780952380952381\n",
            "Starting...40:50 out of 930\n",
            "label:  schriftelijke vraag\n",
            "response:   Sure! Based on the provided examples and the document that needs to be categorized, I can classify it as follows:\n",
            "\n",
            "Document: x Gemeente Amsterdam R\n",
            "Gemeenteraad\n",
            "% Gemeenteblad\n",
            "% Schriftelijke vragen\n",
            "Jaar 2019\n",
            "Afdeling 1\n",
            "Nummer 427\n",
            "Datum indiening 7 maart 2019\n",
            "Datum akkoord 17 april 2019\n",
            "Publicatiedatum 18 april 2019\n",
            "Onderwerp\n",
            "Beantwoording schriftelijke vragen van het lid El Ksaihi inzake de oproep van ziekenhuizen voor een rookvrije omgeving rondom ziekenhuizen.\n",
            "Aan de gemeenteraad\n",
            "Toelichting door vragenstelster: De Amsterdamse nieuwszender AT5 berichtte op 7 maart 2019 dat ziekenhuizen wethouder Kukenheim oproepen.\n",
            "\n",
            "Output: {'categorie': 'Schriftelijke Vraag'}\n",
            "prediction: schriftelijke vraag\n"
          ]
        }
      ],
      "source": [
        "# add new column with truncated text -> new dataframe with column + new column name\n",
        "trunc_df = tf.add_truncation_column(txt,'text', TOKENS_COL, FRONT_THRESHOLD, BACK_THRESHOLD)\n",
        "\n",
        "# if new run MAKE SURE RUN_ID IS UNIQUE, if want to resume run, pass in that run_id\n",
        "run_experiment(chatbot_llama, trunc_df, run_id, PROMPT, TEXT_COLUMN, SPLIT_COLUMN, TRAIN_SET, TEST_SET, LABEL_COLUMN, PREDICTION_PATH, OVERVIEW_PATH, MODEL_NAME, NUMBER_EXAMPLES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>run_id</th>\n",
              "      <th>date</th>\n",
              "      <th>train_set</th>\n",
              "      <th>test_set</th>\n",
              "      <th>train_set_support</th>\n",
              "      <th>test_set_support</th>\n",
              "      <th>split_col</th>\n",
              "      <th>text_col</th>\n",
              "      <th>runtime</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro_avg_precision</th>\n",
              "      <th>macro_avg_recall</th>\n",
              "      <th>macro_avg_f1</th>\n",
              "      <th>classification_report</th>\n",
              "      <th>weighted_avg_precision</th>\n",
              "      <th>weighted_avg_recall</th>\n",
              "      <th>weighted_avg_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>IC_Llama-2-7b-chat-hfzeroshot_prompt_mistral_l...</td>\n",
              "      <td>2024-05-22 21:29:48.627017+02:00</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront100Back0</td>\n",
              "      <td>140223.734147</td>\n",
              "      <td>0.422727</td>\n",
              "      <td>0.491578</td>\n",
              "      <td>0.310000</td>\n",
              "      <td>0.287423</td>\n",
              "      <td>precision...</td>\n",
              "      <td>0.670333</td>\n",
              "      <td>0.422727</td>\n",
              "      <td>0.391940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>IC_Llama-2-7b-chat-hfzeroshot_prompt_mistral_l...</td>\n",
              "      <td>2024-05-27 17:53:30.065278+02:00</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront100Back100</td>\n",
              "      <td>164152.727557</td>\n",
              "      <td>0.425455</td>\n",
              "      <td>0.543238</td>\n",
              "      <td>0.334286</td>\n",
              "      <td>0.321521</td>\n",
              "      <td>precision    ...</td>\n",
              "      <td>0.691394</td>\n",
              "      <td>0.425455</td>\n",
              "      <td>0.409208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>IC_Llama-2-7b-chat-hfzeroshot_prompt_mistral_l...</td>\n",
              "      <td>2024-05-26 21:20:27.966620+02:00</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront200Back0</td>\n",
              "      <td>132040.014386</td>\n",
              "      <td>0.474545</td>\n",
              "      <td>0.537874</td>\n",
              "      <td>0.372857</td>\n",
              "      <td>0.349950</td>\n",
              "      <td>precision    ...</td>\n",
              "      <td>0.684567</td>\n",
              "      <td>0.474545</td>\n",
              "      <td>0.445390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>IC_Llama-2-7b-chat-hffewshot_prompt_with_templ...</td>\n",
              "      <td>2024-06-04 06:20:53.503020+02:00</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>170</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront200Back0</td>\n",
              "      <td>38531.901579</td>\n",
              "      <td>0.776471</td>\n",
              "      <td>0.706896</td>\n",
              "      <td>0.634042</td>\n",
              "      <td>0.650321</td>\n",
              "      <td>precision...</td>\n",
              "      <td>0.909212</td>\n",
              "      <td>0.776471</td>\n",
              "      <td>0.809418</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                model                                             run_id  \\\n",
              "0  Llama-2-7b-chat-hf  IC_Llama-2-7b-chat-hfzeroshot_prompt_mistral_l...   \n",
              "0  Llama-2-7b-chat-hf  IC_Llama-2-7b-chat-hfzeroshot_prompt_mistral_l...   \n",
              "0  Llama-2-7b-chat-hf  IC_Llama-2-7b-chat-hfzeroshot_prompt_mistral_l...   \n",
              "0  Llama-2-7b-chat-hf  IC_Llama-2-7b-chat-hffewshot_prompt_with_templ...   \n",
              "\n",
              "                              date train_set test_set  train_set_support  \\\n",
              "0 2024-05-22 21:29:48.627017+02:00     train     test               9900   \n",
              "0 2024-05-27 17:53:30.065278+02:00     train     test               9900   \n",
              "0 2024-05-26 21:20:27.966620+02:00     train     test               9900   \n",
              "0 2024-06-04 06:20:53.503020+02:00     train     test               9900   \n",
              "\n",
              "   test_set_support       split_col                              text_col  \\\n",
              "0              1100  balanced_split    TruncationLlamaTokensFront100Back0   \n",
              "0              1100  balanced_split  TruncationLlamaTokensFront100Back100   \n",
              "0              1100  balanced_split    TruncationLlamaTokensFront200Back0   \n",
              "0               170  balanced_split    TruncationLlamaTokensFront200Back0   \n",
              "\n",
              "         runtime  accuracy  macro_avg_precision  macro_avg_recall  \\\n",
              "0  140223.734147  0.422727             0.491578          0.310000   \n",
              "0  164152.727557  0.425455             0.543238          0.334286   \n",
              "0  132040.014386  0.474545             0.537874          0.372857   \n",
              "0   38531.901579  0.776471             0.706896          0.634042   \n",
              "\n",
              "   macro_avg_f1                              classification_report  \\\n",
              "0      0.287423                                       precision...   \n",
              "0      0.321521                                   precision    ...   \n",
              "0      0.349950                                   precision    ...   \n",
              "0      0.650321                                       precision...   \n",
              "\n",
              "   weighted_avg_precision  weighted_avg_recall  weighted_avg_f1  \n",
              "0                0.670333             0.422727         0.391940  \n",
              "0                0.691394             0.425455         0.409208  \n",
              "0                0.684567             0.474545         0.445390  \n",
              "0                0.909212             0.776471         0.809418  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pred = pd.read_pickle(OVERVIEW_PATH)\n",
        "display(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mistral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "SHORT_MODEL_NAME = 'Mistral'\n",
        "PROMPT = pt.zeroshot_prompt_mistral_llama\n",
        "PROMPT_NAME = ph.get_promptfunction_name(PROMPT)\n",
        "TOKENS_COL = 'LlamaTokens' # column with text split using tokenizer of either mistral (MistralTokens) or Llama (LlamaTokens). Using Llama, because Llama split into more tokens. \n",
        "FRONT_THRESHOLD = 200\n",
        "BACK_THRESHOLD = 0\n",
        "\n",
        "if PROMPT==pt.zeroshot_prompt_mistral_llama:\n",
        "    NUMBER_EXAMPLES = 0\n",
        "elif PROMPT == pt.fewshot_prompt_with_template or PROMPT == pt.fewshot_prompt_no_template:\n",
        "    NUMBER_EXAMPLES = 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load model - In-context learning\n",
        "Note - ONLY load one model: either in-context or fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9465a5b0d7f4a1e90f5e89654510b09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "587c114eb2694995bb87bd66694d54bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_mistral = pipeline(task='conversational', model='mistralai/Mistral-7B-Instruct-v0.2',\n",
        "                   device_map='cpu', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "MODEL_NAME = 'Mistral-7B-Instruct-v0.2'\n",
        "SUBFOLDER = 'in_context'\n",
        "SHORT_ID = 'IC'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load model - finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d98c1a79c6045a18885491e9e175d0d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40aaa26f40ed4d498a4ce92a5a1405a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_mistral = pipeline(task='conversational', model='FemkeBakker/AmsterdamDocClassificationMistral200T2Epochs',\n",
        "                   device_map='cpu', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "MODEL_NAME = 'AmsterdamDocClassificationMistral200T2Epochs'\n",
        "SUBFOLDER = 'finetuning'\n",
        "SHORT_ID = 'FT'\n",
        "EPOCHS = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set-up paths to save predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/finetuning/2epochs/overview.pkl\n",
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/finetuning/2epochs/MistralFirst200Last0Predictions.pkl\n",
            "\n",
            " FT_AmsterdamDocClassificationMistral200T2Epochszeroshot_prompt_mistral_llamaLlamaTokens200_0traintest_numEx0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if SPLIT_COLUMN == '4split' or SPLIT_COLUMN == '2split':\n",
        "    OVERVIEW_PATH = f\"{cf.output_path}/predictionsVal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/overview.pkl\"\n",
        "    PREDICTION_PATH = f\"{cf.output_path}/predictionsVal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/predictions.pkl\"\n",
        "    \n",
        "elif SPLIT_COLUMN == 'balanced_split':\n",
        "    if SUBFOLDER == 'finetuning':\n",
        "        OVERVIEW_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{EPOCHS}epochs/overview.pkl\"\n",
        "        PREDICTION_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{EPOCHS}epochs/{SHORT_MODEL_NAME}First{FRONT_THRESHOLD}Last{BACK_THRESHOLD}Predictions.pkl\"\n",
        "\n",
        "    elif SUBFOLDER == 'in_context':\n",
        "        OVERVIEW_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{SHORT_MODEL_NAME}/overview.pkl\"\n",
        "        PREDICTION_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/First{FRONT_THRESHOLD}Last{BACK_THRESHOLD}Predictions.pkl\"\n",
        "\n",
        "print(OVERVIEW_PATH)\n",
        "print(PREDICTION_PATH)\n",
        "\n",
        "if not os.path.isdir(os.path.dirname(os.path.abspath(OVERVIEW_PATH))):\n",
        "    raise ValueError(\"Folder to OVERVIEW_PATH does not exist\") \n",
        "if not os.path.isdir(os.path.dirname(os.path.abspath(PREDICTION_PATH))):\n",
        "    raise ValueError(\"Folder to PREDICTION_PATH does not exist\") \n",
        "\n",
        "run_id = f'{SHORT_ID}_{MODEL_NAME}{PROMPT_NAME}{TOKENS_COL}{FRONT_THRESHOLD}_{BACK_THRESHOLD}{TRAIN_SET}{TEST_SET}_numEx{NUMBER_EXAMPLES}'\n",
        "print ('\\n', run_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run-id already known, resuming predictions...\n",
            "Starting...0:10 out of 160\n",
            "label:  factsheet\n",
            "response:  \"factsheet\": Factsheet}\n",
            "prediction: NoPredictionFormat\n",
            "label:  agenda\n",
            "response:  \"agenda\": Actualiteit, Raadsadres, Schriftelijke Vraag, Besluit, Voordracht, Motie, Factsheet, Onderzoeksrapport, Raadsnotulen, Agenda\n",
            "\"actualiteit\": 1\n",
            "\"raadsadres\": 2\n",
            "\"schriftelijke vragen\": 3\n",
            "\"besluit\": 4\n",
            "\"voordracht\": 5\n",
            "\"motie\": 6\n",
            "\"factsheet\": 7\n",
            "\"onderzoeksrapport\": 8\n",
            "\"raadsnotulen\": 9\n",
            "\"agenda\": 10\n",
            "}\n",
            "}\n",
            "\"agenda\": {\n",
            "\"type\": Agenda,\n",
            "\"punten\": [\n",
            "{\n",
            "\"nummer\": 1,\n",
            "\"onderwerp\": Opening en mededelingen\n",
            "},\n",
            "{\n",
            "\"nummer\": 1a,\n",
            "\"onderwerp\": Vaststelling van de agenda\n",
            "},\n",
            "{\n",
            "\"nummer\": 2,\n",
            "\"onderwerp\": Actualiteit inzake het verzoek van het Dagelijks Bestuur aan de\n",
            "Stadsdeelraad om het\n",
            "prediction: MultiplePredictionErrorInFormatting\n",
            "label:  actualiteit\n",
            "response:  'categorie': Actualiteit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  voordracht\n",
            "response:  \"categorie\": Voordracht}\n",
            "prediction: NoPredictionFormat\n",
            "label:  besluit\n",
            "response:  'categorie': Besluit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  brief\n",
            "response:  \"categorie\": Brief}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsnotulen\n",
            "response:  \"raadsnotulen\": {\n",
            "\"vergaderdatum\": \"16 december 2020\",\n",
            "\"publicatiedatum\": \"13 januari 2021\",\n",
            "\"openingstijd\": \"13:00 uur\",\n",
            "\"mededelingen\": \"De voorzitter heropent de vergadering om 13:00 uur.\n",
            "De voorzitter: Dan gaan we beginnen met de mededelingen.\n",
            "De voorzitter: Ik heb de eer voor te stellen, de leden van de gemeenteraad te\n",
            "benoemen als mededelaars van de raad.\n",
            "De voorzitter: Ik heropen de vergadering om 13:05 uur.\n",
            "De voorzitter: Ik stel de leden van de gemeenteraad voor, om te gaan met de\n",
            "mededelingen.\n",
            "De voorzitter: Ik heropen de vergadering om 13:10 uur.\n",
            "De voorzitter: Ik stel de leden van de gemeenteraad voor, om te\n",
            "prediction: NoPredictionFormat\n",
            "label:  motie\n",
            "response:  'categorie': Motie}\n",
            "prediction: NoPredictionFormat\n",
            "label:  brief\n",
            "response:  'categorie': Brief}\n",
            "prediction: NoPredictionFormat\n",
            "label:  agenda\n",
            "response:  \"agenda\": {\n",
            "\"categorie\": Agenda\n",
            "}\n",
            "}\n",
            "prediction: agenda\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.05263157894736842\n",
            "Starting...10:20 out of 160\n",
            "label:  brief\n",
            "response:  \"categorie\": Brief}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsadres\n",
            "response:  'categorie': Raadsadres}\n",
            "prediction: NoPredictionFormat\n",
            "label:  factsheet\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  schriftelijke vraag\n",
            "response:  'categorie': Schriftelijke Vraag}\n",
            "prediction: NoPredictionFormat\n",
            "label:  brief\n",
            "response:  \"Brief\"\n",
            "}\n",
            "prediction: NoPredictionFormat\n",
            "label:  schriftelijke vraag\n",
            "response:  'categorie': Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsnotulen\n",
            "response:  \"raadsnotulen\": {\n",
            "\"categorie\": Raadsnotulen\n",
            "}\n",
            "prediction: raadsnotulen\n",
            "label:  agenda\n",
            "response:  \"agenda\": Agenda, woensdag 18 november 2015\n",
            "\"categorie\": Agenda}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsadres\n",
            "response:  'categorie': Raadsadres}\n",
            "prediction: NoPredictionFormat\n",
            "label:  brief\n",
            "response:  \"categorie\": Brief}\n",
            "prediction: NoPredictionFormat\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.053125\n",
            "Starting...20:30 out of 160\n",
            "label:  raadsadres\n",
            "response:  'categorie': Raadsadres}\n",
            "prediction: NoPredictionFormat\n",
            "label:  actualiteit\n",
            "response:  \"categorie\": Raadsadres}\n",
            "prediction: NoPredictionFormat\n",
            "label:  agenda\n",
            "response:  \"agenda\": {\n",
            "\"categorie\": Agenda\n",
            "}\n",
            "}\n",
            "prediction: agenda\n",
            "label:  factsheet\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  agenda\n",
            "response:  \"agenda\": Agenda, 5 juli 2023\n",
            "\n",
            "\"categorie\": Agenda}\n",
            "prediction: NoPredictionFormat\n",
            "label:  voordracht\n",
            "response:  \"categorie\": Voordracht}\n",
            "prediction: NoPredictionFormat\n",
            "label:  voordracht\n",
            "response:  \"categorie\": Voordracht}\n",
            "prediction: NoPredictionFormat\n",
            "label:  motie\n",
            "response:  'categorie': Motie}\n",
            "prediction: NoPredictionFormat\n",
            "label:  onderzoeksrapport\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  besluit\n",
            "response:  \"categorie\": Besluit}\n",
            "prediction: NoPredictionFormat\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.05360824742268041\n",
            "Starting...30:40 out of 160\n",
            "label:  schriftelijke vraag\n",
            "response:  'categorie': Schriftelijke Vraag}\n",
            "prediction: NoPredictionFormat\n",
            "label:  onderzoeksrapport\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  besluit\n",
            "response:  'categorie': Besluit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  besluit\n",
            "response:  'categorie': Besluit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  factsheet\n",
            "response:  \"categorie\": Factsheet}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsadres\n",
            "response:  'categorie': Raadsadres}\n",
            "prediction: NoPredictionFormat\n",
            "label:  actualiteit\n",
            "response:  \"actualiteit\": {\n",
            "\"categorie\": Actualiteit\n",
            "}\n",
            "}\n",
            "prediction: actualiteit\n",
            "label:  motie\n",
            "response:  'categorie': Motie}\n",
            "prediction: NoPredictionFormat\n",
            "label:  motie\n",
            "response:  \"categorie\": Motie}\n",
            "prediction: NoPredictionFormat\n",
            "label:  besluit\n",
            "response:  'categorie': Besluit}\n",
            "prediction: NoPredictionFormat\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.05408163265306123\n",
            "Starting...40:50 out of 160\n",
            "label:  agenda\n",
            "response:  \"agenda\": Agenda\n",
            "} \"type\": Agenda\n",
            "} \"items\": [\n",
            "{\n",
            "\"date\": \"6-jan-2021\",\n",
            "\"time\": \"19:30\",\n",
            "\"locatie\": \"Virtueel\",\n",
            "\"name\": \"Presentatie Aanpak bijplaatsingen\",\n",
            "\"description\": \"Presentatie Aanpak bijplaatsingen\"\n",
            "},\n",
            "{\n",
            "\"date\": \"6-jan-2021\",\n",
            "\"time\": \"20:00\",\n",
            "\"locatie\": \"Virtueel\",\n",
            "\"name\": \"Agenderingsvoorstel â€˜gekapte bomen terug in Noordâ€™\",\n",
            "\"description\": \"Agenderingsvoorstel â€˜gekapte bomen terug in Noordâ€™ (uitgesteld in SDC 2 december 2020)\"\n",
            "},\n",
            "{\n",
            "\"date\": \"6-jan-2021\",\n",
            "\"time\": \"20:30\",\n",
            "\"locatie\": \"Virtueel\",\n",
            "\"name\": \"Adviesaanvraag Buiteneiland\",\n",
            "\"description\": \"\n",
            "prediction: MultiplePredictionErrorInFormatting\n",
            "label:  voordracht\n",
            "response:  'categorie': Voordracht}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsnotulen\n",
            "response:  \"raadsnotulen\": {\n",
            "\"vergaderdatum\": \"10 maart 2021\",\n",
            "\"publicatiedatum\": \"24 maart 2021\",\n",
            "\"openingstijd\": \"13:00 uur\",\n",
            "\"mededelingen\": \"De voorzitter heropent de vergadering om 13:00 uur.\n",
            "De voorzitter: Dan gaan we beginnen met de mededelingen.\n",
            "De heer Boomsma: Ik heb de eer voor te stellen: het lid Van Dantzig is\n",
            "afwezig.\n",
            "De voorzitter: Dan is er Ã©Ã©n vacature in de raad.\n",
            "De heer Boomsma: Ik heb de eer voor te stellen: het lid Van Dantzig is\n",
            "afwezig.\n",
            "De voorzitter: Dan is er Ã©Ã©n vacature in de raad.\n",
            "De heer Boomsma: Ik heb de eer voor te stellen: het lid Van Dantzig is\n",
            "afwezig.\n",
            "De voorzitter: Dan is er Ã©Ã©n vacature in de ra\n",
            "prediction: NoPredictionFormat\n",
            "label:  motie\n",
            "response:  \"categorie\": Motie}\n",
            "prediction: NoPredictionFormat\n",
            "label:  voordracht\n",
            "response:  \"categorie\": Voordracht}\n",
            "prediction: NoPredictionFormat\n",
            "label:  voordracht\n",
            "response:  'categorie': Voordracht}\n",
            "prediction: NoPredictionFormat\n",
            "label:  onderzoeksrapport\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsadres\n",
            "response:  'categorie': Raadsadres}\n",
            "prediction: NoPredictionFormat\n",
            "label:  brief\n",
            "response:  'categorie': Brief}\n",
            "prediction: NoPredictionFormat\n",
            "label:  actualiteit\n",
            "response:  \"categorie\": Actualiteit}\n",
            "prediction: NoPredictionFormat\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.05353535353535353\n",
            "Starting...50:60 out of 160\n",
            "label:  motie\n",
            "response:  \"categorie\": Motie}\n",
            "prediction: NoPredictionFormat\n",
            "label:  agenda\n",
            "response:  \"agenda\": Agenda\n",
            "\n",
            "\"type\": Agenda\n",
            "}\n",
            "prediction: NoPredictionFormat\n",
            "label:  onderzoeksrapport\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsadres\n",
            "response:  'categorie': Raadsadres}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsnotulen\n",
            "response:  \"categorie\": Raadsnotulen}\n",
            "prediction: NoPredictionFormat\n",
            "label:  motie\n",
            "response:  'categorie': Motie}\n",
            "prediction: NoPredictionFormat\n",
            "label:  agenda\n",
            "response:  \"agenda\": {\n",
            "\"categorie\": Agenda\n",
            "}\n",
            "}\n",
            "prediction: agenda\n",
            "label:  besluit\n",
            "response:  \"categorie\": Besluit\n",
            "}\n",
            "prediction: NoPredictionFormat\n",
            "label:  onderzoeksrapport\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  schriftelijke vraag\n",
            "response:  'categorie': Schriftelijke Vraag}\n",
            "prediction: NoPredictionFormat\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.054\n",
            "Starting...60:70 out of 160\n",
            "label:  factsheet\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  actualiteit\n",
            "response:  'categorie': Actualiteit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  voordracht\n",
            "response:  \"categorie\": Voordracht}\n",
            "prediction: NoPredictionFormat\n",
            "label:  factsheet\n",
            "response:  \"factsheet\": Factsheet bevolkingscijfers Noord A'dam, juli 2017\n",
            "}\n",
            "prediction: NoPredictionFormat\n",
            "label:  agenda\n",
            "response:  \"agenda\": {\n",
            "\"categorie\": Agenda\n",
            "} }\n",
            "prediction: agenda\n",
            "label:  voordracht\n",
            "response:  'categorie': Voordracht}\n",
            "prediction: NoPredictionFormat\n",
            "label:  besluit\n",
            "response:  \"categorie\": Besluit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  schriftelijke vraag\n",
            "response:  'categorie': Schriftelijke Vraag}\n",
            "prediction: NoPredictionFormat\n",
            "label:  onderzoeksrapport\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  onderzoeksrapport\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.054455445544554455\n",
            "Starting...70:80 out of 160\n",
            "label:  actualiteit\n",
            "response:  'categorie': Actualiteit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  brief\n",
            "response:  'categorie': Brief}\n",
            "prediction: NoPredictionFormat\n",
            "label:  motie\n",
            "response:  'categorie': Motie}\n",
            "prediction: NoPredictionFormat\n",
            "label:  motie\n",
            "response:  'categorie': Motie}\n",
            "prediction: NoPredictionFormat\n",
            "label:  schriftelijke vraag\n",
            "response:  'categorie': Schriftelijke Vraag}\n",
            "prediction: NoPredictionFormat\n",
            "label:  schriftelijke vraag\n",
            "response:  'categorie': Schriftelijke Vraag}\n",
            "prediction: NoPredictionFormat\n",
            "label:  brief\n",
            "response:  \"categorie\": Brief}\n",
            "prediction: NoPredictionFormat\n",
            "label:  onderzoeksrapport\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  motie\n",
            "response:  'categorie': Motie}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsnotulen\n",
            "response:  \"categorie\": Raadsnotulen }\n",
            "prediction: NoPredictionFormat\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.05392156862745098\n",
            "Starting...80:90 out of 160\n",
            "label:  raadsnotulen\n",
            "response:  \"raadsnotulen\": {\n",
            "\"categorie\": Raadsnotulen\n",
            "}\n",
            "prediction: raadsnotulen\n",
            "label:  besluit\n",
            "response:  'categorie': Besluit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  factsheet\n",
            "response:  \"factsheet\": Factsheet\n",
            "}\n",
            "}\n",
            "prediction: NoPredictionFormat\n",
            "label:  motie\n",
            "response:  'categorie': Motie}\n",
            "prediction: NoPredictionFormat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Bad pipe message: %s [b\"\\xe6\\xdb/\\xba\\x97?T\\x92\\xd5\\xe9\\xc5\\xad\\xe0nedx\\xf6\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\"]\n",
            "Bad pipe message: %s [b'\\x11\\x00\\x96\\x00\\x05\\x00']\n",
            "Bad pipe message: %s [b'\\xc0\\x1f08\\x81\\x1d\\xf0\\x13\\x95\\xf0\\xde\\x97<\\x90DTTs\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:']\n",
            "Bad pipe message: %s [b'\\x9c)\\xf6\\xcf\\xe0\\x97\\xd9\\x98\\x92\\x14\\x1e\\xc3\\xe2\\xfd\\xf3\\xc7\\x01\\x8c\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0']\n",
            "Bad pipe message: %s [b'\\x05']\n",
            "Bad pipe message: %s [b'k\\x11!\\x11\\xab ^\\xcbS-\\x07\\xbb+\\xe6\\xa5!\\x8d\\xae\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0', b\"&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\"]\n",
            "Bad pipe message: %s [b\"\\xc3\\x96D\\xe4\\r\\xc8T\\x19\\xbd\\xf2\\xbf\\x8c\\xe4cs\\xe8\\x14p\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\"]\n",
            "Bad pipe message: %s [b'\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00;\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\r\\x00 \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05\\x02\\x05\\x03\\x04\\x01\\x04\\x02\\x04\\x03', b'\\x03\\x02', b'\\x02\\x01', b'\\x02']\n",
            "Bad pipe message: %s [b'\\x0f\\x00']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  agenda\n",
            "response:  \"agenda\": {\n",
            "\"type\": \"Agenda\",\n",
            "\"commissie\": \"BWK\",\n",
            "\"ruimte\": \"Ruimte voor de commissie\",\n",
            "\"start\": \"09.00\",\n",
            "\"end\": \"12.30\",\n",
            "\"blokA\": {\n",
            "\"nummer\": 1,\n",
            "\"start\": \"09.00\",\n",
            "\"end\": \"12.30\",\n",
            "\"onderwerp\": \"Openbare vergadering van de Raadscommissie BWK\",\n",
            "\"tekst\": \"U wordt uitgenodigd voor de openbare vergadering van de Raadscommissie BWK. De\n",
            "vergadering vindt plaats in de Boekmanzaal, stadhuis. De commissie vergadert van 09.00\n",
            "tot 12.30 uur. De vergadering is openbaar en vrij te bezoeken. De commissie vergadert\n",
            "als volgt:\n",
            "- Opening\n",
            "- Mededelingen\n",
            "- Vaststellen agenda\n",
            "- _Inspreekhalfuur\n",
            "prediction: NoPredictionFormat\n",
            "label:  actualiteit\n",
            "response:  \"categorie\": Actualiteit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  besluit\n",
            "response:  'categorie': Besluit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  motie\n",
            "response:  'categorie': Motie}\n",
            "prediction: NoPredictionFormat\n",
            "label:  schriftelijke vraag\n",
            "response:  'categorie': Schriftelijke Vraag}\n",
            "prediction: NoPredictionFormat\n",
            "label:  motie\n",
            "response:  \"categorie\": Motie}\n",
            "prediction: NoPredictionFormat\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.05436893203883495\n",
            "Starting...90:100 out of 160\n",
            "label:  voordracht\n",
            "response:  \"categorie\": Voordracht}\n",
            "prediction: NoPredictionFormat\n",
            "label:  besluit\n",
            "response:  \"categorie\": Besluit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  brief\n",
            "response:  \"categorie\": Brief}\n",
            "prediction: NoPredictionFormat\n",
            "label:  schriftelijke vraag\n",
            "response:  'categorie': Schriftelijke Vraag}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsnotulen\n",
            "response:  \"raadsnotulen\": {\n",
            "\"categorie\": Raadsnotulen\n",
            "}\n",
            "prediction: raadsnotulen\n",
            "label:  raadsadres\n",
            "response:  'categorie': Raadsadres}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsnotulen\n",
            "response:  \"categorie\": Raadsnotulen }\n",
            "prediction: NoPredictionFormat\n",
            "label:  agenda\n",
            "response:  'agenda': Agenda}\n",
            "prediction: NoPredictionFormat\n",
            "label:  besluit\n",
            "response:  \"categorie\": Besluit |\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "|\n",
            "\n",
            "prediction: NoPredictionFormat\n",
            "label:  motie\n",
            "response:  'categorie': Motie}\n",
            "prediction: NoPredictionFormat\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.05480769230769231\n",
            "Starting...100:110 out of 160\n",
            "label:  onderzoeksrapport\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  brief\n",
            "response:  \"categorie\": Brief}\n",
            "prediction: NoPredictionFormat\n",
            "label:  actualiteit\n",
            "response:  'categorie': Actualiteit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  agenda\n",
            "response:  \"agenda\": Agenda\n",
            "} \"programma\": Programma\n",
            "} \"soort\": Actualiteit\n",
            "} \"datum in Cie\": 13-Mei-15\n",
            "} \"opmerkingen t.b.v. de commissie\": Extra voorbereidingstijd nodig voor kwalificatie activiteiten\n",
            "} \"datum in Cie\": 13-Mei-15\n",
            "} \"opmerkingen t.b.v. de commissie\": Opdracht tot uitvoering\n",
            "} \"programma\": Programma\n",
            "} \"soort\": Besluit\n",
            "} \"datum in Cie\": 13-Mei-15\n",
            "} \"opmerkingen t.b.v. de commissie\": Nvt.\n",
            "} \"programma\": Programma\n",
            "} \"soort\": Schriftelijke Vraag\n",
            "} \"datum in Cie\": 13-Mei-15\n",
            "} \"opmerkingen t.b.v. de commissie\": Nvt.\n",
            "} \"programma\": Programma\n",
            "} \"soort\": Besluit\n",
            "} \"datum\n",
            "prediction: NoPredictionFormat\n",
            "label:  factsheet\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsnotulen\n",
            "response:  \"raadsnotulen\": {\n",
            "\"categorie\": Raadsnotulen\n",
            "}\n",
            "prediction: raadsnotulen\n",
            "label:  raadsnotulen\n",
            "response:  \"categorie\": Raadsnotulen }\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsadres\n",
            "response:  'categorie': Raadsadres}\n",
            "prediction: NoPredictionFormat\n",
            "label:  schriftelijke vraag\n",
            "response:  'categorie': Schriftelijke Vraag}\n",
            "prediction: NoPredictionFormat\n",
            "label:  agenda\n",
            "response:  \"agenda\": Agenda\n",
            "\n",
            "\"type\": Agenda\n",
            "\n",
            "\"items\": [\n",
            "\n",
            "{\n",
            "\n",
            "\"title\": \"1. Opening\"\n",
            "\n",
            "\"type\": \"Opening\"\n",
            "\n",
            "},\n",
            "\n",
            "{\n",
            "\n",
            "\"title\": \"2. Mededelingen\"\n",
            "\n",
            "\"type\": \"Mededelingen\"\n",
            "\n",
            "},\n",
            "\n",
            "{\n",
            "\n",
            "\"title\": \"3. Insprekers\"\n",
            "\n",
            "\"type\": \"Insprekers\"\n",
            "\n",
            "},\n",
            "\n",
            "{\n",
            "\n",
            "\"title\": \"4. Mondelinge vragen\"\n",
            "\n",
            "\"type\": \"Mondelinge vragen\"\n",
            "\n",
            "},\n",
            "\n",
            "{\n",
            "\n",
            "\"title\": \"5. Adviesaanvraag Ontwerpbestemmingsplan aste partiÃ«le herziening bestemmingsplan Lutkemeerpolder\"\n",
            "\n",
            "\"type\": \"Adviesaanvraag\"\n",
            "\n",
            "},\n",
            "\n",
            "{\n",
            "\n",
            "\"title\": \"6. Motie Jongeren adviescommissie\"\n",
            "\n",
            "\"type\": \"Motie\"\n",
            "\n",
            "},\n",
            "\n",
            "{\n",
            "\n",
            "\"title\": \"7. Presentatie Regenboogagenda\"\n",
            "\n",
            "prediction: MultiplePredictionErrorInFormatting\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.05523809523809524\n",
            "Starting...110:120 out of 160\n",
            "label:  raadsnotulen\n",
            "response:  \"Raadsnotulen\": {\n",
            "\"categorie\": Raadsnotulen\n",
            "}\n",
            "prediction: raadsnotulen\n",
            "label:  raadsnotulen\n",
            "response:  \"categorie\": Raadsnotulen }\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsadres\n",
            "response:  \"categorie\": Raadsadres}\n",
            "prediction: NoPredictionFormat\n",
            "label:  factsheet\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  schriftelijke vraag\n",
            "response:  'categorie': Schriftelijke Vraag}\n",
            "prediction: NoPredictionFormat\n",
            "label:  actualiteit\n",
            "response:  'categorie': Actualiteit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  besluit\n",
            "response:  \"categorie\": Besluit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsnotulen\n",
            "response:  \"raadsnotulen\": {\n",
            "\"categorie\": Raadsnotulen\n",
            "}\n",
            "prediction: raadsnotulen\n",
            "label:  agenda\n",
            "response:  \"agenda\": Agenda,\n",
            "\"commissie\": Commissie,\n",
            "\"datum\": 2011-09-06,\n",
            "\"titel\": Termijnagenda Commissie Samenleving tbv 6 september 2011\n",
            "}\n",
            "prediction: NoPredictionFormat\n",
            "label:  actualiteit\n",
            "response:  \"categorie\": Actualiteit}\n",
            "prediction: NoPredictionFormat\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.05660377358490566\n",
            "Starting...120:130 out of 160\n",
            "label:  brief\n",
            "response:  \"categorie\": Brief}\n",
            "prediction: NoPredictionFormat\n",
            "label:  onderzoeksrapport\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  factsheet\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  brief\n",
            "response:  \"categorie\": Brief}\n",
            "prediction: NoPredictionFormat\n",
            "label:  voordracht\n",
            "response:  \"categorie\": Voordracht}\n",
            "prediction: NoPredictionFormat\n",
            "label:  actualiteit\n",
            "response:  'categorie': Actualiteit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  motie\n",
            "response:  \"categorie\": Motie}\n",
            "prediction: NoPredictionFormat\n",
            "label:  onderzoeksrapport\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsnotulen\n",
            "response:  \"raadsnotulen\": {\n",
            "\"categorie\": Raadsnotulen\n",
            "}\n",
            "prediction: raadsnotulen\n",
            "label:  motie\n",
            "response:  'categorie': Motie}\n",
            "prediction: NoPredictionFormat\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.05700934579439252\n",
            "Starting...130:140 out of 160\n",
            "label:  voordracht\n",
            "response:  \"categorie\": Voordracht}\n",
            "prediction: NoPredictionFormat\n",
            "label:  onderzoeksrapport\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsadres\n",
            "response:  'categorie': Raadsadres}\n",
            "prediction: NoPredictionFormat\n",
            "label:  factsheet\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  factsheet\n",
            "response:  \"factsheet\": Factsheet Economische ontwikkelingen Amsterdam, augustus 2020\n",
            "\n",
            "\"indicatoren\":\n",
            "\n",
            "* _ Gross Domestic Product (GDP) per kwartaal\n",
            "* _ Beroepsbeschikkingen\n",
            "* _ Consumentenvertrouwen\n",
            "* _ Zelfstandigenindex\n",
            "* _ Woningbouw\n",
            "* _ Erfpacht\n",
            "* _ Leningen\n",
            "* _ Inkomens\n",
            "* _ Inflatie\n",
            "* _ Bedrijfsruimte\n",
            "* _ Toerisme\n",
            "* _ Bezoekersaantallen\n",
            "* _ Overnachtingsbezoek\n",
            "* _ Conferentiebranche\n",
            "* _ Deelnemingen\n",
            "* _ Personeel en organisatie\n",
            "* _ Dienstverlening\n",
            "* _ ICT\n",
            "* _ Duurzaamheid\n",
            "\n",
            "\"alternatieve indicatoren\":\n",
            "\n",
            "* _ Google Trends: Searches for \"economische zaken\"\n",
            "* _ Sociale media: Mentions van Amsterdam en economische onderwerpen\n",
            "* _ Vakantieverhuur: Luchthaven en hotels\n",
            "* _\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsnotulen\n",
            "response:  \"raadsnotulen\": {\n",
            "\"categorie\": Raadsnotulen\n",
            "}\n",
            "prediction: raadsnotulen\n",
            "label:  voordracht\n",
            "response:  \"categorie\": Voordracht}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsnotulen\n",
            "response:  \"categorie\": Raadsnotulen }\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsnotulen\n",
            "response:  \"categorie\": Raadsnotulen }\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsadres\n",
            "response:  \"categorie\": Raadsadres}\n",
            "prediction: NoPredictionFormat\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.05740740740740741\n",
            "Starting...140:150 out of 160\n",
            "label:  motie\n",
            "response:  'categorie': Motie}\n",
            "prediction: NoPredictionFormat\n",
            "label:  agenda\n",
            "response:  \"agenda\": Agenda\n",
            "\n",
            "\"commissie\": Commissie\n",
            "\n",
            "\"griffie\": Griffie\n",
            "\n",
            "\"mw\": Mevrouw\n",
            "\n",
            "\"postbus\": Postbus\n",
            "\n",
            "\"raad\": Raad\n",
            "\n",
            "\"telefoon\": Telefoon\n",
            "\n",
            "\"wmo\": Wmo\n",
            "\n",
            "\"zw\": Zorg\n",
            "\n",
            "\"zuid\": Zuid\n",
            "\n",
            "\"raadscommissie\": {\n",
            "\n",
            "\"welzijn\": {\n",
            "\n",
            "\"zorg\": {\n",
            "\n",
            "\"onderwijs\": {\n",
            "\n",
            "\"sport\": {\n",
            "\n",
            "\"kunst en cultuur\": {\n",
            "\n",
            "\"maatschappelijke dienstverlening\": {\n",
            "\n",
            "\"voorzitter\": {\n",
            "\n",
            "\"griffier\": {\n",
            "\n",
            "\"contactpersoon\": {\n",
            "\n",
            "\"raadscommissie\": {\n",
            "\n",
            "\"welzijn\": {\n",
            "\n",
            "\"zorg\": {\n",
            "\n",
            "\"onderwijs\": {\n",
            "\n",
            "\"sport\": {\n",
            "\n",
            "\"kunst en cultuur\": {\n",
            "\n",
            "\"maatschappelijke dienstverlening\": {\n",
            "\n",
            "\"raadscommissie\": {\n",
            "\n",
            "\"\n",
            "prediction: NoPredictionFormat\n",
            "label:  onderzoeksrapport\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  brief\n",
            "response:  ' categorie': Brief}\n",
            "prediction: NoPredictionFormat\n",
            "label:  voordracht\n",
            "response:  \"categorie\": Voordracht}\n",
            "prediction: NoPredictionFormat\n",
            "label:  agenda\n",
            "response:  \"agenda\": Agenda\n",
            "\n",
            "\"type\": Agenda\n",
            "\n",
            "\"_id\": \"agenda:pleno:20190604\"\n",
            "\n",
            "\"items\": [\n",
            "\n",
            "{\n",
            "\n",
            "\"_id\": \"item:1\",\n",
            "\n",
            "\"title\": \"Opening en vaststelling agenda\",\n",
            "\n",
            "\"type\": \"open\"\n",
            "\n",
            "},\n",
            "\n",
            "{\n",
            "\n",
            "\"_id\": \"item:2\",\n",
            "\n",
            "\"title\": \"Mededelingen\",\n",
            "\n",
            "\"type\": \"mededelingen\"\n",
            "\n",
            "},\n",
            "\n",
            "{\n",
            "\n",
            "\"_id\": \"item:3\",\n",
            "\n",
            "\"title\": \"Vaststellen van het conceptverslag van de vergadering van 21 mei 2019\",\n",
            "\n",
            "\"type\": \"conceptverslag\"\n",
            "\n",
            "},\n",
            "\n",
            "{\n",
            "\n",
            "\"_id\": \"item:4\",\n",
            "\n",
            "\"title\": \"Mededelingen van de ingekomen stukken\",\n",
            "\n",
            "\"type\": \"mededelingen\"\n",
            "\n",
            "},\n",
            "\n",
            "{\n",
            "\n",
            "\"_id\": \"item:5\",\n",
            "\n",
            "\"title\": \"Het woord aan bewoners,\n",
            "prediction: MultiplePredictionErrorInFormatting\n",
            "label:  besluit\n",
            "response:  \"categorie\": Besluit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsnotulen\n",
            "response:  \"raadsnotulen\": {\n",
            "\"categorie\": Raadsnotulen\n",
            "}\n",
            "prediction: raadsnotulen\n",
            "label:  onderzoeksrapport\n",
            "response:  \"categorie\": Onderzoeksrapport}\n",
            "prediction: NoPredictionFormat\n",
            "label:  voordracht\n",
            "response:  'categorie': Voordracht}\n",
            "prediction: NoPredictionFormat\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.05779816513761468\n",
            "Starting...last 10 docs\n",
            "label:  besluit\n",
            "response:  ' categorie': Besluit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  motie\n",
            "response:  'categorie': Motie}\n",
            "prediction: NoPredictionFormat\n",
            "label:  brief\n",
            "response:  \"categorie\": Brief}\n",
            "prediction: NoPredictionFormat\n",
            "label:  voordracht\n",
            "response:  \"categorie\": Voordracht}\n",
            "prediction: NoPredictionFormat\n",
            "label:  schriftelijke vraag\n",
            "response:  \"categorie\": Actualiteit}\n",
            "prediction: NoPredictionFormat\n",
            "label:  agenda\n",
            "response:  \"agenda\": Agenda voor de vergadering van de stadsdeelraad Zuidoost op 30 mei 2006\n",
            "\n",
            "\"1\": Opening en Mededelingen\n",
            "\n",
            "\"1a\": Vaststelling van de agenda\n",
            "\n",
            "\"2\": Verslag vergadering 11 april 2006\n",
            "\n",
            "\"3\": Toezeggingen en termijnagenda\n",
            "\n",
            "\"4\": Vragenhalfuur publiek\n",
            "\n",
            "\"5\": Actualiteiten\n",
            "\n",
            "\"6\": Stem van Zuidoost\n",
            "\n",
            "\"7\": Vragen aan het DB\n",
            "\n",
            "\"8\": Kijk op de wijk\n",
            "\n",
            "\"9\": Sluiting\n",
            "\n",
            "\"10\": Termijnagenda (t.b.v. raadsgriffie)\n",
            "\n",
            "\"11\": Voorjaarsnota 2006 (t.b.v. raadsgriffie)\n",
            "\n",
            "\"12\": Voorjaarsnota 2006 (t.b.v. raadsgriffie)\n",
            "\n",
            "\"13\": Voorjaarsnota 200\n",
            "prediction: NoPredictionFormat\n",
            "label:  voordracht\n",
            "response:  \"categorie\": Voordracht}\n",
            "prediction: NoPredictionFormat\n",
            "label:  agenda\n",
            "response:  \"agenda\": Agenda\n",
            "\n",
            "\"type\": Agenda\n",
            "}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsadres\n",
            "response:  \"categorie\": Raadsadres}\n",
            "prediction: NoPredictionFormat\n",
            "label:  raadsnotulen\n",
            "response:  \"categorie\": Raadsnotulen }\n",
            "prediction: NoPredictionFormat\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.057272727272727274\n"
          ]
        }
      ],
      "source": [
        "# run experiment\n",
        "\n",
        "# add new column with truncated text -> new dataframe with column + new column name\n",
        "trunc_df = tf.add_truncation_column(txt,'text', TOKENS_COL, FRONT_THRESHOLD, BACK_THRESHOLD)\n",
        "\n",
        "# if new run MAKE SURE RUN_ID IS UNIQUE, if want to resume run, pass in that run_id\n",
        "run_experiment(chatbot_mistral, trunc_df, run_id, PROMPT, TEXT_COLUMN, SPLIT_COLUMN, TRAIN_SET, TEST_SET, LABEL_COLUMN, PREDICTION_PATH, OVERVIEW_PATH, MODEL_NAME, NUMBER_EXAMPLES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>run_id</th>\n",
              "      <th>date</th>\n",
              "      <th>train_set</th>\n",
              "      <th>test_set</th>\n",
              "      <th>train_set_support</th>\n",
              "      <th>test_set_support</th>\n",
              "      <th>split_col</th>\n",
              "      <th>text_col</th>\n",
              "      <th>runtime</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro_avg_precision</th>\n",
              "      <th>macro_avg_recall</th>\n",
              "      <th>macro_avg_f1</th>\n",
              "      <th>weighted_avg_precision</th>\n",
              "      <th>weighted_avg_recall</th>\n",
              "      <th>weighted_avg_f1</th>\n",
              "      <th>classification_report</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AmsterdamDocClassificationGEITje200T</td>\n",
              "      <td>FT_AmsterdamDocClassificationGEITje200Tzerosho...</td>\n",
              "      <td>2024-05-31 17:00:16.806328+02:00</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront200Back0</td>\n",
              "      <td>23948.996279</td>\n",
              "      <td>0.898182</td>\n",
              "      <td>0.926410</td>\n",
              "      <td>0.898182</td>\n",
              "      <td>0.891699</td>\n",
              "      <td>0.926410</td>\n",
              "      <td>0.898182</td>\n",
              "      <td>0.891699</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AmsterdamDocClassificationMistral200T</td>\n",
              "      <td>OLDFT_AmsterdamDocClassificationMistral200Tzer...</td>\n",
              "      <td>2024-05-31 18:41:44.412997+02:00</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>200</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront200Back0</td>\n",
              "      <td>4586.422368</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AmsterdamDocClassificationLlama200T</td>\n",
              "      <td>FT_AmsterdamDocClassificationLlama200Tzeroshot...</td>\n",
              "      <td>2024-05-31 16:53:49.451759+02:00</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront200Back0</td>\n",
              "      <td>21965.290097</td>\n",
              "      <td>0.864545</td>\n",
              "      <td>0.832160</td>\n",
              "      <td>0.792500</td>\n",
              "      <td>0.780662</td>\n",
              "      <td>0.907811</td>\n",
              "      <td>0.864545</td>\n",
              "      <td>0.851631</td>\n",
              "      <td>precision    recall  f1-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AmsterdamDocClassificationMistral200T</td>\n",
              "      <td>FT_AmsterdamDocClassificationMistral200Tzerosh...</td>\n",
              "      <td>2024-06-04 16:09:46.493691+02:00</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>80</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront200Back0</td>\n",
              "      <td>4198.556982</td>\n",
              "      <td>0.037500</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.087500</td>\n",
              "      <td>0.037500</td>\n",
              "      <td>0.052500</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AmsterdamDocClassificationMistral200T2Epochs</td>\n",
              "      <td>FT_AmsterdamDocClassificationMistral200T2Epoch...</td>\n",
              "      <td>2024-06-05 07:31:54.724291+02:00</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>940</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront200Back0</td>\n",
              "      <td>49201.589993</td>\n",
              "      <td>0.052128</td>\n",
              "      <td>0.326840</td>\n",
              "      <td>0.042827</td>\n",
              "      <td>0.065659</td>\n",
              "      <td>0.411573</td>\n",
              "      <td>0.052128</td>\n",
              "      <td>0.080087</td>\n",
              "      <td>precision...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          model  \\\n",
              "0          AmsterdamDocClassificationGEITje200T   \n",
              "1         AmsterdamDocClassificationMistral200T   \n",
              "2           AmsterdamDocClassificationLlama200T   \n",
              "0         AmsterdamDocClassificationMistral200T   \n",
              "0  AmsterdamDocClassificationMistral200T2Epochs   \n",
              "\n",
              "                                              run_id  \\\n",
              "0  FT_AmsterdamDocClassificationGEITje200Tzerosho...   \n",
              "1  OLDFT_AmsterdamDocClassificationMistral200Tzer...   \n",
              "2  FT_AmsterdamDocClassificationLlama200Tzeroshot...   \n",
              "0  FT_AmsterdamDocClassificationMistral200Tzerosh...   \n",
              "0  FT_AmsterdamDocClassificationMistral200T2Epoch...   \n",
              "\n",
              "                              date train_set test_set  train_set_support  \\\n",
              "0 2024-05-31 17:00:16.806328+02:00     train     test               9900   \n",
              "1 2024-05-31 18:41:44.412997+02:00     train     test               9900   \n",
              "2 2024-05-31 16:53:49.451759+02:00     train     test               9900   \n",
              "0 2024-06-04 16:09:46.493691+02:00     train     test               9900   \n",
              "0 2024-06-05 07:31:54.724291+02:00     train     test               9900   \n",
              "\n",
              "   test_set_support       split_col                            text_col  \\\n",
              "0              1100  balanced_split  TruncationLlamaTokensFront200Back0   \n",
              "1               200  balanced_split  TruncationLlamaTokensFront200Back0   \n",
              "2              1100  balanced_split  TruncationLlamaTokensFront200Back0   \n",
              "0                80  balanced_split  TruncationLlamaTokensFront200Back0   \n",
              "0               940  balanced_split  TruncationLlamaTokensFront200Back0   \n",
              "\n",
              "        runtime  accuracy  macro_avg_precision  macro_avg_recall  \\\n",
              "0  23948.996279  0.898182             0.926410          0.898182   \n",
              "1   4586.422368  0.000000             0.000000          0.000000   \n",
              "2  21965.290097  0.864545             0.832160          0.792500   \n",
              "0   4198.556982  0.037500             0.083333          0.035714   \n",
              "0  49201.589993  0.052128             0.326840          0.042827   \n",
              "\n",
              "   macro_avg_f1  weighted_avg_precision  weighted_avg_recall  weighted_avg_f1  \\\n",
              "0      0.891699                0.926410             0.898182         0.891699   \n",
              "1      0.000000                0.000000             0.000000         0.000000   \n",
              "2      0.780662                0.907811             0.864545         0.851631   \n",
              "0      0.050000                0.087500             0.037500         0.052500   \n",
              "0      0.065659                0.411573             0.052128         0.080087   \n",
              "\n",
              "                               classification_report  \n",
              "0                       precision    recall  f1-s...  \n",
              "1                       precision    recall  f1-s...  \n",
              "2                        precision    recall  f1-...  \n",
              "0                       precision    recall  f1-s...  \n",
              "0                                       precision...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pred = pd.read_pickle(OVERVIEW_PATH)\n",
        "display(pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "amsterdamincontextlearning"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "nl"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
