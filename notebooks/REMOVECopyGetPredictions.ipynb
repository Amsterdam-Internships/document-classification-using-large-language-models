{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "!bash /home/azureuser/cloudfiles/code/blobfuse/blobfuse_raadsinformatie.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1712584227159
        }
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "# Select where to run notebook: \"azure\" or \"local\"\n",
        "my_run = \"azure\"\n",
        "\n",
        "# import my_secrets as sc\n",
        "# import settings as st\n",
        "\n",
        "if my_run == \"azure\":\n",
        "    import config_azure as cf\n",
        "elif my_run == \"local\":\n",
        "    import config as cf\n",
        "\n",
        "\n",
        "import os\n",
        "if my_run == \"azure\":\n",
        "    if not os.path.exists(cf.HUGGING_CACHE):\n",
        "        os.mkdir(cf.HUGGING_CACHE)\n",
        "    os.environ[\"TRANSFORMERS_CACHE\"] = cf.HUGGING_CACHE\n",
        "\n",
        "# set-up environment - GEITje-7b-chat InContextLearning:\n",
        "# - install blobfuse -> sudo apt-get install blobfuse\n",
        "# - pip install transformers\n",
        "# - pip install torch\n",
        "# - pip install accelerate\n",
        "# - pip install jupyter\n",
        "# - pip install ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notebook overview\n",
        "- Goal: Run experiment for InContext Learning GEITje\n",
        "- Trial run model -> prompt GEITje using, example prompt\n",
        "- Zeroshot prompts\n",
        "- Fewshot prompts\n",
        "\n",
        "Load data and functions:\n",
        "- data is already split\n",
        "- text is already converted to tokens using model tokenizer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# df = pd.read_pickle(f\"{cf.output_path}/txtfiles_tokenizer.pkl\")\n",
        "\n",
        "import sys\n",
        "sys.path.append('../scripts/') \n",
        "import prompt_template as pt\n",
        "import prediction_helperfunctions as ph\n",
        "import truncation as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "778f15c2f5a742ec9feea4fa7dd26f88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Trial run Models \n",
        "Code to run the models with a simple prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_geitje = pipeline(task='conversational', model='Rijgersberg/GEITje-7B-chat-v2',\n",
        "                   device_map='auto', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "\n",
        "chatbot_llama = pipeline(task='conversational', model='meta-llama/Llama-2-7b-chat-hf',\n",
        "                   device_map='auto', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "chatbot_mistral = pipeline(task='conversational', model='mistralai/Mistral-7B-Instruct-v0.2',\n",
        "                   device_map='auto', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "## EXAMPLE PROMPT\n",
        "# print(chatbot(\n",
        "    # Conversation('Welk woord hoort er niet in dit rijtje thuis: \"auto, vliegtuig, geitje, bus\"?')\n",
        "# ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Experiment functions\n",
        "Prompt GEITje for each document and save the prediction, return response, response time and the prompt version\n",
        "\n",
        "Code structure:\n",
        "- 2 functions/cells:\n",
        "- predictions_incontextlearning -> given a df with docs that need to be predicted, prompt the model\n",
        "- run the experiment -> built in failsaves (df run in parts, with saves in between)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "from bm25 import BM25\n",
        "\n",
        "\n",
        "\"\"\" Given a dataframe with txt, return a df with predictions \"\"\"\n",
        "# docs_df = dataframe with the documents that need to be predicted\n",
        "# text_column = name of the column that includes the input_text. Can be different based on the text representation method. \n",
        "# prompt_function = prompt template \n",
        "# train_df = dataframe with docs, which can be used as examples/training data/context data\n",
        "# num_examples = number of examples in the prompt\n",
        "\n",
        "def predictions_incontextlearning(chatbot, docs_df, text_column, prompt_function, train_df, num_examples):\n",
        "    results_df = pd.DataFrame(columns = ['id', 'path', 'text_column', 'prompt_function', 'response', 'prediction', 'label', 'runtime', 'date', 'prompt'])\n",
        "\n",
        "\n",
        "    if prompt_function == pt.fewshot_prompt_with_template or prompt_function == pt.fewshot_prompt_no_template:\n",
        "        BM25_model = BM25()\n",
        "        BM25_model.fit(train_df[text_column])\n",
        "   \n",
        "\n",
        "    # prompt each document\n",
        "    for index, row in docs_df.iterrows():\n",
        "        # if (index + 1) % 200 == 0:\n",
        "        #     print(f\"Iteration {index +1}/{len(docs_df)} completed.\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # get the prompt, with the doc filled in\n",
        "        txt = row[text_column]\n",
        "\n",
        "        # each prompt function takes different arguments\n",
        "        # zeroshot prompt for geitje\n",
        "        if prompt_function == pt.zeroshot_prompt_geitje:\n",
        "            prompt = prompt_function(txt)\n",
        "\n",
        "        # zeroshot function for mistral and llama\n",
        "        elif prompt_function == pt.zeroshot_prompt_mistral_llama:\n",
        "            prompt = prompt_function(txt)\n",
        "\n",
        "        # select fewshot examples using bm25, fewshot is the same for all models\n",
        "        # elif prompt_function == pt.fewshot_prompt_bm25:\n",
        "        #     prompt = prompt_function(txt, train_df, num_examples, text_column, BM25_model)\n",
        "        \n",
        "        elif prompt_function == pt.fewshot_prompt_no_template:\n",
        "            prompt = prompt_function(txt, train_df, num_examples, text_column, BM25_model)\n",
        "\n",
        "        elif prompt_function == pt.fewshot_prompt_with_template:\n",
        "            prompt = prompt_function(txt, train_df, num_examples, text_column, BM25_model)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Prompt function not recognised. Check if prompt function is in prompt_template.py and included in the options above.\")\n",
        "\n",
        "        # prompt and get the response\n",
        "        # print(prompt)\n",
        "        converse = chatbot(Conversation(prompt))\n",
        "        response = converse[1]['content']\n",
        "        print(\"label: \", row['label'].lower())\n",
        "        print(\"response: \", response)\n",
        "\n",
        "        # extract prediction from response\n",
        "        prediction = ph.get_prediction_from_response(response)\n",
        "        print(\"prediction:\", prediction)\n",
        "\n",
        "        # save results in dataframe\n",
        "        results_df.loc[len(results_df)] = {\n",
        "            'id': row['id'],\n",
        "            'path' : row['path'],\n",
        "            'text_column' : docs_df.iloc[0]['trunc_col'],\n",
        "            'prompt_function': ph.get_promptfunction_name(prompt_function),\n",
        "            'response':response,\n",
        "            'prediction':prediction,\n",
        "            'label':row['label'].lower(),\n",
        "            'runtime':time.time()-start_time,\n",
        "            'date': ph.get_datetime(),\n",
        "            'prompt':prompt\n",
        "        }\n",
        "    return results_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\"\"\"\n",
        "Function to run GEITje In-Context Learning experiment. \n",
        "The function allows to resume experiment, if run_id matches.\n",
        "\"\"\"\n",
        "# df = dataframe with all docs that need to have a prediction (docs still need to be predict + already predicted)\n",
        "# run_id = unqiue for each experiment. \n",
        "# prompt_function = which prompt from prompt_template.py to use\n",
        "# text_col = colum in df where the text is. (Needs to be already truncated)\n",
        "# split_col = column with the dataset split. Either '2split' (train and test)or '4split'(train, test, dev and val)\n",
        "# subset_train = indicates which subset to use as training. either 'train' or 'dev'\n",
        "# subset_test = indicates which subset to use for testing. either 'test' or 'val'\n",
        "# label_col = column with the true label\n",
        "# prediction_path = path to file where predictions need to be saved.\n",
        "# overview_path = path to file where results of each run need to be saved.\n",
        "# model_name = name of the model. string.\n",
        "# num_exmples = number of exaples given to prompt. zero in case of zeroshot. \n",
        "\n",
        "def run_experiment(chatbot, df, run_id, prompt_function, text_col, split_col, subset_train, subset_test, label_col, prediction_path, overview_path, model_name, num_examples=0):\n",
        "    test_df = df.loc[df[split_col]==subset_test]\n",
        "    train_df = df.loc[df[split_col]==subset_train]\n",
        "    \n",
        "    # get rows of df that still need to be predicted for the specific run_id\n",
        "    to_predict, previous_predictions = ph.get_rows_to_predict(test_df, prediction_path, run_id)\n",
        "\n",
        "    # devide to_predict into subsection of 50 predictions at a time. \n",
        "    # Allows to rerun without problem. And save subsections of 50 predictions.\n",
        "    step_range = list(range(0, len(to_predict), 10))\n",
        "\n",
        "    for i in range(len(step_range)):\n",
        "        try:\n",
        "            sub_to_predict = to_predict.iloc[step_range[i]:step_range[i+1]]\n",
        "            print(f'Starting...{step_range[i]}:{step_range[i+1]} out of {len(to_predict)}')\n",
        "        except Exception as e:\n",
        "            sub_to_predict = to_predict[step_range[i]:]\n",
        "            print(f'Starting...last {len(sub_to_predict)} docs')\n",
        "\n",
        "        # prompt geitje\n",
        "        predictions = predictions_incontextlearning(chatbot, sub_to_predict, text_col, prompt_function, train_df, num_examples)\n",
        "\n",
        "        # save info\n",
        "        predictions['run_id'] = run_id\n",
        "        predictions['train_set'] = subset_train\n",
        "        predictions['test_set'] = subset_test\n",
        "        predictions['shots'] = num_examples\n",
        "\n",
        "        # save new combinations in file\n",
        "        print(\"Dont interrupt, saving predictions...\")\n",
        "        ph.combine_and_save_df(predictions, prediction_path)\n",
        "\n",
        "        # if previous predictions, combine previous with new predictions, to get update classification report\n",
        "        try:\n",
        "            predictions = pd.concat([predictions, previous_predictions])\n",
        "\n",
        "            # set previous predictions to all predictions made until now. Necessary for next loop\n",
        "            previous_predictions = predictions\n",
        "        except Exception as e:\n",
        "            # set previous predictions to all predictions made until now. Necessary for next loop\n",
        "            previous_predictions = predictions\n",
        "\n",
        "        # save results in overview file\n",
        "        date = ph.get_datetime()\n",
        "        y_test = predictions['label']\n",
        "        y_pred = predictions['prediction']\n",
        "\n",
        "        # change error predictions to one error\n",
        "        # error_names = ['NoPredictionInOutput', 'MultiplePredictionErrorInFormatting','NoPredictionFormat', 'MultiplePredictionErrorInOutput']\n",
        "        # y_pred = ['OutputError' if x in error_names else x for x in y_pred]\n",
        "\n",
        "        report = classification_report(y_test, y_pred)\n",
        "\n",
        "        overview = pd.DataFrame(\n",
        "            [{\n",
        "                'model':model_name,\n",
        "                'run_id':run_id,\n",
        "                'date': date,\n",
        "                'train_set': subset_train,\n",
        "                'test_set': subset_test,\n",
        "                'train_set_support':len(df.loc[df[split_col]==subset_train]),\n",
        "                'test_set_support':len(predictions),\n",
        "                'split_col':split_col,\n",
        "                'text_col':df.iloc[0]['trunc_col'],\n",
        "                'runtime':sum(predictions['runtime']),\n",
        "                'accuracy': accuracy_score(y_test, y_pred),\n",
        "                'macro_avg_precision': precision_score(y_test, y_pred, average='macro'),\n",
        "                'macro_avg_recall': recall_score(y_test, y_pred, average='macro'),\n",
        "                'macro_avg_f1': f1_score(y_test, y_pred, average='macro'),\n",
        "                'weighted_avg_precision': precision_score(y_test, y_pred, average='weighted'),\n",
        "                'weighted_avg_recall': recall_score(y_test, y_pred, average='weighted'),\n",
        "                'weighted_avg_f1': f1_score(y_test, y_pred, average='weighted'),\n",
        "                'classification_report':report\n",
        "            }   ]\n",
        "        )\n",
        "        # remove previous results of run_id, replace with new/updated results\n",
        "        ph.replace_and_save_df(overview, overview_path, run_id)\n",
        "        print(\"Saving done! Interrupting is allowed.\")\n",
        "        print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set up variables that are the same for each model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set  variables, same for each model\n",
        "TRAIN_SET = 'train' # must be dev or train\n",
        "TEST_SET = 'test' # must be val or test\n",
        "SPLIT_COLUMN = 'balanced_split' #must be either 2split or 4split. 2split = data split into train and test. 4split = data split into train, test, dev and val. \n",
        "LABEL_COLUMN = 'label'\n",
        "TEXT_COLUMN = 'trunc_txt'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = pd.read_pickle(f\"{cf.output_path}/txtfiles_tokenizer.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GEITje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SHORT_MODEL_NAME = 'GEITje'\n",
        "PROMPT = pt.zeroshot_prompt_geitje\n",
        "PROMPT_NAME = ph.get_promptfunction_name(PROMPT)\n",
        "TOKENS_COL = 'LlamaTokens' # column with text split using tokenizer of either mistral (MistralTokens) or Llama (LlamaTokens). Using Llama, because Llama split into more tokens. \n",
        "FRONT_THRESHOLD = 200\n",
        "BACK_THRESHOLD = 0\n",
        "\n",
        "if PROMPT==pt.zeroshot_prompt_geitje:\n",
        "    NUMBER_EXAMPLES = 0\n",
        "elif PROMPT == pt.fewshot_prompt_no_template:\n",
        "    NUMBER_EXAMPLES = 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load model - In-context learning\n",
        "Note - ONLY load one model: either in-context or fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_geitje = pipeline(task='conversational', model='Rijgersberg/GEITje-7B-chat-v2',\n",
        "                    device_map='cpu', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "MODEL_NAME = 'GEITje-7B-chat-v2'\n",
        "SUBFOLDER = 'in_context'\n",
        "SHORT_ID = 'IC'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load model - Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_geitje = pipeline(task='conversational', model='FemkeBakker/AmsterdamDocClassificationGEITje200T3Epochs',\n",
        "                   device_map='cpu', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "MODEL_NAME = 'AmsterdamDocClassificationGEITje200T3Epochs'\n",
        "SUBFOLDER = 'finetuning'\n",
        "SHORT_ID = 'FT'\n",
        "EPOCHS = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set-up paths to save predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if SPLIT_COLUMN == '4split' or SPLIT_COLUMN == '2split':\n",
        "    OVERVIEW_PATH = f\"{cf.output_path}/predictionsVal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/overview.pkl\"\n",
        "    PREDICTION_PATH = f\"{cf.output_path}/predictionsVal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/predictions.pkl\"\n",
        "    \n",
        "elif SPLIT_COLUMN == 'balanced_split':\n",
        "    if SUBFOLDER == 'finetuning':\n",
        "        OVERVIEW_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{EPOCHS}epochs/overview.pkl\"\n",
        "        PREDICTION_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{EPOCHS}epochs/{SHORT_MODEL_NAME}First{FRONT_THRESHOLD}Last{BACK_THRESHOLD}Predictions.pkl\"\n",
        "\n",
        "    elif SUBFOLDER == 'in_context':\n",
        "        OVERVIEW_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{SHORT_MODEL_NAME}/overview.pkl\"\n",
        "        PREDICTION_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/First{FRONT_THRESHOLD}Last{BACK_THRESHOLD}Predictions.pkl\"\n",
        "\n",
        "print(OVERVIEW_PATH)\n",
        "print(PREDICTION_PATH)\n",
        "\n",
        "if not os.path.isdir(os.path.dirname(os.path.abspath(OVERVIEW_PATH))):\n",
        "    raise ValueError(\"Folder to OVERVIEW_PATH does not exist\") \n",
        "if not os.path.isdir(os.path.dirname(os.path.abspath(PREDICTION_PATH))):\n",
        "    raise ValueError(\"Folder to PREDICTION_PATH does not exist\") \n",
        "\n",
        "run_id = f'{SHORT_ID}_{MODEL_NAME}{PROMPT_NAME}{TOKENS_COL}{FRONT_THRESHOLD}_{BACK_THRESHOLD}{TRAIN_SET}{TEST_SET}_numEx{NUMBER_EXAMPLES}'\n",
        "print ('\\n', run_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----- EXPERIMENT --------\n",
        "# add new column with truncated text -> new dataframe with column + new column name\n",
        "trunc_df = tf.add_truncation_column(txt,'text', TOKENS_COL, FRONT_THRESHOLD, BACK_THRESHOLD)\n",
        "\n",
        "\n",
        "# if new run MAKE SURE RUN_ID IS UNIQUE, if want to resume run, pass in that run_id\n",
        "run_experiment(chatbot_geitje, trunc_df, run_id, PROMPT, TEXT_COLUMN, SPLIT_COLUMN, TRAIN_SET, TEST_SET, LABEL_COLUMN, PREDICTION_PATH, OVERVIEW_PATH, MODEL_NAME, NUMBER_EXAMPLES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = pd.read_pickle(OVERVIEW_PATH)\n",
        "# pred_run = pred.loc[pred['run_id']==f'{PROMPT_NAME}{TOKENS_COL}{FRONT_THRESHOLD}_{BACK_THRESHOLD}']\n",
        "display(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Llama\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "SHORT_MODEL_NAME = 'Llama'\n",
        "PROMPT = pt.fewshot_prompt_with_template\n",
        "PROMPT_NAME = ph.get_promptfunction_name(PROMPT)\n",
        "TOKENS_COL = 'LlamaTokens' # column with text split using tokenizer of either mistral (MistralTokens) or Llama (LlamaTokens). Using Llama, because Llama split into more tokens. \n",
        "FRONT_THRESHOLD = 200\n",
        "BACK_THRESHOLD = 0\n",
        "\n",
        "if PROMPT==pt.zeroshot_prompt_mistral_llama:\n",
        "    NUMBER_EXAMPLES = 0\n",
        "elif PROMPT == pt.fewshot_prompt_with_template or PROMPT == pt.fewshot_prompt_no_template:\n",
        "    NUMBER_EXAMPLES = 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load model - In-context learning\n",
        "Note - ONLY load one model: either in-context or fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c44853d962db404d9fe06a1af602e0a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8839567677e44c1ba085ebc103671cba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_llama = pipeline(task='conversational', model='meta-llama/Llama-2-7b-chat-hf',\n",
        "                   device_map='cpu', model_kwargs={'offload_buffers':True})\n",
        "# load llama using cpu, else will give cuda out of memory error when running fewshot bm25 prompt.\n",
        "\n",
        "MODEL_NAME = 'Llama-2-7b-chat-hf'\n",
        "SUBFOLDER = 'in_context'\n",
        "SHORT_ID = 'IC'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load model - finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_llama = pipeline(task='conversational', model='FemkeBakker/AmsterdamDocClassificationLlama200T3Epochs',\n",
        "                   device_map='cpu', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "MODEL_NAME = 'AmsterdamDocClassificationLlama200T3Epochs'\n",
        "SUBFOLDER = 'finetuning'\n",
        "SHORT_ID = 'FT'\n",
        "EPOCHS = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set-up paths to save predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/in_context/Llama/overview.pkl\n",
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/in_context/Llama/fewshot_prompt_with_template/First200Last0Predictions.pkl\n",
            "\n",
            " IC_Llama-2-7b-chat-hffewshot_prompt_with_templateLlamaTokens200_0traintest_numEx2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if SPLIT_COLUMN == '4split' or SPLIT_COLUMN == '2split':\n",
        "    OVERVIEW_PATH = f\"{cf.output_path}/predictionsVal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/overview.pkl\"\n",
        "    PREDICTION_PATH = f\"{cf.output_path}/predictionsVal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/predictions.pkl\"\n",
        "    \n",
        "elif SPLIT_COLUMN == 'balanced_split':\n",
        "    if SUBFOLDER == 'finetuning':\n",
        "        OVERVIEW_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{EPOCHS}epochs/overview.pkl\"\n",
        "        PREDICTION_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{EPOCHS}epochs/{SHORT_MODEL_NAME}First{FRONT_THRESHOLD}Last{BACK_THRESHOLD}Predictions.pkl\"\n",
        "\n",
        "    elif SUBFOLDER == 'in_context':\n",
        "        OVERVIEW_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{SHORT_MODEL_NAME}/overview.pkl\"\n",
        "        PREDICTION_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/First{FRONT_THRESHOLD}Last{BACK_THRESHOLD}Predictions.pkl\"\n",
        "\n",
        "print(OVERVIEW_PATH)\n",
        "print(PREDICTION_PATH)\n",
        "\n",
        "if not os.path.isdir(os.path.dirname(os.path.abspath(OVERVIEW_PATH))):\n",
        "    raise ValueError(\"Folder to OVERVIEW_PATH does not exist\") \n",
        "if not os.path.isdir(os.path.dirname(os.path.abspath(PREDICTION_PATH))):\n",
        "    raise ValueError(\"Folder to PREDICTION_PATH does not exist\") \n",
        "\n",
        "run_id = f'{SHORT_ID}_{MODEL_NAME}{PROMPT_NAME}{TOKENS_COL}{FRONT_THRESHOLD}_{BACK_THRESHOLD}{TRAIN_SET}{TEST_SET}_numEx{NUMBER_EXAMPLES}'\n",
        "print ('\\n', run_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run-id already known, resuming predictions...\n",
            "Starting...0:10 out of 30\n",
            "label:  voordracht\n",
            "response:   Sure, I can help you categorize the given document! Based on the content and structure of the document, I would classify it under the category of \"Voordracht\" (Dutch for \"Motion\").\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Voordracht\"\n",
            "}\n",
            "\n",
            "The reason for this categorization is that the document appears to be a motion or a proposal brought before a committee or council, as it contains a formal presentation and a request for consideration and decision-making. The content of the document also aligns with the typical structure of a voordracht, including an introduction, a main argument or proposal, and a request for action or decision.\n",
            "prediction: voordracht\n",
            "label:  onderzoeksrapport\n",
            "response:   Sure, I can help you categorize the document! Based on the examples and the provided categories, I would classify the document as:\n",
            "\n",
            " {'categorie': 'Onderzoeksrapport'}\n",
            "\n",
            "The document appears to be an research report, as it contains a clear structure and organization, including an introduction, methods, results, and conclusion sections. The language used is formal and academic, which is typical of research reports. Additionally, the document includes technical terms and jargon related to the field of ecology and landscape, which further supports the categorization as an research report.\n",
            "prediction: onderzoeksrapport\n",
            "label:  raadsadres\n",
            "response:   Sure, I can help you classify the document. Based on the information provided, I would categorize the document as:\n",
            "\n",
            "{'categorie': 'Raadsadres'}\n",
            "\n",
            "The document appears to be a response to a written question (schriftelijke vraag) from the Amsterdam City Council, and it contains information related to the city's housing policy and the relationship between the city's districts. The document is addressed to the City Council and includes a number of appendices with additional information. Based on these characteristics, I would classify the document as a Raadsadres (City Council address) rather than a Voordracht (speech), Besluit (decision), Schriftelijke Vraag (written question), Brief (letter), Raadsnotulen (council minutes), Agenda (agenda), Motie (motion), Actualiteit (current events), or Factsheet (fact sheet).\n",
            "prediction: raadsadres\n",
            "label:  factsheet\n",
            "response:   Sure, I can help you with that! Based on the provided examples and the content of the document you want to categorize, I would suggest the following categories:\n",
            "\n",
            "Categorize the document: Vervoerregio Amsterdam\n",
            "\n",
            "{\n",
            "\"categorie\": \"Onderzoeksrapport\"\n",
            "}\n",
            "\n",
            "The document appears to be an research report on the ambitions of the Vervoerregio Amsterdam, which aims to achieve cleaner and more sustainable mobility for passengers and inhabitants. The report discusses the challenges and opportunities of achieving this goal, including the development of a neutral mobility system by 2050.\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Onderzoeksrapport\"\n",
            "}\n",
            "prediction: MultiplePredictionErrorInFormatting\n",
            "label:  factsheet\n",
            "response:   Based on the provided examples and the document you want to categorize, I would classify it under the category of \"Factsheet\".\n",
            "\n",
            "Here's the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Factsheet\"\n",
            "}\n",
            "\n",
            "The document provides an overview of the current state of the Amsterdam economy, using a set of indicators to measure its performance. It also includes information on the latest trends and developments, and provides an actueel picture of the economy per day or per week. All of these characteristics are typical of a factsheet, which is a type of document that provides a concise and informative overview of a particular topic or issue.\n",
            "prediction: factsheet\n",
            "label:  raadsnotulen\n",
            "response:   Sure, I can help you classify the document. Based on the information provided, the document can be categorized as a 'Raadsnotulen'.\n",
            "\n",
            "Here is the output in the form of a JSON file:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Raadsnotulen\"\n",
            "}\n",
            "\n",
            "The document is a meeting minutes of a municipal council meeting in Amsterdam, Netherlands, and it contains information about the agenda, decisions, and discussions held during the meeting. The document is a official record of the meeting and is used for historical purposes, as well as for informational and decision-making purposes in the future. Therefore, it fits into the category of 'Raadsnotulen'.\n",
            "prediction: raadsnotulen\n",
            "label:  voordracht\n",
            "response:   Sure! Based on the provided examples and the list of categories, I would categorize the third document, VN2021-013518, as:\n",
            "\n",
            "{'categorie': 'Voordracht'}\n",
            "\n",
            "The document is a speech given to the Raadcommissie voor Sociale Zaken, Armoede en Schuldhulpverlening on June 2, 2021, and it pertains to the portfolio of Volwasseneneducatie, Laaggeletterdheid en Inburgering. The document is a speech, which falls under the category of Voordracht.\n",
            "prediction: voordracht\n",
            "label:  raadsnotulen\n",
            "response:   Sure, I can help you categorize the given document. Based on the provided examples and the content of the document you provided, I would categorize the document as:\n",
            "\n",
            "{'categorie': 'Raadsnotulen'}\n",
            "\n",
            "The document contains a list of council meetings, including the date, time, and location of the meetings, as well as the names of the chairperson and secretary. It also includes a report on the meetings, which is a common feature of council meetings. Therefore, the document can be categorized as a council meeting agenda or minutes, which is a type of raadsnotulen.\n",
            "prediction: raadsnotulen\n",
            "label:  raadsnotulen\n",
            "response:   Sure, I can help you categorize the given document. Based on the content and structure of the document, I would classify it under the category of \"Raadsnotulen\".\n",
            "\n",
            "Here is the output in the form of a JSON file:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Raadsnotulen\"\n",
            "}\n",
            "\n",
            "The reason for this classification is that the document appears to be a meeting minutes of a municipal council, containing information on the decisions made, the discussions held, and the voting results. This type of document is typically used to record the proceedings of a municipal council meeting and is considered an official document.\n",
            "prediction: raadsnotulen\n",
            "label:  raadsadres\n",
            "response:   Sure, I can help you categorize the given document. After analyzing the document, I conclude that it belongs to the category of \"Onderzoeksrapport\".\n",
            "\n",
            "Here's the output in the form of a JSON file:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Onderzoeksrapport\"\n",
            "}\n",
            "\n",
            "The document contains several elements that indicate it is an research report, such as:\n",
            "\n",
            "* The use of formal language and structure, indicating a professional and academic tone.\n",
            "* The presence of tables, charts, and graphs, which are commonly used in research reports to present data and results.\n",
            "* The use of technical terms and jargon related to the field of study, which suggests that the document is written by experts in the field.\n",
            "* The inclusion of a detailed introduction and literature review, which are typical components of a research report.\n",
            "* The use of a clear and structured format, with sections and subsections, which makes it easy to follow the author's argument and find the information they are presenting.\n",
            "\n",
            "Based on these elements, I conclude that the document is an example of an onderzoeksrapport, which is a type of research report that presents the\n",
            "prediction: onderzoeksrapport\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.7824074074074074\n",
            "Starting...10:20 out of 30\n",
            "label:  motie\n",
            "response:   Sure, I can help you categorize the given document. Based on the content and structure of the document, I would classify it under the category of \"Motie\" (Motion).\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Motie\"\n",
            "}\n",
            "\n",
            "The reason for this classification is that the document appears to be a proposal or a motion put forward by a member of the Gemeenteraad (City Council) for discussion and vote. The document contains a formal introduction, the text of the motion, and information on the date and time of the meeting where it will be discussed and voted upon. This is a common structure and format for motions in Dutch municipal governments.\n",
            "prediction: motie\n",
            "label:  agenda\n",
            "response:   Sure! Based on the provided examples and the document you want to categorize, I would categorize it as an \"Agenda\".\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Agenda\"\n",
            "}\n",
            "\n",
            "The document you provided contains a list of items to be discussed during a meeting, including the date, time, location, and participants. This is a common characteristic of an agenda document, which is why I have categorized it as such.\n",
            "prediction: agenda\n",
            "label:  onderzoeksrapport\n",
            "response:   Sure, I can help you classify the document! Based on the information provided, I would categorize the document as:\n",
            "\n",
            "{'categorie': 'Raadsadres'}\n",
            "\n",
            "This document appears to be a letter or memo addressed to the council or mayor of Amsterdam, with a clear purpose of bringing attention to a specific issue or matter. The document contains a detailed explanation of the issue, including background information and a proposed solution, and is written in a formal and professional tone. The language used is clear and concise, and the document includes specific references and citations to support the arguments made. Overall, the document has the characteristics of a formal government document, which is why I would categorize it as a 'Raadsadres'.\n",
            "prediction: raadsadres\n",
            "label:  brief\n",
            "response:   Sure! Based on the provided examples and the given categories, I would categorize the third document as:\n",
            "\n",
            "{ \"categorie\": \"Brief\" }\n",
            "\n",
            "The document appears to be a brief communication from the City of Amsterdam's CTO Innovation Team to the members of the city council, informing them about the development of a policy framework for participatory democracy. The document provides some context and background information on the topic, and includes a quote from Hannah Arendt's book \"On Revolution\" to emphasize the importance of public participation in democratic decision-making. Based on these characteristics, I would classify the document as a brief.\n",
            "prediction: brief\n",
            "label:  voordracht\n",
            "response:   Sure, I can help you with that! Based on the information provided, I would categorize the document VN2022-018470 as follows:\n",
            "\n",
            " {'categorie': 'Voordracht'}\n",
            "\n",
            "The document is a speech given to the Temporary General Council of Amsterdam on June 30, 2022, and it falls under the category of \"Voordracht\" (Dutch for \"Speech\") because it contains a speech or presentation given to a council or assembly.\n",
            "prediction: voordracht\n",
            "label:  agenda\n",
            "response:   Sure, I can help you categorize the document! Based on the content provided, I would categorize the document as:\n",
            "\n",
            "{'categorie': 'Agenda'}\n",
            "\n",
            "This document is an agenda for a meeting of the Stadsdeelcommissie, which includes the date, time, location, and items to be discussed. The document is formatted in a structured manner, with clear headings and subheadings, indicating that it is a formal document. The content is related to the meeting's agenda, including opening and closing remarks, reports, and updates from the committee members and external stakeholders. Therefore, the category of 'Agenda' is the most appropriate for this document.\n",
            "prediction: agenda\n",
            "label:  besluit\n",
            "response:   Sure, I can help you categorize the document! Based on the provided information, I would categorize the document as a \"Besluit\" (Dutch for \"Decision\").\n",
            "\n",
            "Here is the output in the form of a JSON file:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Besluit\"\n",
            "}\n",
            "\n",
            "The reason for this categorization is that the document appears to be a formal decision made by the council of the municipality of Amsterdam, outlining changes to the Algemene Plaatselijke Verordening (APV) regarding the implementation of a meldingsplicht (mandatory reporting) for sensors. The document includes details on the reasons for the decision, the implications for the functioning of the Nvt., and external informative annex for the Nvt. It also includes a formal approval process and is signed by the council. All of these elements suggest that the document is a formal decision or resolution, which is the definition of a Besluit in Dutch law.\n",
            "prediction: besluit\n",
            "label:  raadsnotulen\n",
            "response:   Sure, I can help you categorize the given document. Based on the information provided, the document can be categorized as:\n",
            "\n",
            "{'categorie': 'Raadsnotulen'}\n",
            "\n",
            "Here's why:\n",
            "\n",
            "The document is a meeting minutes of a municipal council, specifically the Gemeente Amsterdam council. It includes information about the council members present, the agenda items discussed, and the decisions made during the meeting. All of these elements are typical of a municipal council meeting and are therefore classified as Raadsnotulen (Dutch for \"Council Minutes\").\n",
            "prediction: raadsnotulen\n",
            "label:  onderzoeksrapport\n",
            "response:   Sure, I can help you classify the given document into one of the categories. After reviewing the document, I suggest it belongs to the category of \"Onderzoeksrapport\".\n",
            "\n",
            "Here's the output in the form of a JSON file:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Onderzoeksrapport\"\n",
            "}\n",
            "\n",
            "The reasons for this classification are:\n",
            "\n",
            "1. The document is an analysis of the current situation and future trends in the field of healthcare, which is a common topic in onderzoeksrapports.\n",
            "2. The document includes sections on internal and external analysis, prognosis, and recommendations, which are all typical elements of an onderzoeksrapport.\n",
            "3. The language used in the document is formal and professional, which is typical of academic and research reports.\n",
            "\n",
            "I hope this helps! Let me know if you have any other questions.\n",
            "prediction: onderzoeksrapport\n",
            "label:  voordracht\n",
            "response:   Sure, I can help you with that! Based on the provided examples and the document that needs to be categorized, I would categorize the document VN2022-018989 as follows:\n",
            "\n",
            " {'categorie': 'Voordracht'}\n",
            "\n",
            "Here's why:\n",
            "\n",
            "The document VN2022-018989 is a voordracht (a presentation or proposal) for the Tijdelijke Algemene Raadscommissie (TAR) of the City of Amsterdam. The document provides an overview of the current state of public space in Amsterdam, including the availability and accessibility of public spaces, and presents a proposal for the future of public space in the city.\n",
            "\n",
            "The document contains elements of a voordracht, such as a presentation of the problem, a proposal for solution, and a call to action. The document is also addressed to the TAR, which is a committee of the City Council responsible for advising on matters related to public space.\n",
            "\n",
            "Based on these features, I would categorize the document as a voordracht.\n",
            "prediction: voordracht\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.7834862385321101\n",
            "Starting...last 10 docs\n",
            "label:  besluit\n",
            "response:   Sure, I can help you categorize the document \"Gemeente Bezoekadres\". Based on the examples provided and the content of the document, I would categorize it as a \"Besluit\".\n",
            "\n",
            "Here is the output in the form of a JSON file:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Besluit\"\n",
            "}\n",
            "\n",
            "The reason for this categorization is that the document contains a decision or a resolution made by the Bestuurscommissie of the stadsdeel Nieuw-West. The document includes information about the meeting date, time, and agenda item, as well as the decision made by the committee. This is consistent with the definition of a \"Besluit\" in the provided categories.\n",
            "prediction: besluit\n",
            "label:  motie\n",
            "response:   Sure, I can help you categorize the document. Based on the information provided, I would classify the document as a 'Motie'.\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Motie\"\n",
            "}\n",
            "\n",
            "The reason for this classification is that the document appears to be a motion put forward by a member of the council, as it contains a proposal for a decision or action by the council. The document includes the name of the member who put forward the motion, the date of the meeting, and the subject matter of the motion. This is consistent with the definition of a motie, which is a proposal made by a member of a council or assembly for a decision or action by the body.\n",
            "prediction: motie\n",
            "label:  brief\n",
            "response:   Sure, I can help you classify the given document. Based on the content and structure, I would categorize it as a \"Brief\".\n",
            "\n",
            "Here is the output in the form of a JSON file:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Brief\"\n",
            "}\n",
            "\n",
            "The reason for this categorization is that the document appears to be a formal communication from the municipality of Amsterdam to its council members, providing them with information about the evaluation and follow-up of a specific project related to education. The document includes the name of the portfolio holder and the date of the communication, as well as a brief summary of the project and its outcome.\n",
            "\n",
            "The format and tone of the document are also consistent with a brief, which is a common form of communication in business and government contexts. Briefs are typically used to provide a concise and informative summary of a topic or issue, and are often used to inform decision-making or to communicate policy decisions.\n",
            "\n",
            "I hope this helps! Let me know if you have any further questions.\n",
            "prediction: brief\n",
            "label:  voordracht\n",
            "response:   Sure, I can help you classify the document! Based on the information provided, here is the output in the form of a JSON file:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Voordracht\"\n",
            "}\n",
            "\n",
            "The document VN2021-012764 N Gemeente Raadscommissie voor Sociale Zaken, Armoede en Schuldhulpverlening, WI O is a speech given to the Commissie WIO of June 2, 2021, for the purpose of knowledge sharing. Therefore, the category of this document is \"Voordracht\".\n",
            "prediction: voordracht\n",
            "label:  schriftelijke vraag\n",
            "response:   Output: {'categorie': 'Schriftelijke Vraag'}\n",
            "\n",
            "De document you provided is a written inquiry, specifically a question from the Amsterdam City Council to the Education Directorate regarding the coronavirus and the start of the new school year. The document contains questions and requests for information from the council, and is therefore categorized as a written inquiry.\n",
            "prediction: schriftelijke vraag\n",
            "label:  agenda\n",
            "response:   Sure, I can help you classify the document! Based on the content you provided, I would categorize the document as:\n",
            "\n",
            "{'categorie': 'Agenda'}\n",
            "\n",
            "The document contains a notice of a municipal council meeting, including the date, time, location, and agenda items. This is a common format for agendas, and the document is clearly intended to inform the council members and the public about the topics that will be discussed and decided upon at the meeting. Therefore, the most appropriate category for this document is \"Agenda\".\n",
            "prediction: agenda\n",
            "label:  voordracht\n",
            "response:   Based on the provided examples and the list of categories, I would categorize the third document, VN2021-032800 issi, as a 'Voordracht'.\n",
            "\n",
            "Here is the output in JSON format:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Voordracht\"\n",
            "}\n",
            "\n",
            "Explanation:\n",
            "\n",
            "The document VN2021-032800 issi is a presentation or speech given to the Raadscommissie voor Kunst en Cultuur Monumenten en Erfgoed, KDD, on January 12, 2022. The document contains information about the committee's agenda, including a discussion on the city's diversity and antidiscrimination policy, democratization, and municipal affairs. Based on the content of the document, it appears to be a preparatory document for a meeting or presentation, which is consistent with the definition of a 'Voordracht'.\n",
            "prediction: voordracht\n",
            "label:  agenda\n",
            "response:   Sure! Based on the provided examples and the content of the document you want to categorize, I would classify it as follows:\n",
            "\n",
            "{ 'categorie': 'Agenda' }\n",
            "\n",
            "The document contains the agenda for a meeting of the Public Commission of the Amsterdam city council, with topics including the opening and establishment of the agenda, updates on current affairs, and a presentation on residential noise. All of these elements are consistent with the category of \"Agenda\".\n",
            "prediction: agenda\n",
            "label:  raadsadres\n",
            "response:   Sure, I can help you classify the given document. After analyzing the content of the document, I would categorize it as a 'Raadsadres' (Council Address).\n",
            "\n",
            "Here is the output in the form of a JSON file:\n",
            "\n",
            "{\n",
            "\"categorie\": \"Raadsadres\"\n",
            "}\n",
            "\n",
            "The document is an address to the council, specifically the Gemeenteraad of Amsterdam, and it contains information about the importance of preserving historical ships as part of Amsterdam's cultural heritage. The document also provides a request for the council's attention to this matter and suggests possible solutions for preserving the varend erfgoed (naval heritage) of Amsterdam.\n",
            "\n",
            "The term 'Raadsadres' refers to a document that is written to the council or a government agency, and it is typically used to provide information, make a request, or express an opinion on a particular issue. In this case, the document is an appeal to the council to take action to preserve Amsterdam's historical ships.\n",
            "prediction: raadsadres\n",
            "label:  raadsnotulen\n",
            "response:   Sure! Based on the provided examples and the document you want to categorize, I would classify it as:\n",
            "\n",
            "{'categorie': 'Raadsnotulen'}\n",
            "\n",
            "Here's why:\n",
            "\n",
            "The document you provided is a meeting minutes of a municipal council meeting in Amsterdam, Netherlands. It includes the agenda, the names of the present council members, the raadgriffier (clerk), and the verslaglegger (reporter). The document also mentions the date, time, and location of the meeting, as well as any problems or issues that were discussed.\n",
            "\n",
            "All of these elements are typical of a municipal council meeting, and therefore, the document can be classified as a 'Raadsnotulen' (Dutch for 'Council Minutes').\n",
            "prediction: raadsnotulen\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Accuracy:  0.7854545454545454\n"
          ]
        }
      ],
      "source": [
        "# add new column with truncated text -> new dataframe with column + new column name\n",
        "trunc_df = tf.add_truncation_column(txt,'text', TOKENS_COL, FRONT_THRESHOLD, BACK_THRESHOLD)\n",
        "\n",
        "# if new run MAKE SURE RUN_ID IS UNIQUE, if want to resume run, pass in that run_id\n",
        "run_experiment(chatbot_llama, trunc_df, run_id, PROMPT, TEXT_COLUMN, SPLIT_COLUMN, TRAIN_SET, TEST_SET, LABEL_COLUMN, PREDICTION_PATH, OVERVIEW_PATH, MODEL_NAME, NUMBER_EXAMPLES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>run_id</th>\n",
              "      <th>date</th>\n",
              "      <th>train_set</th>\n",
              "      <th>test_set</th>\n",
              "      <th>train_set_support</th>\n",
              "      <th>test_set_support</th>\n",
              "      <th>split_col</th>\n",
              "      <th>text_col</th>\n",
              "      <th>runtime</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro_avg_precision</th>\n",
              "      <th>macro_avg_recall</th>\n",
              "      <th>macro_avg_f1</th>\n",
              "      <th>classification_report</th>\n",
              "      <th>weighted_avg_precision</th>\n",
              "      <th>weighted_avg_recall</th>\n",
              "      <th>weighted_avg_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>IC_Llama-2-7b-chat-hfzeroshot_prompt_mistral_l...</td>\n",
              "      <td>2024-05-22 21:29:48.627017+02:00</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront100Back0</td>\n",
              "      <td>140223.734147</td>\n",
              "      <td>0.422727</td>\n",
              "      <td>0.491578</td>\n",
              "      <td>0.310000</td>\n",
              "      <td>0.287423</td>\n",
              "      <td>precision...</td>\n",
              "      <td>0.670333</td>\n",
              "      <td>0.422727</td>\n",
              "      <td>0.391940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>IC_Llama-2-7b-chat-hfzeroshot_prompt_mistral_l...</td>\n",
              "      <td>2024-05-27 17:53:30.065278+02:00</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront100Back100</td>\n",
              "      <td>164152.727557</td>\n",
              "      <td>0.425455</td>\n",
              "      <td>0.543238</td>\n",
              "      <td>0.334286</td>\n",
              "      <td>0.321521</td>\n",
              "      <td>precision    ...</td>\n",
              "      <td>0.691394</td>\n",
              "      <td>0.425455</td>\n",
              "      <td>0.409208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>IC_Llama-2-7b-chat-hfzeroshot_prompt_mistral_l...</td>\n",
              "      <td>2024-05-26 21:20:27.966620+02:00</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront200Back0</td>\n",
              "      <td>132040.014386</td>\n",
              "      <td>0.474545</td>\n",
              "      <td>0.537874</td>\n",
              "      <td>0.372857</td>\n",
              "      <td>0.349950</td>\n",
              "      <td>precision    ...</td>\n",
              "      <td>0.684567</td>\n",
              "      <td>0.474545</td>\n",
              "      <td>0.445390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>IC_Llama-2-7b-chat-hffewshot_prompt_with_templ...</td>\n",
              "      <td>2024-06-08 15:54:40.157839+02:00</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront200Back0</td>\n",
              "      <td>250904.835556</td>\n",
              "      <td>0.785455</td>\n",
              "      <td>0.697680</td>\n",
              "      <td>0.617143</td>\n",
              "      <td>0.641036</td>\n",
              "      <td>precision...</td>\n",
              "      <td>0.887956</td>\n",
              "      <td>0.785455</td>\n",
              "      <td>0.815864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                model                                             run_id  \\\n",
              "0  Llama-2-7b-chat-hf  IC_Llama-2-7b-chat-hfzeroshot_prompt_mistral_l...   \n",
              "0  Llama-2-7b-chat-hf  IC_Llama-2-7b-chat-hfzeroshot_prompt_mistral_l...   \n",
              "0  Llama-2-7b-chat-hf  IC_Llama-2-7b-chat-hfzeroshot_prompt_mistral_l...   \n",
              "0  Llama-2-7b-chat-hf  IC_Llama-2-7b-chat-hffewshot_prompt_with_templ...   \n",
              "\n",
              "                              date train_set test_set  train_set_support  \\\n",
              "0 2024-05-22 21:29:48.627017+02:00     train     test               9900   \n",
              "0 2024-05-27 17:53:30.065278+02:00     train     test               9900   \n",
              "0 2024-05-26 21:20:27.966620+02:00     train     test               9900   \n",
              "0 2024-06-08 15:54:40.157839+02:00     train     test               9900   \n",
              "\n",
              "   test_set_support       split_col                              text_col  \\\n",
              "0              1100  balanced_split    TruncationLlamaTokensFront100Back0   \n",
              "0              1100  balanced_split  TruncationLlamaTokensFront100Back100   \n",
              "0              1100  balanced_split    TruncationLlamaTokensFront200Back0   \n",
              "0              1100  balanced_split    TruncationLlamaTokensFront200Back0   \n",
              "\n",
              "         runtime  accuracy  macro_avg_precision  macro_avg_recall  \\\n",
              "0  140223.734147  0.422727             0.491578          0.310000   \n",
              "0  164152.727557  0.425455             0.543238          0.334286   \n",
              "0  132040.014386  0.474545             0.537874          0.372857   \n",
              "0  250904.835556  0.785455             0.697680          0.617143   \n",
              "\n",
              "   macro_avg_f1                              classification_report  \\\n",
              "0      0.287423                                       precision...   \n",
              "0      0.321521                                   precision    ...   \n",
              "0      0.349950                                   precision    ...   \n",
              "0      0.641036                                       precision...   \n",
              "\n",
              "   weighted_avg_precision  weighted_avg_recall  weighted_avg_f1  \n",
              "0                0.670333             0.422727         0.391940  \n",
              "0                0.691394             0.425455         0.409208  \n",
              "0                0.684567             0.474545         0.445390  \n",
              "0                0.887956             0.785455         0.815864  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pred = pd.read_pickle(OVERVIEW_PATH)\n",
        "display(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mistral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SHORT_MODEL_NAME = 'Mistral'\n",
        "PROMPT = pt.zeroshot_prompt_mistral_llama\n",
        "PROMPT_NAME = ph.get_promptfunction_name(PROMPT)\n",
        "TOKENS_COL = 'LlamaTokens' # column with text split using tokenizer of either mistral (MistralTokens) or Llama (LlamaTokens). Using Llama, because Llama split into more tokens. \n",
        "FRONT_THRESHOLD = 200\n",
        "BACK_THRESHOLD = 0\n",
        "\n",
        "if PROMPT==pt.zeroshot_prompt_mistral_llama:\n",
        "    NUMBER_EXAMPLES = 0\n",
        "elif PROMPT == pt.fewshot_prompt_bm25:\n",
        "    NUMBER_EXAMPLES = 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load model - In-context learning\n",
        "Note - ONLY load one model: either in-context or fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_mistral = pipeline(task='conversational', model='mistralai/Mistral-7B-Instruct-v0.2',\n",
        "                   device_map='cpu', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "MODEL_NAME = 'Mistral-7B-Instruct-v0.2'\n",
        "SUBFOLDER = 'in_context'\n",
        "SHORT_ID = 'IC'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load model - finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_mistral = pipeline(task='conversational', model='FemkeBakker/AmsterdamDocClassificationMistral200T3Epochs',\n",
        "                   device_map='cpu', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "MODEL_NAME = 'AmsterdamDocClassificationMistral200T3Epochs'\n",
        "SUBFOLDER = 'finetuning'\n",
        "SHORT_ID = 'FT'\n",
        "EPOCHS = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set-up paths to save predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if SPLIT_COLUMN == '4split' or SPLIT_COLUMN == '2split':\n",
        "    OVERVIEW_PATH = f\"{cf.output_path}/predictionsVal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/overview.pkl\"\n",
        "    PREDICTION_PATH = f\"{cf.output_path}/predictionsVal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/predictions.pkl\"\n",
        "    \n",
        "elif SPLIT_COLUMN == 'balanced_split':\n",
        "    if SUBFOLDER == 'finetuning':\n",
        "        OVERVIEW_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{EPOCHS}epochs/overview.pkl\"\n",
        "        PREDICTION_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{EPOCHS}epochs/{SHORT_MODEL_NAME}First{FRONT_THRESHOLD}Last{BACK_THRESHOLD}Predictions.pkl\"\n",
        "\n",
        "    elif SUBFOLDER == 'in_context':\n",
        "        OVERVIEW_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{SHORT_MODEL_NAME}/overview.pkl\"\n",
        "        PREDICTION_PATH = f\"{cf.output_path}/predictionsFinal/{SUBFOLDER}/{SHORT_MODEL_NAME}/{PROMPT_NAME}/First{FRONT_THRESHOLD}Last{BACK_THRESHOLD}Predictions.pkl\"\n",
        "\n",
        "print(OVERVIEW_PATH)\n",
        "print(PREDICTION_PATH)\n",
        "\n",
        "if not os.path.isdir(os.path.dirname(os.path.abspath(OVERVIEW_PATH))):\n",
        "    raise ValueError(\"Folder to OVERVIEW_PATH does not exist\") \n",
        "if not os.path.isdir(os.path.dirname(os.path.abspath(PREDICTION_PATH))):\n",
        "    raise ValueError(\"Folder to PREDICTION_PATH does not exist\") \n",
        "\n",
        "run_id = f'{SHORT_ID}_{MODEL_NAME}{PROMPT_NAME}{TOKENS_COL}{FRONT_THRESHOLD}_{BACK_THRESHOLD}{TRAIN_SET}{TEST_SET}_numEx{NUMBER_EXAMPLES}'\n",
        "print ('\\n', run_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run experiment\n",
        "\n",
        "# add new column with truncated text -> new dataframe with column + new column name\n",
        "trunc_df = tf.add_truncation_column(txt,'text', TOKENS_COL, FRONT_THRESHOLD, BACK_THRESHOLD)\n",
        "\n",
        "# if new run MAKE SURE RUN_ID IS UNIQUE, if want to resume run, pass in that run_id\n",
        "run_experiment(chatbot_mistral, trunc_df, run_id, PROMPT, TEXT_COLUMN, SPLIT_COLUMN, TRAIN_SET, TEST_SET, LABEL_COLUMN, PREDICTION_PATH, OVERVIEW_PATH, MODEL_NAME, NUMBER_EXAMPLES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = pd.read_pickle(OVERVIEW_PATH)\n",
        "display(pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "amsterdamincontextlearning"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.-1"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "nl"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
