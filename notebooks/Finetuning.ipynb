{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash /home/azureuser/cloudfiles/code/blobfuse/blobfuse_raadsinformatie.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Select where to run notebook: \"azure\" or \"local\"\n",
    "my_run = \"azure\"\n",
    "\n",
    "# import my_secrets as sc\n",
    "import settings as st\n",
    "\n",
    "if my_run == \"azure\":\n",
    "    import config_azure as cf\n",
    "elif my_run == \"local\":\n",
    "    import config as cf\n",
    "\n",
    "\n",
    "import os\n",
    "if my_run == \"azure\":\n",
    "    if not os.path.exists(cf.HUGGING_CACHE):\n",
    "        os.mkdir(cf.HUGGING_CACHE)\n",
    "    os.environ[\"TRANSFORMERS_CACHE\"] = cf.HUGGING_CACHE\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# setup environment GEITje-7B Finetuning\n",
    "# - pip install torch\n",
    "# - pip install datasets\n",
    "# - pip install transformers\n",
    "# - pip install trl\n",
    "# - pip install accelerate (restart after)\n",
    "# - switch device_map='auto' to avaoid memory error\n",
    "\n",
    "# - pip install sentencepiece\n",
    "# - pip install jupyter\n",
    "# - pip install protobuf \n",
    "# pip install bitsandbytes\n",
    "# pip install bnb\n",
    "# pip install wandb==0.13.3 --upgrade\n",
    "#pip install tensorboardX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35db5c6dea74e9eafb4a2024aaaf803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning GEITje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GEITje formatted data\n",
    "from datasets import load_dataset\n",
    "chat_dataset = load_dataset('FemkeBakker/AmsterdamBalancedFirst200Tokens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d946414a630b4d58be82bf0aa3b9a0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521baad220d14418b5baf7635dc3a6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "basemodel_name = 'Rijgersberg/GEITje-7B-chat-v2'\n",
    "# basemodel_name = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "# basemodel_name = \"stabilityai/stablelm-2-1_6b\"\n",
    "# basemodel_name = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "model = AutoModelForCausalLM.from_pretrained(basemodel_name, torch_dtype=torch.bfloat16,\n",
    "                                                low_cpu_mem_usage=True, attn_implementation=\"sdpa\",\n",
    "                                                device_map='cpu')\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(basemodel_name)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "model.config.pad_token_id = tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Classificeer het document in één van de categoriën. Categoriën: ['Voordracht', 'Besluit', 'Schriftelijke Vraag', 'Brief', 'Raadsadres', 'Onderzoeksrapport', 'Raadsnotulen', 'Agenda', 'Motie', 'Actualiteit', 'Factsheet']. Categoriseer dit document: > Gemeente\n",
      "Amsterdam\n",
      "Motie\n",
      "Datum raadsvergadering 19 juli 2023\n",
      "Ingekomen onder nummer 456\n",
      "Status Aangenomen\n",
      "Onderwerp Motie van de leden Van Pijpen, Runderkamp, Alberts, Wehkamp,\n",
      "Kabamba en Krom inzake een grote schoonmaak voor iedereen op de\n",
      "wachtlijst Hulp bij Huishouden\n",
      "Onderwerp\n",
      "Een grote schoonmaak voor iedereen op de wachtlijst Hulp bij het Huishouden\n",
      "Aan de gemeenteraad\n",
      "Ondergetekenden hebben de eer voor te stellen:\n",
      "De Raad,\n",
      "Gehoord de discussie over Plan van Aanpak Wachtlijsten Hulp bij het Huishouden\n",
      "Constaterende dat:\n",
      "e \n",
      "Geef de output in de vorm van een JSON file: {'categorie': categorie van het document}. </s>\n",
      "<|assistant|>\n",
      "{'categorie': Motie}</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# geitje base\n",
    "print(tokenizer.apply_chat_template(chat_dataset['train']['message'][0], tokenize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Classificeer het document in één van de categoriën. Categoriën: ['Voordracht', 'Besluit', 'Schriftelijke Vraag', 'Brief', 'Raadsadres', 'Onderzoeksrapport', 'Raadsnotulen', 'Agenda', 'Motie', 'Actualiteit', 'Factsheet']. Categoriseer dit document: > Gemeente\n",
      "Amsterdam\n",
      "Motie\n",
      "Datum raadsvergadering 19 juli 2023\n",
      "Ingekomen onder nummer 456\n",
      "Status Aangenomen\n",
      "Onderwerp Motie van de leden Van Pijpen, Runderkamp, Alberts, Wehkamp,\n",
      "Kabamba en Krom inzake een grote schoonmaak voor iedereen op de\n",
      "wachtlijst Hulp bij Huishouden\n",
      "Onderwerp\n",
      "Een grote schoonmaak voor iedereen op de wachtlijst Hulp bij het Huishouden\n",
      "Aan de gemeenteraad\n",
      "Ondergetekenden hebben de eer voor te stellen:\n",
      "De Raad,\n",
      "Gehoord de discussie over Plan van Aanpak Wachtlijsten Hulp bij het Huishouden\n",
      "Constaterende dat:\n",
      "e \n",
      "Geef de output in de vorm van een JSON file: {'categorie': categorie van het document}. [/INST] {'categorie': Motie} </s>\n"
     ]
    }
   ],
   "source": [
    "# llama\n",
    "print(tokenizer.apply_chat_template(chat_dataset['train']['message'][0], tokenize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Classificeer het document in één van de categoriën. Categoriën: ['Voordracht', 'Besluit', 'Schriftelijke Vraag', 'Brief', 'Raadsadres', 'Onderzoeksrapport', 'Raadsnotulen', 'Agenda', 'Motie', 'Actualiteit', 'Factsheet']. Categoriseer dit document: > Gemeente\n",
      "Amsterdam\n",
      "Motie\n",
      "Datum raadsvergadering 19 juli 2023\n",
      "Ingekomen onder nummer 456\n",
      "Status Aangenomen\n",
      "Onderwerp Motie van de leden Van Pijpen, Runderkamp, Alberts, Wehkamp,\n",
      "Kabamba en Krom inzake een grote schoonmaak voor iedereen op de\n",
      "wachtlijst Hulp bij Huishouden\n",
      "Onderwerp\n",
      "Een grote schoonmaak voor iedereen op de wachtlijst Hulp bij het Huishouden\n",
      "Aan de gemeenteraad\n",
      "Ondergetekenden hebben de eer voor te stellen:\n",
      "De Raad,\n",
      "Gehoord de discussie over Plan van Aanpak Wachtlijsten Hulp bij het Huishouden\n",
      "Constaterende dat:\n",
      "e \n",
      "Geef de output in de vorm van een JSON file: {'categorie': categorie van het document}. </s>\n",
      "<|assistant|>\n",
      "{'categorie': Motie}</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# geitje chat\n",
    "print(tokenizer.apply_chat_template(chat_dataset['train']['message'][0], tokenize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def combine_and_save_df(model_df, save_to_path):\n",
    "    \n",
    "    # combine with earlier runs if exists\n",
    "    if os.path.exists(save_to_path):\n",
    "        original = pd.read_pickle(save_to_path)\n",
    "        model_df = pd.concat([original, model_df])\n",
    "\n",
    "    model_df.to_pickle(save_to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import DatasetDict, load_dataset, concatenate_datasets\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../scripts/') \n",
    "import prediction_helperfunctions as ph\n",
    "\n",
    "def train(model, model_name, tokenizer, chat_dataset, chat_dataset_name, new_model_name, train_set, test_set, run_id='No_id', save_to_hub=True, resume=False):\n",
    "    start_time = time.time()\n",
    "    def format(examples):\n",
    "        return [tokenizer.apply_chat_template(conversation, tokenize=False)\n",
    "                for conversation in examples['message']]\n",
    "\n",
    "    per_device_train_batch_size = 2\n",
    "    gradient_accumulation_steps = 8\n",
    "    steps_per_epoch = len(chat_dataset[train_set])\\\n",
    "                // (torch.cuda.device_count() * per_device_train_batch_size * gradient_accumulation_steps)\n",
    "    eval_steps = steps_per_epoch // 5\n",
    "\n",
    "    output_directory = f'{cf.output_path}/finetuning_output/1epochs/AmsterdamDocClassificationMistral200T1Epochs'\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        optim='adamw_bnb_8bit',\n",
    "        num_train_epochs=3,\n",
    "        learning_rate=1e-5,\n",
    "        lr_scheduler_type='cosine',\n",
    "        warmup_ratio=0.1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=8,\n",
    "        gradient_checkpointing=True,\n",
    "        evaluation_strategy='steps',\n",
    "        eval_steps=eval_steps,\n",
    "        save_strategy='epoch',\n",
    "        bf16=False, #bf16=True require CUDA 11 -> original code bf16=True\n",
    "        output_dir=output_directory,\n",
    "        report_to=[\"tensorboard\", 'wandb'],\n",
    "        logging_steps=1,\n",
    "        logging_first_step=True,\n",
    "        hub_model_id=new_model_name,\n",
    "        push_to_hub=True,\n",
    "        hub_private_repo=True,\n",
    "        hub_strategy='all_checkpoints',\n",
    "    )\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=8192,\n",
    "        train_dataset=chat_dataset[train_set],\n",
    "        eval_dataset=chat_dataset[test_set],\n",
    "        formatting_func=format,\n",
    "        neftune_noise_alpha=5,\n",
    "    )\n",
    "\n",
    "  \n",
    "    dict_info = {\n",
    "        'model':new_model_name,\n",
    "        'base_model':model_name,\n",
    "        'chat_dataset':chat_dataset_name,\n",
    "        'train_set':train_set,\n",
    "        'test_set': test_set,\n",
    "        'training_args': training_args,\n",
    "        'resume_from_checkpoint':resume,\n",
    "        'date':ph.get_datetime(),\n",
    "        'runtime': False,\n",
    "        'Error': False,\n",
    "        'run_id':run_id,\n",
    "        'save_to_hub':save_to_hub,\n",
    "        'output_dir': output_directory\n",
    "        }\n",
    "\n",
    "    data = pd.DataFrame(columns=dict_info.keys())\n",
    "\n",
    "    # trainer.train(resume_from_checkpoint=resume)\n",
    "    # if save_to_hub == True:\n",
    "    #     trainer.push_to_hub()\n",
    "    # return trainer\n",
    "\n",
    "    try:\n",
    "        trainer.train(resume_from_checkpoint=resume)\n",
    "        if save_to_hub == True:\n",
    "            trainer.push_to_hub()\n",
    "            \n",
    "        dict_info['runtime'] = time.time()-start_time\n",
    "\n",
    "        data.loc[len(data)] = dict_info\n",
    "        combine_and_save_df(data, f'{cf.output_path}/overview_models.pkl')\n",
    "        print(\"Finished without error!\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        dict_info['Error'] = 'KeyboardInterrupt'        \n",
    "        dict_info['runtime'] = time.time()-start_time\n",
    "\n",
    "        data.loc[len(data)] = dict_info\n",
    "        combine_and_save_df(data, f'{cf.output_path}/overview_models.pkl')\n",
    "\n",
    "    except Exception  as e:\n",
    "        print(e)\n",
    "        dict_info['Error'] = e\n",
    "        dict_info['runtime'] = time.time()-start_time\n",
    "\n",
    "        data.loc[len(data)] = dict_info\n",
    "        combine_and_save_df(data, f'{cf.output_path}/overview_models.pkl')\n",
    "\n",
    "\n",
    "        model_df = pd.DataFrame(dict_info)\n",
    "        combine_and_save_df(model_df, f'{cf.output_path}/overview_models.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note\n",
    "resume_from_checkpoitn, gives error if last epoch was not fully run, because then files are missing but the folder exists, thus it throws an error. Removing the last checkpoint folder solves this, does mean the epoch need to restart completely. If this is a viable solution  depends on how long an epoch takes to train. Might be quite long. However if all files are in folder then it is fine. How long does it take before all files are saved in folder? Does this need the epoch to be completed?\n",
    "\n",
    "\n",
    "MAKE SURE: no previous checkpints of runs unrelated to current run are in output folder!!\n",
    "\n",
    "MAKE SURE: run_id is unique, for each seperate run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:257: UserWarning: You passed a `neftune_noise_alpha` argument to the SFTTrainer, the value you passed will override the one in the `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfemkebakker\u001b[0m (\u001b[33mthesisamsterdam\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/batch/tasks/shared/LS_root/mounts/clusters/femke-gpu-24cores-220ram/code/Users/f.bakker/document-classification-using-large-language-models/notebooks/wandb/run-20240603_104041-dqrlsto9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/thesisamsterdam/huggingface/runs/dqrlsto9\" target=\"_blank\">/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationGEITje200T3Epochs</a></strong> to <a href=\"https://wandb.ai/thesisamsterdam/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1854' max='1854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1854/1854 33:29, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1353</td>\n",
       "      <td>0.608100</td>\n",
       "      <td>0.588623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1476</td>\n",
       "      <td>0.291100</td>\n",
       "      <td>0.586250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599</td>\n",
       "      <td>0.369100</td>\n",
       "      <td>0.585314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1722</td>\n",
       "      <td>0.623400</td>\n",
       "      <td>0.585330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1845</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.585360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8073b8355df467ab069acdc831affa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f2f72b4ab14b20abd9db1df25d884b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4356e7c02746f989414cc1cabbb3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b44c0c612a4b6badfbc5876edd2a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished without error!\n"
     ]
    }
   ],
   "source": [
    "train(model, basemodel_name, tokenizer, chat_dataset, 'FemkeBakker/AmsterdamBalancedFirst200Tokens',\n",
    "          'FemkeBakker/AmsterdamDocClassificationMistral200T1Epochs', 'train', 'val',  run_id=25, save_to_hub=True, resume=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "260 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>base_model</th>\n",
       "      <th>chat_dataset</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>training_args</th>\n",
       "      <th>resume_from_checkpoint</th>\n",
       "      <th>date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>Error</th>\n",
       "      <th>run_id</th>\n",
       "      <th>save_to_hub</th>\n",
       "      <th>output_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryOutFinetuningGeitje</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-25 13:21:46.201696+02:00</td>\n",
       "      <td>0.876791</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryOutFinetuningGeitje</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-04-25 13:24:59.884223+02:00</td>\n",
       "      <td>0.274652</td>\n",
       "      <td>Error(s) in loading state_dict for MistralForC...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryOutFinetuningGeitje</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-04-25 13:25:57.527833+02:00</td>\n",
       "      <td>0.362344</td>\n",
       "      <td>No valid checkpoint found in output directory ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryOutFinetuningGeitje</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-25 13:26:24.369492+02:00</td>\n",
       "      <td>0.319212</td>\n",
       "      <td>CUDA out of memory. Tried to allocate 112.00 M...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryOutFinetuningGeitje</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-04-26 08:47:21.945291+02:00</td>\n",
       "      <td>0.392476</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryOutFinetuningGeitje</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-04-26 08:47:57.151755+02:00</td>\n",
       "      <td>0.600505</td>\n",
       "      <td>string longer than 2147483647 bytes</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryoutGeitje2</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-26 08:56:52.283214+02:00</td>\n",
       "      <td>0.449522</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryoutGeitje2</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-04-26 09:26:12.329799+02:00</td>\n",
       "      <td>3.251497</td>\n",
       "      <td>[Errno 2] No such file or directory: '/home/az...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/TryoutGeitje2</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-04-26 09:29:06.636546+02:00</td>\n",
       "      <td>0.543515</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/tryoutstablelm</td>\n",
       "      <td>stabilityai/stablelm-2-1_6b</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-29 09:46:03.908296+02:00</td>\n",
       "      <td>0.364137</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/tryoutstablelm</td>\n",
       "      <td>stabilityai/stablelm-2-1_6b</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-29 09:48:18.644406+02:00</td>\n",
       "      <td>0.791530</td>\n",
       "      <td>Expected input batch_size (2) to match target ...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/GEITjeSmallData200Tokens</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-29 11:28:02.756504+02:00</td>\n",
       "      <td>1.342644</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/GEITjeSmallData200Tokens</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-29 11:48:12.624523+02:00</td>\n",
       "      <td>4.499735</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/GEITjeSmallData200Tokens</td>\n",
       "      <td>Rijgersberg/GEITje-7B</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-29 11:53:35.436951+02:00</td>\n",
       "      <td>0.519014</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/MistralSmallData200Tokens</td>\n",
       "      <td>mistral-community/Mistral-7B-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamGEITjeFormat200Tokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-30 13:32:55.123342+02:00</td>\n",
       "      <td>1.238507</td>\n",
       "      <td>CUDA out of memory. Tried to allocate 22.00 Mi...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/MistralSmallData200Tokens</td>\n",
       "      <td>mistral-community/Mistral-7B-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamFormat200LlamaTokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-02 10:14:42.103986+02:00</td>\n",
       "      <td>4.744335</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/LlamaSmallData200Tokens</td>\n",
       "      <td>meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>FemkeBakker/AmsterdamFormat200LlamaTokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-02 10:22:35.180386+02:00</td>\n",
       "      <td>0.644924</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/MistralSmallData200Tokens</td>\n",
       "      <td>mistral-community/Mistral-7B-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamFormat200LlamaTokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-02 11:30:37.119100+02:00</td>\n",
       "      <td>1.784342</td>\n",
       "      <td>CUDA out of memory. Tried to allocate 112.00 M...</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/MistralSmallData200Tokens</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamFormat200LlamaTokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-02 13:29:55.638421+02:00</td>\n",
       "      <td>4.780315</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/MistralSmallData200Tokens</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamFormat200LlamaTokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-02 14:02:55.215348+02:00</td>\n",
       "      <td>0.597784</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/MistralSmallData200Tokens</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamFormat200LlamaTokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-02 14:06:39.657276+02:00</td>\n",
       "      <td>1467.518128</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/GEITjeSmallData200Tokens</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamFormat200LlamaTokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-02 14:33:40.318320+02:00</td>\n",
       "      <td>1367.711304</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/LlamaSmallData200Tokens</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>FemkeBakker/AmsterdamFormat200LlamaTokens</td>\n",
       "      <td>dev</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-02 15:01:21.038330+02:00</td>\n",
       "      <td>1040.267759</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/tryoutstablelm</td>\n",
       "      <td>stabilityai/stablelm-2-1_6b</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-28 09:33:15.666775+02:00</td>\n",
       "      <td>1274.191825</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/tryoutstablelm</td>\n",
       "      <td>stabilityai/stablelm-2-1_6b</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-28 09:54:46.992883+02:00</td>\n",
       "      <td>2.428063</td>\n",
       "      <td>No valid checkpoint found in output directory ...</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/tryoutstablelm</td>\n",
       "      <td>stabilityai/stablelm-2-1_6b</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-28 09:57:30.580525+02:00</td>\n",
       "      <td>0.332646</td>\n",
       "      <td>No valid checkpoint found in output directory ...</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/tryoutstablelm</td>\n",
       "      <td>stabilityai/stablelm-2-1_6b</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-28 09:57:47.191583+02:00</td>\n",
       "      <td>6866.744590</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/tryoutstablelm</td>\n",
       "      <td>stabilityai/stablelm-2-1_6b</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-28 11:53:36.216185+02:00</td>\n",
       "      <td>15681.023710</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/tryoutstablelm</td>\n",
       "      <td>stabilityai/stablelm-2-1_6b</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-28 16:17:16.520661+02:00</td>\n",
       "      <td>189.865374</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationGEITje200T</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-29 14:07:04.642821+02:00</td>\n",
       "      <td>2926.216714</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistral200T</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-29 15:36:45.085202+02:00</td>\n",
       "      <td>2879.482625</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationLlama200T</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-29 16:44:49.778730+02:00</td>\n",
       "      <td>2459.635145</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationLlama200T</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-29 17:32:34.996990+02:00</td>\n",
       "      <td>2435.851116</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistrall...</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-29 18:17:40.189426+02:00</td>\n",
       "      <td>2909.715319</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistral200T</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-29 19:20:43.997402+02:00</td>\n",
       "      <td>19.168457</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistral200T</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-29 19:21:12.049071+02:00</td>\n",
       "      <td>370.747607</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationGEITje200T</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-29 19:39:27.535325+02:00</td>\n",
       "      <td>2821.834527</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationGEITje20...</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-03 08:33:45.251941+02:00</td>\n",
       "      <td>419.937012</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationLlama200...</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-03 08:52:32.234614+02:00</td>\n",
       "      <td>378.556517</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistral2...</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-03 09:10:08.642664+02:00</td>\n",
       "      <td>257.880533</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationGEITje20...</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-03 09:46:02.168824+02:00</td>\n",
       "      <td>15.640660</td>\n",
       "      <td>KeyboardInterrupt</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  \\\n",
       "0                 FemkeBakker/TryOutFinetuningGeitje   \n",
       "0                 FemkeBakker/TryOutFinetuningGeitje   \n",
       "0                 FemkeBakker/TryOutFinetuningGeitje   \n",
       "0                 FemkeBakker/TryOutFinetuningGeitje   \n",
       "0                 FemkeBakker/TryOutFinetuningGeitje   \n",
       "0                 FemkeBakker/TryOutFinetuningGeitje   \n",
       "0                          FemkeBakker/TryoutGeitje2   \n",
       "0                          FemkeBakker/TryoutGeitje2   \n",
       "0                          FemkeBakker/TryoutGeitje2   \n",
       "0                         FemkeBakker/tryoutstablelm   \n",
       "0                         FemkeBakker/tryoutstablelm   \n",
       "0               FemkeBakker/GEITjeSmallData200Tokens   \n",
       "0               FemkeBakker/GEITjeSmallData200Tokens   \n",
       "0               FemkeBakker/GEITjeSmallData200Tokens   \n",
       "0              FemkeBakker/MistralSmallData200Tokens   \n",
       "0              FemkeBakker/MistralSmallData200Tokens   \n",
       "0                FemkeBakker/LlamaSmallData200Tokens   \n",
       "0              FemkeBakker/MistralSmallData200Tokens   \n",
       "0              FemkeBakker/MistralSmallData200Tokens   \n",
       "0              FemkeBakker/MistralSmallData200Tokens   \n",
       "0              FemkeBakker/MistralSmallData200Tokens   \n",
       "0               FemkeBakker/GEITjeSmallData200Tokens   \n",
       "0                FemkeBakker/LlamaSmallData200Tokens   \n",
       "0                         FemkeBakker/tryoutstablelm   \n",
       "0                         FemkeBakker/tryoutstablelm   \n",
       "0                         FemkeBakker/tryoutstablelm   \n",
       "0                         FemkeBakker/tryoutstablelm   \n",
       "0                         FemkeBakker/tryoutstablelm   \n",
       "0                         FemkeBakker/tryoutstablelm   \n",
       "0   FemkeBakker/AmsterdamDocClassificationGEITje200T   \n",
       "0  FemkeBakker/AmsterdamDocClassificationMistral200T   \n",
       "0    FemkeBakker/AmsterdamDocClassificationLlama200T   \n",
       "0    FemkeBakker/AmsterdamDocClassificationLlama200T   \n",
       "0  FemkeBakker/AmsterdamDocClassificationMistrall...   \n",
       "0  FemkeBakker/AmsterdamDocClassificationMistral200T   \n",
       "0  FemkeBakker/AmsterdamDocClassificationMistral200T   \n",
       "0   FemkeBakker/AmsterdamDocClassificationGEITje200T   \n",
       "0  FemkeBakker/AmsterdamDocClassificationGEITje20...   \n",
       "0  FemkeBakker/AmsterdamDocClassificationLlama200...   \n",
       "0  FemkeBakker/AmsterdamDocClassificationMistral2...   \n",
       "0  FemkeBakker/AmsterdamDocClassificationGEITje20...   \n",
       "\n",
       "                           base_model  \\\n",
       "0               Rijgersberg/GEITje-7B   \n",
       "0               Rijgersberg/GEITje-7B   \n",
       "0               Rijgersberg/GEITje-7B   \n",
       "0               Rijgersberg/GEITje-7B   \n",
       "0               Rijgersberg/GEITje-7B   \n",
       "0               Rijgersberg/GEITje-7B   \n",
       "0               Rijgersberg/GEITje-7B   \n",
       "0               Rijgersberg/GEITje-7B   \n",
       "0               Rijgersberg/GEITje-7B   \n",
       "0         stabilityai/stablelm-2-1_6b   \n",
       "0         stabilityai/stablelm-2-1_6b   \n",
       "0               Rijgersberg/GEITje-7B   \n",
       "0               Rijgersberg/GEITje-7B   \n",
       "0               Rijgersberg/GEITje-7B   \n",
       "0   mistral-community/Mistral-7B-v0.2   \n",
       "0   mistral-community/Mistral-7B-v0.2   \n",
       "0            meta-llama/Llama-2-7b-hf   \n",
       "0   mistral-community/Mistral-7B-v0.2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0       Rijgersberg/GEITje-7B-chat-v2   \n",
       "0       meta-llama/Llama-2-7b-chat-hf   \n",
       "0         stabilityai/stablelm-2-1_6b   \n",
       "0         stabilityai/stablelm-2-1_6b   \n",
       "0         stabilityai/stablelm-2-1_6b   \n",
       "0         stabilityai/stablelm-2-1_6b   \n",
       "0         stabilityai/stablelm-2-1_6b   \n",
       "0         stabilityai/stablelm-2-1_6b   \n",
       "0       Rijgersberg/GEITje-7B-chat-v2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0       meta-llama/Llama-2-7b-chat-hf   \n",
       "0       meta-llama/Llama-2-7b-chat-hf   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0       Rijgersberg/GEITje-7B-chat-v2   \n",
       "0       Rijgersberg/GEITje-7B-chat-v2   \n",
       "0       meta-llama/Llama-2-7b-chat-hf   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0       Rijgersberg/GEITje-7B-chat-v2   \n",
       "\n",
       "                                  chat_dataset train_set test_set  \\\n",
       "0   FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0   FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0   FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0   FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0   FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0   FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0   FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0   FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0   FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0   FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0   FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0   FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0   FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0   FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0   FemkeBakker/AmsterdamGEITjeFormat200Tokens       dev      val   \n",
       "0    FemkeBakker/AmsterdamFormat200LlamaTokens       dev      val   \n",
       "0    FemkeBakker/AmsterdamFormat200LlamaTokens       dev      val   \n",
       "0    FemkeBakker/AmsterdamFormat200LlamaTokens       dev      val   \n",
       "0    FemkeBakker/AmsterdamFormat200LlamaTokens       dev      val   \n",
       "0    FemkeBakker/AmsterdamFormat200LlamaTokens       dev      val   \n",
       "0    FemkeBakker/AmsterdamFormat200LlamaTokens       dev      val   \n",
       "0    FemkeBakker/AmsterdamFormat200LlamaTokens       dev      val   \n",
       "0    FemkeBakker/AmsterdamFormat200LlamaTokens       dev      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train     test   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train     test   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train     test   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train     test   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "\n",
       "                                       training_args  resume_from_checkpoint  \\\n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                   False   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "0  TrainingArguments(\\n_n_gpu=1,\\naccelerator_con...                    True   \n",
       "\n",
       "                              date       runtime  \\\n",
       "0 2024-04-25 13:21:46.201696+02:00      0.876791   \n",
       "0 2024-04-25 13:24:59.884223+02:00      0.274652   \n",
       "0 2024-04-25 13:25:57.527833+02:00      0.362344   \n",
       "0 2024-04-25 13:26:24.369492+02:00      0.319212   \n",
       "0 2024-04-26 08:47:21.945291+02:00      0.392476   \n",
       "0 2024-04-26 08:47:57.151755+02:00      0.600505   \n",
       "0 2024-04-26 08:56:52.283214+02:00      0.449522   \n",
       "0 2024-04-26 09:26:12.329799+02:00      3.251497   \n",
       "0 2024-04-26 09:29:06.636546+02:00      0.543515   \n",
       "0 2024-04-29 09:46:03.908296+02:00      0.364137   \n",
       "0 2024-04-29 09:48:18.644406+02:00      0.791530   \n",
       "0 2024-04-29 11:28:02.756504+02:00      1.342644   \n",
       "0 2024-04-29 11:48:12.624523+02:00      4.499735   \n",
       "0 2024-04-29 11:53:35.436951+02:00      0.519014   \n",
       "0 2024-04-30 13:32:55.123342+02:00      1.238507   \n",
       "0 2024-05-02 10:14:42.103986+02:00      4.744335   \n",
       "0 2024-05-02 10:22:35.180386+02:00      0.644924   \n",
       "0 2024-05-02 11:30:37.119100+02:00      1.784342   \n",
       "0 2024-05-02 13:29:55.638421+02:00      4.780315   \n",
       "0 2024-05-02 14:02:55.215348+02:00      0.597784   \n",
       "0 2024-05-02 14:06:39.657276+02:00   1467.518128   \n",
       "0 2024-05-02 14:33:40.318320+02:00   1367.711304   \n",
       "0 2024-05-02 15:01:21.038330+02:00   1040.267759   \n",
       "0 2024-05-28 09:33:15.666775+02:00   1274.191825   \n",
       "0 2024-05-28 09:54:46.992883+02:00      2.428063   \n",
       "0 2024-05-28 09:57:30.580525+02:00      0.332646   \n",
       "0 2024-05-28 09:57:47.191583+02:00   6866.744590   \n",
       "0 2024-05-28 11:53:36.216185+02:00  15681.023710   \n",
       "0 2024-05-28 16:17:16.520661+02:00    189.865374   \n",
       "0 2024-05-29 14:07:04.642821+02:00   2926.216714   \n",
       "0 2024-05-29 15:36:45.085202+02:00   2879.482625   \n",
       "0 2024-05-29 16:44:49.778730+02:00   2459.635145   \n",
       "0 2024-05-29 17:32:34.996990+02:00   2435.851116   \n",
       "0 2024-05-29 18:17:40.189426+02:00   2909.715319   \n",
       "0 2024-05-29 19:20:43.997402+02:00     19.168457   \n",
       "0 2024-05-29 19:21:12.049071+02:00    370.747607   \n",
       "0 2024-05-29 19:39:27.535325+02:00   2821.834527   \n",
       "0 2024-06-03 08:33:45.251941+02:00    419.937012   \n",
       "0 2024-06-03 08:52:32.234614+02:00    378.556517   \n",
       "0 2024-06-03 09:10:08.642664+02:00    257.880533   \n",
       "0 2024-06-03 09:46:02.168824+02:00     15.640660   \n",
       "\n",
       "                                               Error  run_id save_to_hub  \\\n",
       "0                                  KeyboardInterrupt       0         NaN   \n",
       "0  Error(s) in loading state_dict for MistralForC...       0         NaN   \n",
       "0  No valid checkpoint found in output directory ...       0         NaN   \n",
       "0  CUDA out of memory. Tried to allocate 112.00 M...       0         NaN   \n",
       "0                                  KeyboardInterrupt       0         NaN   \n",
       "0                string longer than 2147483647 bytes       0         NaN   \n",
       "0                                              False       1         NaN   \n",
       "0  [Errno 2] No such file or directory: '/home/az...       1         NaN   \n",
       "0                                              False       1         NaN   \n",
       "0                                  KeyboardInterrupt       2         NaN   \n",
       "0  Expected input batch_size (2) to match target ...       2       False   \n",
       "0                                  KeyboardInterrupt       3        True   \n",
       "0                                  KeyboardInterrupt       4        True   \n",
       "0                                              False       4        True   \n",
       "0  CUDA out of memory. Tried to allocate 22.00 Mi...       5        True   \n",
       "0                                  KeyboardInterrupt       6        True   \n",
       "0                                              False       7        True   \n",
       "0  CUDA out of memory. Tried to allocate 112.00 M...       8        True   \n",
       "0                                              False       9        True   \n",
       "0                                  KeyboardInterrupt      10        True   \n",
       "0                                              False      10        True   \n",
       "0                                              False      11        True   \n",
       "0                                              False      12        True   \n",
       "0                                  KeyboardInterrupt      13        True   \n",
       "0  No valid checkpoint found in output directory ...      13        True   \n",
       "0  No valid checkpoint found in output directory ...      13        True   \n",
       "0                                  KeyboardInterrupt      13        True   \n",
       "0                                              False      14        True   \n",
       "0                                  KeyboardInterrupt      14        True   \n",
       "0                                              False      15        True   \n",
       "0                                              False      16        True   \n",
       "0                                              False      17        True   \n",
       "0                                              False      17        True   \n",
       "0                                              False      16        True   \n",
       "0                                  KeyboardInterrupt      16        True   \n",
       "0                                              False      16        True   \n",
       "0                                              False      15        True   \n",
       "0                                              False      18        True   \n",
       "0                                              False      19        True   \n",
       "0                                              False      20        True   \n",
       "0                                  KeyboardInterrupt      21        True   \n",
       "\n",
       "                                          output_dir  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yeet = pd.read_pickle(f'{cf.output_path}/overview_models.pkl')\n",
    "display(yeet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import DatasetDict, load_dataset, concatenate_datasets\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../scripts/') \n",
    "import prediction_helperfunctions as ph\n",
    "\n",
    "def train(model, model_name, tokenizer, dataset, chat_dataset_name, new_model_name, train_set, test_set, run_id='No_id', save_to_hub=True, resume=False):\n",
    "    start_time = time.time()\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "    # tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    train_data = dataset[train_set].shuffle(seed=42).select(range(100))\n",
    "    train_data = train_data.map(tokenize_function, batched=True)\n",
    "    test_data = dataset[test_set].shuffle(seed=42).select(range(100))    \n",
    "    test_data = test_data.map(tokenize_function, batched=True)\n",
    "\n",
    "    per_device_train_batch_size = 2\n",
    "    gradient_accumulation_steps = 8\n",
    "    steps_per_epoch = len(train_data)\\\n",
    "                // (torch.cuda.device_count() * per_device_train_batch_size * gradient_accumulation_steps)\n",
    "    eval_steps = steps_per_epoch // 5\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        optim='adamw_bnb_8bit',\n",
    "        num_train_epochs=1,\n",
    "        learning_rate=1e-5,\n",
    "        lr_scheduler_type='cosine',\n",
    "        warmup_ratio=0.1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=8,\n",
    "        gradient_checkpointing=True,\n",
    "        evaluation_strategy='steps',\n",
    "        eval_steps=eval_steps,\n",
    "        save_strategy='epoch',\n",
    "        bf16=False, #bf16=True require CUDA 11 -> original code bf16=True\n",
    "        output_dir=f'{cf.output_path}/finetuning_output/stablelm_finetuning_output',\n",
    "        report_to=[\"tensorboard\", 'wandb'],\n",
    "        logging_steps=1,\n",
    "        logging_first_step=True,\n",
    "        hub_model_id=new_model_name,\n",
    "        push_to_hub=True,\n",
    "        hub_private_repo=True,\n",
    "        hub_strategy='all_checkpoints',\n",
    "    )\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=8192,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=test_data,\n",
    "        packing=True\n",
    "        # formatting_func=format,\n",
    "        # neftune_noise_alpha=5,\n",
    "    )\n",
    "\n",
    "  \n",
    "    dict_info = {\n",
    "        'model':new_model_name,\n",
    "        'base_model':model_name,\n",
    "        'chat_dataset':chat_dataset_name,\n",
    "        'train_set':train_set,\n",
    "        'test_set': test_set,\n",
    "        'training_args': training_args,\n",
    "        'resume_from_checkpoint':resume,\n",
    "        'date':ph.get_datetime(),\n",
    "        'runtime': time.time()-start_time,\n",
    "        'Error': False,\n",
    "        'run_id':run_id,\n",
    "        'save_to_hub':save_to_hub\n",
    "        }\n",
    "\n",
    "    data = pd.DataFrame(columns=dict_info.keys())\n",
    "\n",
    "    trainer.train(resume_from_checkpoint=resume)\n",
    "    if save_to_hub == True:\n",
    "        trainer.push_to_hub()\n",
    "    return trainer\n",
    "\n",
    "    # try:\n",
    "    #     trainer.train(resume_from_checkpoint=resume)\n",
    "    #     if save_to_hub == True:\n",
    "    #         trainer.push_to_hub()\n",
    "    #     data.loc[len(data)] = dict_info\n",
    "    #     combine_and_save_df(data, f'{cf.output_path}/overview_models.pkl')\n",
    "\n",
    "    # except KeyboardInterrupt:\n",
    "    #     dict_info['Error'] = 'KeyboardInterrupt'\n",
    "    #     data.loc[len(data)] = dict_info\n",
    "    #     combine_and_save_df(data, f'{cf.output_path}/overview_models.pkl')\n",
    "\n",
    "    # except Exception  as e:\n",
    "    #     print(e)\n",
    "    #     dict_info['Error'] = e\n",
    "    #     data.loc[len(data)] = dict_info\n",
    "    #     combine_and_save_df(data, f'{cf.output_path}/overview_models.pkl')\n",
    "\n",
    "\n",
    "    #     model_df = pd.DataFrame(dict_info)\n",
    "    #     combine_and_save_df(model_df, f'{cf.output_path}/overview_models.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# basemodel_name = 'Rijgersberg/GEITje-7B'\n",
    "basemodel_name = \"stabilityai/stablelm-2-1_6b\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(basemodel_name,num_labels=5, torch_dtype=torch.bfloat16,\n",
    "                                                low_cpu_mem_usage=True, attn_implementation=\"sdpa\",\n",
    "                                                device_map='cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(basemodel_name)\n",
    "# tokenizer.pad_token = tokenizer.unk_token\n",
    "# tokenizer.padding_side = 'right'\n",
    "\n",
    "# model.config.pad_token_id = tokenizer.unk_token_id\n",
    "model.config.problem_type = \"multi_label_classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_class = train(model, basemodel_name, tokenizer, dataset, 'FemkeBakker/AmsterdamGEITjeFormat200Tokens',\n",
    "          'FemkeBakker/tryoutstablelm', 'train', 'test',  run_id=2, save_to_hub=False, resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"FemkeBakker/TryoutGeitje2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize input text\n",
    "input_text = \"This is a sample sentence.\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Model inference\n",
    "outputs = model(**inputs)\n",
    "predictions = outputs.logits.argmax(dim=1)\n",
    "\n",
    "# Post-processing (e.g., convert predictions to labels)\n",
    "predicted_label = predictions.item()\n",
    "print(\"Predicted label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tryout finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## WORKING VERSION OF GEITJE-Chat using AutoModelForCausalLM\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_name = 'Rijgersberg/GEITje-7B-chat-v2'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16,\n",
    "                                             low_cpu_mem_usage=True, attn_implementation=\"eager\",\n",
    "                                             device_map='balanced')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def generate(conversation, temperature=0.2, top_k=50, max_new_tokens=1_000):\n",
    "    tokenized = tokenizer.apply_chat_template(conversation, add_generation_prompt=True,\n",
    "                                              return_tensors='pt').to(device)\n",
    "    outputs = model.generate(tokenized, do_sample=True, temperature=temperature,\n",
    "                             top_k=top_k, max_new_tokens=max_new_tokens)\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Xx Gemeente Amsterdam F l N\\n% Raadscommissie voor Financiën, Coördinatie 3d, Coördinatie Aanpak Subsidies,\\nAanpak Belastingen, Waterbeheer, Vastgoed, Inkoop en Personeel en Organisatie\\n\\n% Agenda, woensdag 3 juni 2015\\nHierbij wordt u uitgenodigd voor de openbare vergadering van de Raadscommissie\\nvoor Financiën, Coördinatie 3d, Coördinatie Aanpak Subsidies, Aanpak Belastingen,\\nWaterbeheer, Vastgoed, Inkoop en Personeel en Organisatie\\n\\nTijd 09.00 tot 12.30 uur en van 13.30 tot 17',\n",
    "    }\n",
    "]\n",
    "print(generate(conversation))\n",
    "# <|user|>\n",
    "# Welk woord hoort er niet in dit rijtje thuis: \"auto, vliegtuig, geitje, bus\"? \n",
    "# <|assistant|>\n",
    "# Het woord dat niet op zijn plaats staat is 'geit'. Een geit zou niet tussen een lijst van vervoersmiddelen moeten staan. Het past beter bij een boerderijthema of dierenlijst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conversation = [\n",
    "      {\n",
    "        'role': 'user',\n",
    "        'content': f\"\"\"\n",
    "         Classificeer het document in één van de categoriën.\n",
    "        Houd het kort, geef enkel de naam van de categorie als response.\n",
    "    \n",
    "    Categoriën:   ['Voordracht', 'Besluit', 'Schriftelijke Vragen', 'Brief', 'Raadsadres', 'Onderzoeksrapport', 'Termijnagenda', 'Raadsnotulen', 'Agenda', 'Motie', 'Actualiteit', 'Factsheets']\n",
    "    \n",
    "    Document: \n",
    "\n",
    "        'Xx Gemeente Amsterdam F l N\\n% Raadscommissie voor Financiën, Coördinatie 3d, Coördinatie Aanpak Subsidies,\\nAanpak Belastingen, Waterbeheer, Vastgoed, Inkoop en Personeel en Organisatie\\n\\n% Agenda, woensdag 3 juni 2015\\nHierbij wordt u uitgenodigd voor de openbare vergadering van de Raadscommissie\\nvoor Financiën, Coördinatie 3d, Coördinatie Aanpak Subsidies, Aanpak Belastingen,\\nWaterbeheer, Vastgoed, Inkoop en Personeel en Organisatie\\n\\nTijd 09.00 tot 12.30 uur en van 13.30 tot 17'\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "print(generate(conversation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_dataset['val'][0]['message'][0]['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code works for GEITje example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "basemodel_name = 'Rijgersberg/GEITje-7B'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(basemodel_name, torch_dtype=torch.bfloat16,\n",
    "                                                low_cpu_mem_usage=True, attn_implementation=\"sdpa\",\n",
    "                                                device_map='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import DatasetDict, load_dataset, concatenate_datasets\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "import os\n",
    "\n",
    "def train(model, tokenizer, chat_dataset, new_model_name):\n",
    "\n",
    "    def format(examples):\n",
    "        return [tokenizer.apply_chat_template(conversation, tokenize=False)\n",
    "                for conversation in examples['messages_nl']]\n",
    "\n",
    "    per_device_train_batch_size = 2\n",
    "    gradient_accumulation_steps = 8\n",
    "    steps_per_epoch = len(chat_dataset['train_sft'])\\\n",
    "                 // (torch.cuda.device_count() * per_device_train_batch_size * gradient_accumulation_steps)\n",
    "    eval_steps = steps_per_epoch // 5\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        optim='adamw_bnb_8bit',\n",
    "        num_train_epochs=3,\n",
    "        learning_rate=1e-5,\n",
    "        lr_scheduler_type='cosine',\n",
    "        warmup_ratio=0.1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=8,\n",
    "        gradient_checkpointing=True,\n",
    "        evaluation_strategy='steps',\n",
    "        eval_steps=eval_steps,\n",
    "        save_strategy='epoch',\n",
    "        bf16=True,\n",
    "        output_dir=f'{cf.output_path}/geitje_finetuning_output',\n",
    "        report_to=[\"tensorboard\", 'wandb'],\n",
    "        logging_steps=1,\n",
    "        logging_first_step=True,\n",
    "        hub_model_id=new_model_name,\n",
    "        push_to_hub=True,\n",
    "        hub_private_repo=True,\n",
    "        hub_strategy='all_checkpoints',\n",
    "    )\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=8192,\n",
    "        train_dataset=chat_dataset['train_sft'],\n",
    "        eval_dataset=chat_dataset['test_sft'],\n",
    "        formatting_func=format,\n",
    "        neftune_noise_alpha=5,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.push_to_hub()\n",
    "    return trainer\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "# basemodel_name = 'Rijgersberg/GEITje-7B'\n",
    "# model = AutoModelForCausalLM.from_pretrained(basemodel_name, torch_dtype=torch.bfloat16,\n",
    "#                                                 low_cpu_mem_usage=True, attn_implementation=\"eager\",\n",
    "#                                                 device_map='balanced')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(basemodel_name)\n",
    "\n",
    "# Mistral 7B is missing a padding token by default, so we need to assign\n",
    "# another token to the padding job during training.\n",
    "# Unfortunately we cannot use the </s> token, because we need the model to\n",
    "# learn to output </s> at the end of its turn, so that we can stop generating\n",
    "# when it emits it. If we were to also use it as the padding token,\n",
    "# any loss computed on </s> would then be discarded, nothing would be learned\n",
    "# and the model would never stop generating.\n",
    "# Trust me, I learned this the hard way ;).\n",
    "# Therefore, we take the least bad alternative action and assign\n",
    "# the rarely used <UNK> token to the padding role.\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.padding_side = 'right'\n",
    "model.config.pad_token_id = tokenizer.unk_token_id\n",
    "\n",
    "no_robots_nl = load_dataset('Rijgersberg/no_robots_nl')\n",
    "no_robots_nl[\"train_sft\"]=no_robots_nl[\"train_sft\"].select(range(2))\n",
    "no_robots_nl[\"test_sft\"]=no_robots_nl[\"test_sft\"].select(range(2))\n",
    "\n",
    "ultrachat_nl = load_dataset('Rijgersberg/ultrachat_10k_nl')\n",
    "ultrachat_nl[\"train_sft\"]=ultrachat_nl[\"train_sft\"].select(range(2))\n",
    "ultrachat_nl[\"test_sft\"]=ultrachat_nl[\"test_sft\"].select(range(2))\n",
    "\n",
    "chat_dataset = DatasetDict({\n",
    "    'train_sft': concatenate_datasets([no_robots_nl['train_sft'],\n",
    "                                        ultrachat_nl['train_sft']]).shuffle(seed=42),\n",
    "    'test_sft': concatenate_datasets([no_robots_nl['test_sft'],\n",
    "                                        ultrachat_nl['test_sft']]).shuffle(seed=42),\n",
    "})\n",
    "\n",
    "chat_dataset = chat_dataset.filter(lambda row: all(turn['content'] != '<TRANSLATION FAILED>'\n",
    "                                                    for turn in row['messages_nl']))\n",
    "\n",
    "trained_model = train(model, tokenizer, chat_dataset,\n",
    "        new_model_name='FemkeBakker/TryOutFinetuningGeitje')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## WORKING VERSION OF GEITJE-Chat using AutoModelForCausalLM\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_name = 'Rijgersberg/GEITje-7B-chat-v2'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16,\n",
    "                                             low_cpu_mem_usage=True, attn_implementation=\"eager\",\n",
    "                                             device_map='balanced')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def generate(conversation, temperature=0.2, top_k=50, max_new_tokens=1_000):\n",
    "    tokenized = tokenizer.apply_chat_template(conversation, add_generation_prompt=True,\n",
    "                                              return_tensors='pt').to(device)\n",
    "    outputs = model.generate(tokenized, do_sample=True, temperature=temperature,\n",
    "                             top_k=top_k, max_new_tokens=max_new_tokens)\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Welk woord hoort er niet in dit rijtje thuis: \"auto, vliegtuig, geitje, bus\"?'\n",
    "    }\n",
    "]\n",
    "print(generate(conversation))\n",
    "# <|user|>\n",
    "# Welk woord hoort er niet in dit rijtje thuis: \"auto, vliegtuig, geitje, bus\"? \n",
    "# <|assistant|>\n",
    "# Het woord dat niet op zijn plaats staat is 'geit'. Een geit zou niet tussen een lijst van vervoersmiddelen moeten staan. Het past beter bij een boerderijthema of dierenlijst."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
