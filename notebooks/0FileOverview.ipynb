{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash /home/azureuser/cloudfiles/code/blobfuse/blobfuse_raadsinformatie.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Select where to run notebook: \"azure\" or \"local\"\n",
    "my_run = \"azure\"\n",
    "\n",
    "import my_secrets as sc\n",
    "import settings as st\n",
    "\n",
    "if my_run == \"azure\":\n",
    "    import config_azure as cf\n",
    "elif my_run == \"local\":\n",
    "    import config as cf\n",
    "\n",
    "\n",
    "import os\n",
    "if my_run == \"azure\":\n",
    "    if not os.path.exists(cf.HUGGING_CACHE):\n",
    "        os.mkdir(cf.HUGGING_CACHE)\n",
    "    os.environ[\"TRANSFORMERS_CACHE\"] = cf.HUGGING_CACHE\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Explain/show the contents of the different kind of files included in this project. During the project, a lot of extra columns are added to the data, predictions and overview files. Thus in this notebook, all columns are explained. \n",
    "\n",
    "Different kind of files:\n",
    "1. txtfiles_notcleaned.pkl\n",
    "2. txtfiles.pkl\n",
    "3. overview.pkl\n",
    "4. predictions.pkl (difference between baselines and LLMs?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common columns\n",
    "The following columns are included in (almost) all files:\n",
    "- label = true class of doc\n",
    "- path = path to OCR file\n",
    "- id = document id\n",
    "- text = extracted text from OCR file\n",
    "- num_pages = amount of pages in pdf file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. txtfiles_notcleaned.pkl\n",
    "\n",
    "This file contains all docs that were scraped. \n",
    "\n",
    "Columns:\n",
    "- tokens = text split into tokens using the NLTK library. These tokens are not used during the research, but needed for the preliminary analysis of the data.\n",
    "- token_count = amount of tokens in text, split using the NLTK library. Equal the length of the tokens columns.\n",
    "- clean_tokens = tokens column, but removed stopwords and interpunction. These tokens are not used during the research, but needed for the preliminary analysis of the data.\n",
    "- clean_tokens_count = amount of tokens in text, split using the NLTK library. Equal the length of the clean_tokens columns.\n",
    "- pdf_path = path to PDF file. Each doc has multiple versions saved, including the OCR version and the PDF version. That's why there is a distinction between path and pdf_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The txtfiles_notcleaned file contains 33117 docs.\n",
      "Columns: ['label', 'path', 'id', 'text', 'tokens', 'token_count', 'clean_tokens', 'clean_tokens_count', 'pdf_path', 'num_pages']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>clean_tokens_count</th>\n",
       "      <th>pdf_path</th>\n",
       "      <th>num_pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Motie</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>0</td>\n",
       "      <td>Gemeente Amsterdam\\n% Gemeenteraad R\\n% Gemeen...</td>\n",
       "      <td>[Gemeente, Amsterdam, %, Gemeenteraad, R, %, G...</td>\n",
       "      <td>395</td>\n",
       "      <td>[Gemeente, Amsterdam, Gemeenteraad, Gemeentebl...</td>\n",
       "      <td>205</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Motie</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gemeente Amsterdam\\n\\n% Gemeenteraad R\\n\\n% Ge...</td>\n",
       "      <td>[Gemeente, Amsterdam, %, Gemeenteraad, R, %, G...</td>\n",
       "      <td>390</td>\n",
       "      <td>[Gemeente, Amsterdam, Gemeenteraad, Gemeentebl...</td>\n",
       "      <td>197</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               path  id  \\\n",
       "0  Motie  /home/azureuser/cloudfiles/code/blobfuse/raads...   0   \n",
       "1  Motie  /home/azureuser/cloudfiles/code/blobfuse/raads...   1   \n",
       "\n",
       "                                                text  \\\n",
       "0  Gemeente Amsterdam\\n% Gemeenteraad R\\n% Gemeen...   \n",
       "1  Gemeente Amsterdam\\n\\n% Gemeenteraad R\\n\\n% Ge...   \n",
       "\n",
       "                                              tokens  token_count  \\\n",
       "0  [Gemeente, Amsterdam, %, Gemeenteraad, R, %, G...          395   \n",
       "1  [Gemeente, Amsterdam, %, Gemeenteraad, R, %, G...          390   \n",
       "\n",
       "                                        clean_tokens  clean_tokens_count  \\\n",
       "0  [Gemeente, Amsterdam, Gemeenteraad, Gemeentebl...                 205   \n",
       "1  [Gemeente, Amsterdam, Gemeenteraad, Gemeentebl...                 197   \n",
       "\n",
       "                                            pdf_path  num_pages  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...        2.0  \n",
       "1  /home/azureuser/cloudfiles/code/blobfuse/raads...        2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "txtfiles_notcleaned = pd.read_pickle(f\"{cf.output_path}/txtfiles_notcleaned.pkl\")\n",
    "print(f\"The txtfiles_notcleaned file contains {len(txtfiles_notcleaned)} docs.\")\n",
    "print(f\"Columns: {list(txtfiles_notcleaned.columns)}\")\n",
    "display(txtfiles_notcleaned.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. txtfiles.pkl\n",
    "\n",
    "This file contains all documents, without faulty/unclean documents and duplicates. This file is used during the research. \n",
    "\n",
    "What is removed (compared to txtfiles_unclean):\n",
    "- three classes that were deemed to unclean. \n",
    "- faulty documents that only contained gibberish.\n",
    "- duplicates.\n",
    "\n",
    "Columns:\n",
    "- 4split = indicates to which subset the doc belongs to. Incase of 4split, the data is split into train,dev, test and val.\n",
    "- 2split = indicates to which subset the doc belongs to. Incase of 2split, the data is split into train and test.\n",
    "- balanced_split = indicates to which subset the doc belongs to. Incase of 2split, the data is split into train, test and val. Is used for the final experiments.\n",
    "- MistralTokens = text split into tokens using Mistral tokenizer. Needed to shorten the docs for the experiments. Note: since mistral and geitje have the same tokenizer, an extra column GeitjeTokens is not needed.\n",
    "- count_MistralTokens = is count of tokens in MistralTokens, i.e. in how many tokens the text was split by Mistral tokenizer.\n",
    "- LlamaTokens = text split into tokens using Llama tokenizer. Needed to shorten the docs for the experiments.\n",
    "- count_LlamaTokens = is count of tokens in LlamaTokens, i.e. in how many tokens the text was split by Llama tokenizer.\n",
    "- md5_hash = unique id for the content of the doc. Is used to remove duplicates.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The txtfiles file contains 20818 docs.\n",
      "Columns: ['label', 'path', 'id', 'text', 'num_pages', '4split', '2split', 'MistralTokens', 'count_MistralTokens', 'LlamaTokens', 'count_LlamaTokens', 'md5_hash', 'balanced_split']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>4split</th>\n",
       "      <th>2split</th>\n",
       "      <th>MistralTokens</th>\n",
       "      <th>count_MistralTokens</th>\n",
       "      <th>LlamaTokens</th>\n",
       "      <th>count_LlamaTokens</th>\n",
       "      <th>md5_hash</th>\n",
       "      <th>balanced_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Motie</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>1874</td>\n",
       "      <td>x Gemeente Amsterdam R\\nGemeenteraad\\n% Gemeen...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[▁x, ▁Geme, ente, ▁Amsterdam, ▁R, &lt;0x0A&gt;, G, e...</td>\n",
       "      <td>350</td>\n",
       "      <td>[▁x, ▁Geme, ente, ▁Amsterdam, ▁R, &lt;0x0A&gt;, G, e...</td>\n",
       "      <td>346</td>\n",
       "      <td>2f09ba2c967bba0eecf71f846f258a78</td>\n",
       "      <td>discard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Motie</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>230</td>\n",
       "      <td>X Gemeente Amsterdam R\\nGemeenteraad\\n% Gemeen...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[▁X, ▁Geme, ente, ▁Amsterdam, ▁R, &lt;0x0A&gt;, G, e...</td>\n",
       "      <td>1130</td>\n",
       "      <td>[▁X, ▁Geme, ente, ▁Amsterdam, ▁R, &lt;0x0A&gt;, G, e...</td>\n",
       "      <td>1082</td>\n",
       "      <td>d14b33c32ba1e1bcff16320891bdf158</td>\n",
       "      <td>discard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               path    id  \\\n",
       "0  Motie  /home/azureuser/cloudfiles/code/blobfuse/raads...  1874   \n",
       "1  Motie  /home/azureuser/cloudfiles/code/blobfuse/raads...   230   \n",
       "\n",
       "                                                text  num_pages 4split 2split  \\\n",
       "0  x Gemeente Amsterdam R\\nGemeenteraad\\n% Gemeen...        1.0  train  train   \n",
       "1  X Gemeente Amsterdam R\\nGemeenteraad\\n% Gemeen...        2.0  train  train   \n",
       "\n",
       "                                       MistralTokens  count_MistralTokens  \\\n",
       "0  [▁x, ▁Geme, ente, ▁Amsterdam, ▁R, <0x0A>, G, e...                  350   \n",
       "1  [▁X, ▁Geme, ente, ▁Amsterdam, ▁R, <0x0A>, G, e...                 1130   \n",
       "\n",
       "                                         LlamaTokens  count_LlamaTokens  \\\n",
       "0  [▁x, ▁Geme, ente, ▁Amsterdam, ▁R, <0x0A>, G, e...                346   \n",
       "1  [▁X, ▁Geme, ente, ▁Amsterdam, ▁R, <0x0A>, G, e...               1082   \n",
       "\n",
       "                           md5_hash balanced_split  \n",
       "0  2f09ba2c967bba0eecf71f846f258a78        discard  \n",
       "1  d14b33c32ba1e1bcff16320891bdf158        discard  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "txtfiles = pd.read_pickle(f\"{cf.output_path}/txtfiles.pkl\")\n",
    "print(f\"The txtfiles file contains {len(txtfiles)} docs.\")\n",
    "print(f\"Columns: {list(txtfiles.columns)}\")\n",
    "display(txtfiles.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview.pkl\n",
    "The overview files for the experiments contain for each experiment exactly one row with meta data about the experiments. There is not difference between the overview file of the baselines and the overview files of the LLMs.\n",
    "\n",
    "Columns:\n",
    "- model = model used to get predictions.\n",
    "- run_id = id of the experiment, unique for each experiment.\n",
    "- date = date and time when experiment finished running.\n",
    "- train_set = the subset of the split_col that was used as training set. Depending on the split and goal of the experiment this can be either train or dev.\n",
    "- test_set = the subset of the split_col that was used as test set. Depending on the split and goal of the experiment this can be either test or val.\n",
    "- train_set_support = amount of docs in training set.\n",
    "- test_set_support = amount of docs in test set. \n",
    "- split_col = column that indicates the split, shows which split was used. Can be 2split, 4split or balanced_split.\n",
    "- text_col = column that contained the text of the document. Indicates how doc was shortened.\n",
    "- runtime = total time it took to run the experiment in seconds.\n",
    "- 'accuracy', 'macro_avg_precision', 'macro_avg_recall', 'macro_avg_f1', 'weighted_avg_precision', 'weighted_avg_recall', 'weighted_avg_f1', 'classification_report' = evaluation scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline_overview file contains 3 experiments.\n",
      "Columns: ['model', 'run_id', 'date', 'train_set', 'test_set', 'train_set_support', 'test_set_support', 'split_col', 'text_col', 'runtime', 'accuracy', 'macro_avg_precision', 'macro_avg_recall', 'macro_avg_f1', 'weighted_avg_precision', 'weighted_avg_recall', 'weighted_avg_f1', 'classification_report']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>run_id</th>\n",
       "      <th>date</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>train_set_support</th>\n",
       "      <th>test_set_support</th>\n",
       "      <th>split_col</th>\n",
       "      <th>text_col</th>\n",
       "      <th>runtime</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro_avg_precision</th>\n",
       "      <th>macro_avg_recall</th>\n",
       "      <th>macro_avg_f1</th>\n",
       "      <th>weighted_avg_precision</th>\n",
       "      <th>weighted_avg_recall</th>\n",
       "      <th>weighted_avg_f1</th>\n",
       "      <th>classification_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmsterdamDocClassificationMistral200T1Epochs</td>\n",
       "      <td>FT_AmsterdamDocClassificationMistral200T1Epoch...</td>\n",
       "      <td>2024-06-03 21:28:18.488289+02:00</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>9900</td>\n",
       "      <td>1100</td>\n",
       "      <td>balanced_split</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>24081.369143</td>\n",
       "      <td>0.895455</td>\n",
       "      <td>0.921469</td>\n",
       "      <td>0.895455</td>\n",
       "      <td>0.888446</td>\n",
       "      <td>0.921469</td>\n",
       "      <td>0.895455</td>\n",
       "      <td>0.888446</td>\n",
       "      <td>precision    recall  f1-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmsterdamDocClassificationGEITje200T1Epochs</td>\n",
       "      <td>FT_AmsterdamDocClassificationGEITje200T1Epochs...</td>\n",
       "      <td>2024-06-04 10:25:38.531475+02:00</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>9900</td>\n",
       "      <td>1100</td>\n",
       "      <td>balanced_split</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>25634.273609</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.925842</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.881006</td>\n",
       "      <td>0.925842</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.881006</td>\n",
       "      <td>precision    recall  f1-s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model  \\\n",
       "0  AmsterdamDocClassificationMistral200T1Epochs   \n",
       "0   AmsterdamDocClassificationGEITje200T1Epochs   \n",
       "\n",
       "                                              run_id  \\\n",
       "0  FT_AmsterdamDocClassificationMistral200T1Epoch...   \n",
       "0  FT_AmsterdamDocClassificationGEITje200T1Epochs...   \n",
       "\n",
       "                              date train_set test_set  train_set_support  \\\n",
       "0 2024-06-03 21:28:18.488289+02:00     train     test               9900   \n",
       "0 2024-06-04 10:25:38.531475+02:00     train     test               9900   \n",
       "\n",
       "   test_set_support       split_col                            text_col  \\\n",
       "0              1100  balanced_split  TruncationLlamaTokensFront200Back0   \n",
       "0              1100  balanced_split  TruncationLlamaTokensFront200Back0   \n",
       "\n",
       "        runtime  accuracy  macro_avg_precision  macro_avg_recall  \\\n",
       "0  24081.369143  0.895455             0.921469          0.895455   \n",
       "0  25634.273609  0.890909             0.925842          0.890909   \n",
       "\n",
       "   macro_avg_f1  weighted_avg_precision  weighted_avg_recall  weighted_avg_f1  \\\n",
       "0      0.888446                0.921469             0.895455         0.888446   \n",
       "0      0.881006                0.925842             0.890909         0.881006   \n",
       "\n",
       "                               classification_report  \n",
       "0                       precision    recall  f1-s...  \n",
       "0                       precision    recall  f1-s...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_overview = pd.read_pickle(f\"{cf.output_path}/predictionsFinal/finetuning/1epochs/overview.pkl\")\n",
    "print(f\"The baseline_overview file contains {len(llm_overview)} experiments.\")\n",
    "print(f\"Columns: {list(llm_overview.columns)}\")\n",
    "display(llm_overview.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_overview = pd.read_pickle(f\"{cf.output_path}/trial/overview.pkl\")\n",
    "baseline_predictions = pd.read_pickle(f\"{cf.output_path}/trial/LinearSVCpredictions.pkl\")\n",
    "llm_overview = pd.read_pickle(f\"{cf.output_path}/predictionsFinal/finetuning/1epochs/overview.pkl\")\n",
    "llm_predictions =  pd.read_pickle(f\"{cf.output_path}/predictionsFinal/finetuning/1epochs/MistralFirst200Last0Predictions.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>MistralTokens</th>\n",
       "      <th>count_MistralTokens</th>\n",
       "      <th>LlamaTokens</th>\n",
       "      <th>count_LlamaTokens</th>\n",
       "      <th>old_label</th>\n",
       "      <th>md5_hash</th>\n",
       "      <th>balanced_split</th>\n",
       "      <th>trunc_txt</th>\n",
       "      <th>trunc_col</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>model</th>\n",
       "      <th>date</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>10154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[▁x, ▁Geme, ente, ▁Amsterdam, ▁J, ▁C, &lt;0x0A&gt;, ...</td>\n",
       "      <td>447</td>\n",
       "      <td>[▁x, ▁Geme, ente, ▁Amsterdam, ▁J, ▁C, &lt;0x0A&gt;, ...</td>\n",
       "      <td>422</td>\n",
       "      <td>Actualiteit</td>\n",
       "      <td>2307717591d864eea5918ef27cea118b</td>\n",
       "      <td>test</td>\n",
       "      <td>x Gemeente Amsterdam J C\\n% Actualiteit voor d...</td>\n",
       "      <td>TruncationLlamaTokensFront100Back100</td>\n",
       "      <td>Actualiteit</td>\n",
       "      <td>Actualiteit</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>2024-05-15 16:01:29.742235+02:00</td>\n",
       "      <td>LinearSVC_fulltext</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>10470</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[▁Geme, ente, ▁Amsterdam, &lt;0x0A&gt;, %, ▁Geme, en...</td>\n",
       "      <td>1179</td>\n",
       "      <td>[▁Geme, ente, ▁Amsterdam, &lt;0x0A&gt;, %, ▁Geme, en...</td>\n",
       "      <td>1167</td>\n",
       "      <td>Actualiteit</td>\n",
       "      <td>a72c3857912f5e79874002c849d92da7</td>\n",
       "      <td>test</td>\n",
       "      <td>Gemeente Amsterdam\\n% Gemeenteraad R\\n% Raadsa...</td>\n",
       "      <td>TruncationLlamaTokensFront100Back100</td>\n",
       "      <td>Actualiteit</td>\n",
       "      <td>Actualiteit</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>2024-05-15 16:01:29.742235+02:00</td>\n",
       "      <td>LinearSVC_fulltext</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path     id  num_pages  \\\n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...  10154        1.0   \n",
       "1  /home/azureuser/cloudfiles/code/blobfuse/raads...  10470        2.0   \n",
       "\n",
       "                                       MistralTokens  count_MistralTokens  \\\n",
       "0  [▁x, ▁Geme, ente, ▁Amsterdam, ▁J, ▁C, <0x0A>, ...                  447   \n",
       "1  [▁Geme, ente, ▁Amsterdam, <0x0A>, %, ▁Geme, en...                 1179   \n",
       "\n",
       "                                         LlamaTokens  count_LlamaTokens  \\\n",
       "0  [▁x, ▁Geme, ente, ▁Amsterdam, ▁J, ▁C, <0x0A>, ...                422   \n",
       "1  [▁Geme, ente, ▁Amsterdam, <0x0A>, %, ▁Geme, en...               1167   \n",
       "\n",
       "     old_label                          md5_hash balanced_split  \\\n",
       "0  Actualiteit  2307717591d864eea5918ef27cea118b           test   \n",
       "1  Actualiteit  a72c3857912f5e79874002c849d92da7           test   \n",
       "\n",
       "                                           trunc_txt  \\\n",
       "0  x Gemeente Amsterdam J C\\n% Actualiteit voor d...   \n",
       "1  Gemeente Amsterdam\\n% Gemeenteraad R\\n% Raadsa...   \n",
       "\n",
       "                              trunc_col        label   prediction      model  \\\n",
       "0  TruncationLlamaTokensFront100Back100  Actualiteit  Actualiteit  LinearSVC   \n",
       "1  TruncationLlamaTokensFront100Back100  Actualiteit  Actualiteit  LinearSVC   \n",
       "\n",
       "                              date              run_id  \n",
       "0 2024-05-15 16:01:29.742235+02:00  LinearSVC_fulltext  \n",
       "1 2024-05-15 16:01:29.742235+02:00  LinearSVC_fulltext  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(baseline_predictions.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy', 'classification_report', 'date', 'macro_avg_f1', 'macro_avg_precision', 'macro_avg_recall', 'model', 'run_id', 'runtime', 'split_col', 'test_set', 'test_set_support', 'text_col', 'train_set', 'train_set_support']\n",
      "['accuracy', 'classification_report', 'date', 'macro_avg_f1', 'macro_avg_precision', 'macro_avg_recall', 'model', 'run_id', 'runtime', 'split_col', 'test_set', 'test_set_support', 'text_col', 'train_set', 'train_set_support', 'weighted_avg_f1', 'weighted_avg_precision', 'weighted_avg_recall']\n",
      "['balanced_split', 'count_LlamaTokens', 'count_MistralTokens', 'date', 'id', 'label', 'LlamaTokens', 'md5_hash', 'MistralTokens', 'model', 'num_pages', 'old_label', 'path', 'prediction', 'run_id', 'trunc_col', 'trunc_txt']\n",
      "['date', 'id', 'label', 'path', 'prediction', 'prompt', 'prompt_function', 'response', 'run_id', 'runtime', 'shots', 'test_set', 'text_column', 'train_set']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(list(baseline_overview.columns)))\n",
    "print(sorted(list(llm_overview.columns)))\n",
    "\n",
    "\n",
    "print(sorted(list(baseline_predictions.columns),  key=str.lower))\n",
    "print(sorted(list(llm_predictions.columns),  key=str.lower))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2AmsterdamLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
