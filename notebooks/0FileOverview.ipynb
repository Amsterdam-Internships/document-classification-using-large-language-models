{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash /home/azureuser/cloudfiles/code/blobfuse/blobfuse_raadsinformatie.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     running_demo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m my_run \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcf\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     running_demo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# MAKE SURE TO SET-UP PATH -> use local to run with demo data; use azure to run with complete dataset (access required)\n",
    "# Select where to run notebook: \"azure\" or \"local\"\n",
    "my_run = \"local\"\n",
    "\n",
    "if my_run == \"azure\":\n",
    "    import config_azure as cf\n",
    "    running_demo = False\n",
    "elif my_run == \"local\":\n",
    "    import config as cf\n",
    "    running_demo = True\n",
    "\n",
    "\n",
    "import os\n",
    "if my_run == \"azure\":\n",
    "    if not os.path.exists(cf.HUGGING_CACHE):\n",
    "        os.mkdir(cf.HUGGING_CACHE)\n",
    "    os.environ[\"TRANSFORMERS_CACHE\"] = cf.HUGGING_CACHE\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Explain/show the contents of the different kind of files included in this project. During the project, a lot of extra columns are added to the data, predictions and overview files. Thus in this notebook, all columns are explained. \n",
    "\n",
    "Different kind of files:\n",
    "1. txtfiles_notcleaned.pkl\n",
    "2. txtfiles.pkl\n",
    "3. predictions.pkl\n",
    "4. overview.pkl (experiments)\n",
    "5. overview_model.pkl (fine-tuning of models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common columns\n",
    "The following columns are included in (almost) all files:\n",
    "- label = true class of doc\n",
    "- path = path to OCR file\n",
    "- id = document id\n",
    "- text = extracted text from OCR file\n",
    "- num_pages = amount of pages in pdf file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. txtfiles_notcleaned.pkl\n",
    "\n",
    "This file contains all docs that were scraped. \n",
    "\n",
    "Columns:\n",
    "- tokens = text split into tokens using the NLTK library. These tokens are not used during the research, but needed for the preliminary analysis of the data.\n",
    "- token_count = amount of tokens in text, split using the NLTK library. Equal the length of the tokens columns.\n",
    "- clean_tokens = tokens column, but removed stopwords and interpunction. These tokens are not used during the research, but needed for the preliminary analysis of the data.\n",
    "- clean_tokens_count = amount of tokens in text, split using the NLTK library. Equal the length of the clean_tokens columns.\n",
    "- pdf_path = path to PDF file. Each doc has multiple versions saved, including the OCR version and the PDF version. That's why there is a distinction between path and pdf_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The txtfiles_notcleaned file contains 33117 docs.\n",
      "Columns: ['label', 'path', 'id', 'text', 'tokens', 'token_count', 'clean_tokens', 'clean_tokens_count', 'pdf_path', 'num_pages']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>clean_tokens_count</th>\n",
       "      <th>pdf_path</th>\n",
       "      <th>num_pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Motie</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>0</td>\n",
       "      <td>Gemeente Amsterdam\\n% Gemeenteraad R\\n% Gemeen...</td>\n",
       "      <td>[Gemeente, Amsterdam, %, Gemeenteraad, R, %, G...</td>\n",
       "      <td>395</td>\n",
       "      <td>[Gemeente, Amsterdam, Gemeenteraad, Gemeentebl...</td>\n",
       "      <td>205</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Motie</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gemeente Amsterdam\\n\\n% Gemeenteraad R\\n\\n% Ge...</td>\n",
       "      <td>[Gemeente, Amsterdam, %, Gemeenteraad, R, %, G...</td>\n",
       "      <td>390</td>\n",
       "      <td>[Gemeente, Amsterdam, Gemeenteraad, Gemeentebl...</td>\n",
       "      <td>197</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               path  id  \\\n",
       "0  Motie  /home/azureuser/cloudfiles/code/blobfuse/raads...   0   \n",
       "1  Motie  /home/azureuser/cloudfiles/code/blobfuse/raads...   1   \n",
       "\n",
       "                                                text  \\\n",
       "0  Gemeente Amsterdam\\n% Gemeenteraad R\\n% Gemeen...   \n",
       "1  Gemeente Amsterdam\\n\\n% Gemeenteraad R\\n\\n% Ge...   \n",
       "\n",
       "                                              tokens  token_count  \\\n",
       "0  [Gemeente, Amsterdam, %, Gemeenteraad, R, %, G...          395   \n",
       "1  [Gemeente, Amsterdam, %, Gemeenteraad, R, %, G...          390   \n",
       "\n",
       "                                        clean_tokens  clean_tokens_count  \\\n",
       "0  [Gemeente, Amsterdam, Gemeenteraad, Gemeentebl...                 205   \n",
       "1  [Gemeente, Amsterdam, Gemeenteraad, Gemeentebl...                 197   \n",
       "\n",
       "                                            pdf_path  num_pages  \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...        2.0  \n",
       "1  /home/azureuser/cloudfiles/code/blobfuse/raads...        2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "txtfiles_notcleaned = pd.read_pickle(f\"{cf.output_path}/txtfiles_notcleaned.pkl\")\n",
    "print(f\"The txtfiles_notcleaned file contains {len(txtfiles_notcleaned)} docs.\")\n",
    "print(f\"Columns: {list(txtfiles_notcleaned.columns)}\")\n",
    "display(txtfiles_notcleaned.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. txtfiles.pkl\n",
    "\n",
    "This file contains all documents, without faulty/unclean documents and duplicates. This file is used during the research. \n",
    "\n",
    "What is removed (compared to txtfiles_unclean):\n",
    "- three classes that were deemed to unclean. \n",
    "- faulty documents that only contained gibberish.\n",
    "- duplicates.\n",
    "\n",
    "Columns:\n",
    "- 4split = indicates to which subset the doc belongs to. Incase of 4split, the data is split into train,dev, test and val.\n",
    "- 2split = indicates to which subset the doc belongs to. Incase of 2split, the data is split into train and test.\n",
    "- balanced_split = indicates to which subset the doc belongs to. Incase of 2split, the data is split into train, test and val. Is used for the final experiments.\n",
    "- MistralTokens = text split into tokens using Mistral tokenizer. Needed to shorten the docs for the experiments. Note: since mistral and geitje have the same tokenizer, an extra column GeitjeTokens is not needed.\n",
    "- count_MistralTokens = is count of tokens in MistralTokens, i.e. in how many tokens the text was split by Mistral tokenizer.\n",
    "- LlamaTokens = text split into tokens using Llama tokenizer. Needed to shorten the docs for the experiments.\n",
    "- count_LlamaTokens = is count of tokens in LlamaTokens, i.e. in how many tokens the text was split by Llama tokenizer.\n",
    "- md5_hash = unique id for the content of the doc. Is used to remove duplicates.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The txtfiles file contains 20818 docs.\n",
      "Columns: ['label', 'path', 'id', 'text', 'num_pages', '4split', '2split', 'MistralTokens', 'count_MistralTokens', 'LlamaTokens', 'count_LlamaTokens', 'md5_hash', 'balanced_split']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>4split</th>\n",
       "      <th>2split</th>\n",
       "      <th>MistralTokens</th>\n",
       "      <th>count_MistralTokens</th>\n",
       "      <th>LlamaTokens</th>\n",
       "      <th>count_LlamaTokens</th>\n",
       "      <th>md5_hash</th>\n",
       "      <th>balanced_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Motie</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>1874</td>\n",
       "      <td>x Gemeente Amsterdam R\\nGemeenteraad\\n% Gemeen...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[▁x, ▁Geme, ente, ▁Amsterdam, ▁R, &lt;0x0A&gt;, G, e...</td>\n",
       "      <td>350</td>\n",
       "      <td>[▁x, ▁Geme, ente, ▁Amsterdam, ▁R, &lt;0x0A&gt;, G, e...</td>\n",
       "      <td>346</td>\n",
       "      <td>2f09ba2c967bba0eecf71f846f258a78</td>\n",
       "      <td>discard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Motie</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>230</td>\n",
       "      <td>X Gemeente Amsterdam R\\nGemeenteraad\\n% Gemeen...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[▁X, ▁Geme, ente, ▁Amsterdam, ▁R, &lt;0x0A&gt;, G, e...</td>\n",
       "      <td>1130</td>\n",
       "      <td>[▁X, ▁Geme, ente, ▁Amsterdam, ▁R, &lt;0x0A&gt;, G, e...</td>\n",
       "      <td>1082</td>\n",
       "      <td>d14b33c32ba1e1bcff16320891bdf158</td>\n",
       "      <td>discard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               path    id  \\\n",
       "0  Motie  /home/azureuser/cloudfiles/code/blobfuse/raads...  1874   \n",
       "1  Motie  /home/azureuser/cloudfiles/code/blobfuse/raads...   230   \n",
       "\n",
       "                                                text  num_pages 4split 2split  \\\n",
       "0  x Gemeente Amsterdam R\\nGemeenteraad\\n% Gemeen...        1.0  train  train   \n",
       "1  X Gemeente Amsterdam R\\nGemeenteraad\\n% Gemeen...        2.0  train  train   \n",
       "\n",
       "                                       MistralTokens  count_MistralTokens  \\\n",
       "0  [▁x, ▁Geme, ente, ▁Amsterdam, ▁R, <0x0A>, G, e...                  350   \n",
       "1  [▁X, ▁Geme, ente, ▁Amsterdam, ▁R, <0x0A>, G, e...                 1130   \n",
       "\n",
       "                                         LlamaTokens  count_LlamaTokens  \\\n",
       "0  [▁x, ▁Geme, ente, ▁Amsterdam, ▁R, <0x0A>, G, e...                346   \n",
       "1  [▁X, ▁Geme, ente, ▁Amsterdam, ▁R, <0x0A>, G, e...               1082   \n",
       "\n",
       "                           md5_hash balanced_split  \n",
       "0  2f09ba2c967bba0eecf71f846f258a78        discard  \n",
       "1  d14b33c32ba1e1bcff16320891bdf158        discard  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "txtfiles = pd.read_pickle(f\"{cf.output_path}/txtfiles.pkl\")\n",
    "print(f\"The txtfiles file contains {len(txtfiles)} docs.\")\n",
    "print(f\"Columns: {list(txtfiles.columns)}\")\n",
    "display(txtfiles.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions.pkl\n",
    "In the predictions files all individual predictions are saved. Each experiment has it's own predictions file. There is a slight difference between the predictions files of the baselines and the predictions files of the LLMs.\n",
    "\n",
    "Columns that are the same:\n",
    "- path, id, label\n",
    "- prediction = predicted class of the doc\n",
    "- date = date and time of when prediction was made.\n",
    "- run_id = unique id for each experiment.\n",
    "\n",
    "Column unique to baseline predictions file:\n",
    "- model = model used to make the predictions \n",
    "- trunc_txt = the text of the doc truncated, which is the input. Incase the full doc was used, the value will be N.A.\n",
    "\n",
    "Columns unique to LLM predictions file:\n",
    "- text_column = column of the input dataframe that contained the truncated text. This column was used as input.\n",
    "- prompt_function = function used to format the prompt. All formats can be found in scripts/prompt_template.py\n",
    "- response = the response of the LLM. Prediction not yet extracted.\n",
    "- runtime = the time it took for the model to respond.\n",
    "- prompt = the doc formatted in the prompt. The input given to the LLM.\n",
    "- shots = amount of example docs included in the prompt.\n",
    "\n",
    "\n",
    "Furthermore, because fine-tuned Mistral's predictions needed to be repaired, the prediction files of Mistral for 2epoch and 3epoch contain extra columns:\n",
    "- Original_Prediction = prediction originally extracted, without repair.\n",
    "- matches_complete_regex = True or False, indicates whether the response included a JSON file with the format '{category}'\n",
    "- matched_adjusted_regex = True or False, indicates whether the response matched with 'category}'. If a response is false for matches_complete_regex and true for matches_adjusted_regex, then we know that that response only missed the opening bracket.\n",
    "- prediction = prediction after repair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline_predictions file contains 8 predictions.\n",
      "Columns: ['path', 'id', 'label', 'prediction', 'model', 'date', 'run_id', 'trunc_txt']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>model</th>\n",
       "      <th>date</th>\n",
       "      <th>run_id</th>\n",
       "      <th>trunc_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>26304</td>\n",
       "      <td>Raadsnotulen</td>\n",
       "      <td>Raadsadres</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>2024-06-10 15:28:09.365516+02:00</td>\n",
       "      <td>LinearSVC_fulltext</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>32939</td>\n",
       "      <td>Factsheet</td>\n",
       "      <td>Voordracht</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>2024-06-10 15:28:09.365516+02:00</td>\n",
       "      <td>LinearSVC_fulltext</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path     id         label  \\\n",
       "2   /home/azureuser/cloudfiles/code/blobfuse/raads...  26304  Raadsnotulen   \n",
       "13  /home/azureuser/cloudfiles/code/blobfuse/raads...  32939     Factsheet   \n",
       "\n",
       "    prediction      model                             date  \\\n",
       "2   Raadsadres  LinearSVC 2024-06-10 15:28:09.365516+02:00   \n",
       "13  Voordracht  LinearSVC 2024-06-10 15:28:09.365516+02:00   \n",
       "\n",
       "                run_id trunc_txt  \n",
       "2   LinearSVC_fulltext       NaN  \n",
       "13  LinearSVC_fulltext       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The llm_predictions file contains 1100 predictions.\n",
      "Columns: ['id', 'path', 'text_column', 'prompt_function', 'response', 'prediction', 'label', 'runtime', 'date', 'prompt', 'run_id', 'shots', 'new_prediction']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>text_column</th>\n",
       "      <th>prompt_function</th>\n",
       "      <th>response</th>\n",
       "      <th>prediction</th>\n",
       "      <th>label</th>\n",
       "      <th>runtime</th>\n",
       "      <th>date</th>\n",
       "      <th>prompt</th>\n",
       "      <th>run_id</th>\n",
       "      <th>shots</th>\n",
       "      <th>new_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26304</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>zeroshot_prompt_mistral_llama</td>\n",
       "      <td>{'categorie': Raadsnotulen}</td>\n",
       "      <td>raadsnotulen</td>\n",
       "      <td>raadsnotulen</td>\n",
       "      <td>23.454581</td>\n",
       "      <td>2024-06-03 14:46:15.522548+02:00</td>\n",
       "      <td>Classificeer het document in één van de catego...</td>\n",
       "      <td>FT_AmsterdamDocClassificationMistral200T1Epoch...</td>\n",
       "      <td>0</td>\n",
       "      <td>raadsnotulen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32939</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>zeroshot_prompt_mistral_llama</td>\n",
       "      <td>{'categorie': Onderzoeksrapport}</td>\n",
       "      <td>onderzoeksrapport</td>\n",
       "      <td>factsheet</td>\n",
       "      <td>24.833001</td>\n",
       "      <td>2024-06-03 14:46:40.356687+02:00</td>\n",
       "      <td>Classificeer het document in één van de catego...</td>\n",
       "      <td>FT_AmsterdamDocClassificationMistral200T1Epoch...</td>\n",
       "      <td>0</td>\n",
       "      <td>onderzoeksrapport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               path  \\\n",
       "0  26304  /home/azureuser/cloudfiles/code/blobfuse/raads...   \n",
       "1  32939  /home/azureuser/cloudfiles/code/blobfuse/raads...   \n",
       "\n",
       "                          text_column                prompt_function  \\\n",
       "0  TruncationLlamaTokensFront200Back0  zeroshot_prompt_mistral_llama   \n",
       "1  TruncationLlamaTokensFront200Back0  zeroshot_prompt_mistral_llama   \n",
       "\n",
       "                           response         prediction         label  \\\n",
       "0       {'categorie': Raadsnotulen}       raadsnotulen  raadsnotulen   \n",
       "1  {'categorie': Onderzoeksrapport}  onderzoeksrapport     factsheet   \n",
       "\n",
       "     runtime                             date  \\\n",
       "0  23.454581 2024-06-03 14:46:15.522548+02:00   \n",
       "1  24.833001 2024-06-03 14:46:40.356687+02:00   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Classificeer het document in één van de catego...   \n",
       "1  Classificeer het document in één van de catego...   \n",
       "\n",
       "                                              run_id  shots     new_prediction  \n",
       "0  FT_AmsterdamDocClassificationMistral200T1Epoch...      0       raadsnotulen  \n",
       "1  FT_AmsterdamDocClassificationMistral200T1Epoch...      0  onderzoeksrapport  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mistral_predictions file contains 200 predictions.\n",
      "Columns: ['id', 'path', 'text_column', 'prompt_function', 'response', 'Original_Prediction', 'label', 'runtime', 'date', 'prompt', 'run_id', 'shots', 'matches_complete_regex', 'matches_adjusted_regex', 'prediction', 'new_prediction']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>text_column</th>\n",
       "      <th>prompt_function</th>\n",
       "      <th>response</th>\n",
       "      <th>Original_Prediction</th>\n",
       "      <th>label</th>\n",
       "      <th>runtime</th>\n",
       "      <th>date</th>\n",
       "      <th>prompt</th>\n",
       "      <th>run_id</th>\n",
       "      <th>shots</th>\n",
       "      <th>matches_complete_regex</th>\n",
       "      <th>matches_adjusted_regex</th>\n",
       "      <th>prediction</th>\n",
       "      <th>new_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26304</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>zeroshot_prompt_mistral_llama</td>\n",
       "      <td>'categorie': Raadsnotulen}</td>\n",
       "      <td>NoPredictionFormat</td>\n",
       "      <td>raadsnotulen</td>\n",
       "      <td>22.356095</td>\n",
       "      <td>2024-05-31 17:25:30.266286+02:00</td>\n",
       "      <td>Classificeer het document in één van de catego...</td>\n",
       "      <td>FT_AmsterdamDocClassificationMistral200T2Epoch...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>raadsnotulen</td>\n",
       "      <td>NoPredictionFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32939</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>zeroshot_prompt_mistral_llama</td>\n",
       "      <td>'categorie': Onderzoeksrapport}</td>\n",
       "      <td>NoPredictionFormat</td>\n",
       "      <td>factsheet</td>\n",
       "      <td>23.359804</td>\n",
       "      <td>2024-05-31 17:25:53.744179+02:00</td>\n",
       "      <td>Classificeer het document in één van de catego...</td>\n",
       "      <td>FT_AmsterdamDocClassificationMistral200T2Epoch...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>onderzoeksrapport</td>\n",
       "      <td>NoPredictionFormat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               path  \\\n",
       "0  26304  /home/azureuser/cloudfiles/code/blobfuse/raads...   \n",
       "1  32939  /home/azureuser/cloudfiles/code/blobfuse/raads...   \n",
       "\n",
       "                          text_column                prompt_function  \\\n",
       "0  TruncationLlamaTokensFront200Back0  zeroshot_prompt_mistral_llama   \n",
       "1  TruncationLlamaTokensFront200Back0  zeroshot_prompt_mistral_llama   \n",
       "\n",
       "                          response Original_Prediction         label  \\\n",
       "0       'categorie': Raadsnotulen}  NoPredictionFormat  raadsnotulen   \n",
       "1  'categorie': Onderzoeksrapport}  NoPredictionFormat     factsheet   \n",
       "\n",
       "     runtime                             date  \\\n",
       "0  22.356095 2024-05-31 17:25:30.266286+02:00   \n",
       "1  23.359804 2024-05-31 17:25:53.744179+02:00   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Classificeer het document in één van de catego...   \n",
       "1  Classificeer het document in één van de catego...   \n",
       "\n",
       "                                              run_id  shots  \\\n",
       "0  FT_AmsterdamDocClassificationMistral200T2Epoch...      0   \n",
       "1  FT_AmsterdamDocClassificationMistral200T2Epoch...      0   \n",
       "\n",
       "   matches_complete_regex  matches_adjusted_regex         prediction  \\\n",
       "0                       0                       1       raadsnotulen   \n",
       "1                       0                       1  onderzoeksrapport   \n",
       "\n",
       "       new_prediction  \n",
       "0  NoPredictionFormat  \n",
       "1  NoPredictionFormat  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_predictions = pd.read_pickle(f\"{cf.output_path}/trial/LinearSVCpredictions.pkl\")\n",
    "print(f\"The baseline_predictions file contains {len(baseline_predictions)} predictions.\")\n",
    "print(f\"Columns: {list(baseline_predictions.columns)}\")\n",
    "display(baseline_predictions.head(2))\n",
    "\n",
    "\n",
    "llm_predictions =  pd.read_pickle(f\"{cf.output_path}/predictionsFinal/finetuning/1epochs/MistralFirst200Last0Predictions.pkl\")\n",
    "print(f\"The llm_predictions file contains {len(llm_predictions)} predictions.\")\n",
    "print(f\"Columns: {list(llm_predictions.columns)}\")\n",
    "display(llm_predictions.head(2))\n",
    "\n",
    "mistral_predictions =  pd.read_pickle(f\"{cf.output_path}/predictionsFinal/finetuning/2epochs/MistralFirst200Last0Predictions.pkl\")\n",
    "print(f\"The mistral_predictions file contains {len(mistral_predictions)} predictions.\")\n",
    "print(f\"Columns: {list(mistral_predictions.columns)}\")\n",
    "display(mistral_predictions.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview.pkl\n",
    "The overview files for the experiments contain for each experiment exactly one row with meta data about the experiments. There is not difference between the overview file of the baselines and the overview files of the LLMs.\n",
    "\n",
    "Columns:\n",
    "- model = model used to get predictions.\n",
    "- run_id = id of the experiment, unique for each experiment.\n",
    "- date = date and time when experiment finished running.\n",
    "- train_set = the subset of the split_col that was used as training set. Depending on the split and goal of the experiment this can be either train or dev.\n",
    "- test_set = the subset of the split_col that was used as test set. Depending on the split and goal of the experiment this can be either test or val.\n",
    "- train_set_support = amount of docs in training set.\n",
    "- test_set_support = amount of docs in test set. \n",
    "- split_col = column that indicates the split, shows which split was used. Can be 2split, 4split or balanced_split.\n",
    "- text_col = column that contained the text of the document. Indicates how doc was shortened.\n",
    "- runtime = total time it took to run the experiment in seconds.\n",
    "- 'accuracy', 'macro_avg_precision', 'macro_avg_recall', 'macro_avg_f1', 'weighted_avg_precision', 'weighted_avg_recall', 'weighted_avg_f1', 'classification_report' = evaluation scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline_overview file contains 3 experiments.\n",
      "Columns: ['model', 'run_id', 'date', 'train_set', 'test_set', 'train_set_support', 'test_set_support', 'split_col', 'text_col', 'runtime', 'accuracy', 'macro_avg_precision', 'macro_avg_recall', 'macro_avg_f1', 'weighted_avg_precision', 'weighted_avg_recall', 'weighted_avg_f1', 'classification_report']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>run_id</th>\n",
       "      <th>date</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>train_set_support</th>\n",
       "      <th>test_set_support</th>\n",
       "      <th>split_col</th>\n",
       "      <th>text_col</th>\n",
       "      <th>runtime</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro_avg_precision</th>\n",
       "      <th>macro_avg_recall</th>\n",
       "      <th>macro_avg_f1</th>\n",
       "      <th>weighted_avg_precision</th>\n",
       "      <th>weighted_avg_recall</th>\n",
       "      <th>weighted_avg_f1</th>\n",
       "      <th>classification_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmsterdamDocClassificationMistral200T1Epochs</td>\n",
       "      <td>FT_AmsterdamDocClassificationMistral200T1Epoch...</td>\n",
       "      <td>2024-06-03 21:28:18.488289+02:00</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>9900</td>\n",
       "      <td>1100</td>\n",
       "      <td>balanced_split</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>24081.369143</td>\n",
       "      <td>0.895455</td>\n",
       "      <td>0.921469</td>\n",
       "      <td>0.895455</td>\n",
       "      <td>0.888446</td>\n",
       "      <td>0.921469</td>\n",
       "      <td>0.895455</td>\n",
       "      <td>0.888446</td>\n",
       "      <td>precision    recall  f1-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmsterdamDocClassificationGEITje200T1Epochs</td>\n",
       "      <td>FT_AmsterdamDocClassificationGEITje200T1Epochs...</td>\n",
       "      <td>2024-06-04 10:25:38.531475+02:00</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>9900</td>\n",
       "      <td>1100</td>\n",
       "      <td>balanced_split</td>\n",
       "      <td>TruncationLlamaTokensFront200Back0</td>\n",
       "      <td>25634.273609</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.925842</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.881006</td>\n",
       "      <td>0.925842</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.881006</td>\n",
       "      <td>precision    recall  f1-s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model  \\\n",
       "0  AmsterdamDocClassificationMistral200T1Epochs   \n",
       "0   AmsterdamDocClassificationGEITje200T1Epochs   \n",
       "\n",
       "                                              run_id  \\\n",
       "0  FT_AmsterdamDocClassificationMistral200T1Epoch...   \n",
       "0  FT_AmsterdamDocClassificationGEITje200T1Epochs...   \n",
       "\n",
       "                              date train_set test_set  train_set_support  \\\n",
       "0 2024-06-03 21:28:18.488289+02:00     train     test               9900   \n",
       "0 2024-06-04 10:25:38.531475+02:00     train     test               9900   \n",
       "\n",
       "   test_set_support       split_col                            text_col  \\\n",
       "0              1100  balanced_split  TruncationLlamaTokensFront200Back0   \n",
       "0              1100  balanced_split  TruncationLlamaTokensFront200Back0   \n",
       "\n",
       "        runtime  accuracy  macro_avg_precision  macro_avg_recall  \\\n",
       "0  24081.369143  0.895455             0.921469          0.895455   \n",
       "0  25634.273609  0.890909             0.925842          0.890909   \n",
       "\n",
       "   macro_avg_f1  weighted_avg_precision  weighted_avg_recall  weighted_avg_f1  \\\n",
       "0      0.888446                0.921469             0.895455         0.888446   \n",
       "0      0.881006                0.925842             0.890909         0.881006   \n",
       "\n",
       "                               classification_report  \n",
       "0                       precision    recall  f1-s...  \n",
       "0                       precision    recall  f1-s...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_overview = pd.read_pickle(f\"{cf.output_path}/predictionsFinal/finetuning/1epochs/overview.pkl\")\n",
    "print(f\"The baseline_overview file contains {len(llm_overview)} experiments.\")\n",
    "print(f\"Columns: {list(llm_overview.columns)}\")\n",
    "display(llm_overview.head(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RequirementsEnv",
   "language": "python",
   "name": "requirementsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
