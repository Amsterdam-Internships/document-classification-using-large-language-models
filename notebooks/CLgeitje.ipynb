{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash /home/azureuser/cloudfiles/code/blobfuse/blobfuse_raadsinformatie.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Select where to run notebook: \"azure\" or \"local\"\n",
    "my_run = \"azure\"\n",
    "\n",
    "import my_secrets as sc\n",
    "import settings as st\n",
    "\n",
    "if my_run == \"azure\":\n",
    "    import config_azure as cf\n",
    "elif my_run == \"local\":\n",
    "    import config as cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load data - just first 2 docs of training set\n",
    "- text truncation\n",
    "- load file with prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_truncation(tokens_list, maximum=500):\n",
    "    selected_tokens = tokens_list[:maximum]  # Select the first 300 tokens\n",
    "    return ' '.join(selected_tokens)  # Convert the list back to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Raadsnotulen', 'Factsheets', 'Actualiteit', 'Termijnagenda', 'Onderzoeksrapport', 'Motie', 'Raadsadres', 'Schriftelijke Vragen', 'Agenda', 'Besluit', 'Brief', 'Voordracht']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61357/3685248844.py:5: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  df['text_trunc'] = df['tokens'].apply(text_truncation,100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>set</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>clean_tokens_count</th>\n",
       "      <th>pdf_path</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_trunc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Motie</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>Gemeente Amsterdam\\n% Gemeenteraad R\\n% Gemeen...</td>\n",
       "      <td>[Gemeente, Amsterdam, %, Gemeenteraad, R, %, G...</td>\n",
       "      <td>395</td>\n",
       "      <td>[Gemeente, Amsterdam, Gemeenteraad, Gemeentebl...</td>\n",
       "      <td>205</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Gemeente Amsterdam Gemeenteraad Gemeenteblad M...</td>\n",
       "      <td>Gemeente Amsterdam % Gemeenteraad R % Gemeente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Motie</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>Gemeente Amsterdam\\n\\n% Gemeenteraad R\\n\\n% Ge...</td>\n",
       "      <td>[Gemeente, Amsterdam, %, Gemeenteraad, R, %, G...</td>\n",
       "      <td>390</td>\n",
       "      <td>[Gemeente, Amsterdam, Gemeenteraad, Gemeentebl...</td>\n",
       "      <td>197</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Gemeente Amsterdam Gemeenteraad Gemeenteblad M...</td>\n",
       "      <td>Gemeente Amsterdam % Gemeenteraad R % Gemeente...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               path  id    set  \\\n",
       "0  Motie  /home/azureuser/cloudfiles/code/blobfuse/raads...   0  train   \n",
       "1  Motie  /home/azureuser/cloudfiles/code/blobfuse/raads...   1  train   \n",
       "\n",
       "                                                text  \\\n",
       "0  Gemeente Amsterdam\\n% Gemeenteraad R\\n% Gemeen...   \n",
       "1  Gemeente Amsterdam\\n\\n% Gemeenteraad R\\n\\n% Ge...   \n",
       "\n",
       "                                              tokens  token_count  \\\n",
       "0  [Gemeente, Amsterdam, %, Gemeenteraad, R, %, G...          395   \n",
       "1  [Gemeente, Amsterdam, %, Gemeenteraad, R, %, G...          390   \n",
       "\n",
       "                                        clean_tokens  clean_tokens_count  \\\n",
       "0  [Gemeente, Amsterdam, Gemeenteraad, Gemeentebl...                 205   \n",
       "1  [Gemeente, Amsterdam, Gemeenteraad, Gemeentebl...                 197   \n",
       "\n",
       "                                            pdf_path  num_pages  \\\n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raads...        2.0   \n",
       "1  /home/azureuser/cloudfiles/code/blobfuse/raads...        2.0   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  Gemeente Amsterdam Gemeenteraad Gemeenteblad M...   \n",
       "1  Gemeente Amsterdam Gemeenteraad Gemeenteblad M...   \n",
       "\n",
       "                                          text_trunc  \n",
       "0  Gemeente Amsterdam % Gemeenteraad R % Gemeente...  \n",
       "1  Gemeente Amsterdam % Gemeenteraad R % Gemeente...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(f\"{cf.output_path}/txtfiles.pkl\")\n",
    "print(list(set(df['label'])))\n",
    "df = df.loc[df['set']=='train'].head(2)\n",
    "df['text_trunc'] = df['tokens'].apply(text_truncation,100)\n",
    "display(df)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../scripts/') \n",
    "import prompt_template as pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tryout GEITje\n",
    "Load chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 10:39:13.377443: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-04-03 10:39:13.377478: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2f0eaee00e40e9b84f0755014ccf8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, Conversation\n",
    "\n",
    "chatbot = pipeline(task='conversational', model='Rijgersberg/GEITje-7B-chat-v2',\n",
    "                   device_map='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: c7f94172-c476-4fc4-a1cf-27485289b9d1\n",
      "user: Welk woord hoort er niet in dit rijtje thuis: \"auto, vliegtuig, geitje, bus\"?\n",
      "assistant: Geitje hoort er niet in thuis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chatbot(\n",
    "    Conversation('Welk woord hoort er niet in dit rijtje thuis: \"auto, vliegtuig, geitje, bus\"?')\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7d8ce18c2e49deaf46f51213ee5ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 14.58 GiB of which 101.62 MiB is free. Including non-PyTorch memory, this process has 14.48 GiB memory in use. Of the allocated memory 14.33 GiB is allocated by PyTorch, and 19.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRijgersberg/GEITje-7B-chat-v2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_implementation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meager\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(conversation, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1_000\u001b[39m):\n",
      "File \u001b[0;32m/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    560\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m )\n",
      "File \u001b[0;32m/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/transformers/modeling_utils.py:3502\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3494\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3495\u001b[0m     (\n\u001b[1;32m   3496\u001b[0m         model,\n\u001b[1;32m   3497\u001b[0m         missing_keys,\n\u001b[1;32m   3498\u001b[0m         unexpected_keys,\n\u001b[1;32m   3499\u001b[0m         mismatched_keys,\n\u001b[1;32m   3500\u001b[0m         offload_index,\n\u001b[1;32m   3501\u001b[0m         error_msgs,\n\u001b[0;32m-> 3502\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3509\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3510\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3513\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3514\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3518\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3520\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   3521\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/transformers/modeling_utils.py:3926\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3924\u001b[0m                     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, state_dict)\n\u001b[1;32m   3925\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3926\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3927\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3928\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3929\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3930\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3931\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3932\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3933\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3934\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3935\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3936\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3937\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3938\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3939\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3940\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3941\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3942\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3943\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   3944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/transformers/modeling_utils.py:805\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys)\u001b[0m\n\u001b[1;32m    798\u001b[0m     state_dict_index \u001b[38;5;241m=\u001b[39m offload_weight(param, param_name, model, state_dict_folder, state_dict_index)\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    800\u001b[0m     hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m hf_quantizer\u001b[38;5;241m.\u001b[39mrequires_parameters_quantization)\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m hf_quantizer\u001b[38;5;241m.\u001b[39mcheck_quantized_param(model, param, param_name, state_dict))\n\u001b[1;32m    803\u001b[0m ):\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[39;00m\n\u001b[0;32m--> 805\u001b[0m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n",
      "File \u001b[0;32m/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/accelerate/utils/modeling.py:387\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    385\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 387\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 14.58 GiB of which 101.62 MiB is free. Including non-PyTorch memory, this process has 14.48 GiB memory in use. Of the allocated memory 14.33 GiB is allocated by PyTorch, and 19.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_name = 'Rijgersberg/GEITje-7B-chat-v2'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16,\n",
    "                                             low_cpu_mem_usage=True, attn_implementation='eager',\n",
    "                                             device_map=device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def generate(conversation, temperature=0.2, top_k=50, max_new_tokens=1_000):\n",
    "    tokenized = tokenizer.apply_chat_template(conversation, add_generation_prompt=True,\n",
    "                                              return_tensors='pt').to(device)\n",
    "    outputs = model.generate(tokenized, do_sample=True, temperature=temperature,\n",
    "                             top_k=top_k, max_new_tokens=max_new_tokens)\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Welk woord hoort er niet in dit rijtje thuis: \"auto, vliegtuig, geitje, bus\"?'\n",
    "    }\n",
    "]\n",
    "print(generate(conversation))\n",
    "# <|user|>\n",
    "# Welk woord hoort er niet in dit rijtje thuis: \"auto, vliegtuig, geitje, bus\"? \n",
    "# <|assistant|>\n",
    "# Het woord dat niet op zijn plaats staat is 'geit'. Een geit zou niet tussen een lijst van vervoersmiddelen moeten staan. Het past beter bij een boerderijthema of dierenlijst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment set-up\n",
    "Prompt GEITje for each document and save the prediction, return response, response time and the prompt version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import pytz\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# given the string response, extract the prediction\n",
    "def get_prediction_from_response(response):\n",
    "    # get a list of the possible classes\n",
    "    classes_list = pt.get_class_list()\n",
    "\n",
    "    predictions = [True if category.lower() in response.lower() else False for category in classes_list]\n",
    "\n",
    "    # check if multiple classes were named, this is a prediction error\n",
    "    if Counter(predictions)[True] > 1:\n",
    "        return \"PredictionError\"\n",
    "\n",
    "    # check if exactly one class is named, this is the prediction\n",
    "    elif Counter(predictions)[True] == 1:\n",
    "        prediction = [category.lower() for category in classes_list if category.lower() in response.lower()]\n",
    "        return prediction[0]\n",
    "\n",
    "    # if no class is named, then this is a no prediction error\n",
    "    else:\n",
    "        return 'NoPrediction'\n",
    "\n",
    "# extract the promptfunction name\n",
    "def get_promptfunction_name(prompt_function):\n",
    "    string = f\"{prompt_function}\"\n",
    "    match = re.search(r'<function\\s+(\\w+)', string)\n",
    "    if match:\n",
    "        function_name = match.group(1)\n",
    "        return function_name\n",
    "    else:\n",
    "        return f\"{prompt_function}\"\n",
    "    \n",
    "\n",
    "def get_datetime():\n",
    "    current_datetime_utc = datetime.datetime.now(pytz.utc)\n",
    "\n",
    "    # Convert UTC time to Dutch time (CET)\n",
    "    dutch_timezone = pytz.timezone('Europe/Amsterdam')\n",
    "    current_datetime_dutch = current_datetime_utc.astimezone(dutch_timezone)\n",
    "    return current_datetime_dutch\n",
    "        \n",
    "\n",
    "def get_runid(path):\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_pickle(path)\n",
    "        return max(df['run_id'])+1, df\n",
    "\n",
    "    else:\n",
    "        return 0, pd.DataFrame()\n",
    "    \n",
    "def update_overview_results(df, model_name, subset=None):\n",
    " \n",
    "    evaluation_dict = classification_report(df['label'], df['prediction'], output_dict=True)\n",
    "    evaluation = pd.DataFrame(evaluation_dict).transpose()\n",
    "    \n",
    "    new_row = {\n",
    "        'run_id':df.iloc[0]['run_id'],\n",
    "        'model':model_name,\n",
    "        'prompt_function':df.iloc[0]['prompt_function'],\n",
    "        'text_column':df.iloc[0]['text_column'],\n",
    "        'date': get_datetime(),\n",
    "        'runtime':sum(df['runtime']),\n",
    "        'set':subset,\n",
    "        'support':evaluation.iloc[-1]['support'],\n",
    "        'accuracy': evaluation_dict['accuracy'],\n",
    "\n",
    "        'recall_weighted_avg':evaluation.loc[evaluation.index=='weighted avg']['recall'].values[0],\n",
    "        'precision_weighted_avg': evaluation.loc[evaluation.index=='weighted avg']['precision'].values[0],\n",
    "        'f1_weighted_avg': evaluation.loc[evaluation.index=='weighted avg']['f1-score'].values[0],\n",
    "\n",
    "        'recall_macro_avg':evaluation.loc[evaluation.index=='macro avg']['recall'].values[0],\n",
    "        'precision_macro_avg': evaluation.loc[evaluation.index=='macro avg']['precision'].values[0],\n",
    "        'f1_macro_avg': evaluation.loc[evaluation.index=='macro avg']['f1-score'].values[0],\n",
    "\n",
    "\n",
    "        'recall_classes': dict(zip(evaluation.index[0:-3], evaluation['recall'][0:-3])),\n",
    "        'precision_classes': dict(zip(evaluation.index[0:-3], evaluation['precision'][0:-3])),\n",
    "        'f1_classes': dict(zip(evaluation.index[0:-3], evaluation['f1-score'][0:-3])),\n",
    "        'support_classes': dict(zip(evaluation.index[0:-3], evaluation['support'][0:-3])),\n",
    "\n",
    "        'doc_paths':list(df['path'].values)\n",
    "        \n",
    "    }\n",
    "    results = pd.DataFrame(columns=new_row.keys())\n",
    "    results.loc[len(results)] = new_row\n",
    "   \n",
    "    path = f\"{cf.output_path}/overview_results.pkl\"\n",
    "    if os.path.exists(path):\n",
    "        earlier_results = pd.read_pickle(path)\n",
    "        results = pd.concat([earlier_results, results])\n",
    "\n",
    "    results.to_pickle(path)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "update_overview_results(res, 'geitje')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_function</th>\n",
       "      <th>text_column</th>\n",
       "      <th>date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>set</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall_weighted_avg</th>\n",
       "      <th>precision_weighted_avg</th>\n",
       "      <th>f1_weighted_avg</th>\n",
       "      <th>recall_macro_avg</th>\n",
       "      <th>precision_macro_avg</th>\n",
       "      <th>f1_macro_avg</th>\n",
       "      <th>recall_classes</th>\n",
       "      <th>precision_classes</th>\n",
       "      <th>f1_classes</th>\n",
       "      <th>support_classes</th>\n",
       "      <th>doc_paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>text_trunc</td>\n",
       "      <td>2024-04-03 15:08:43.626104+02:00</td>\n",
       "      <td>18.881136</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'brief': 0.0, 'motie': 0.0, 'voordracht': 0.0}</td>\n",
       "      <td>{'brief': 0.0, 'motie': 0.0, 'voordracht': 0.0}</td>\n",
       "      <td>{'brief': 0.0, 'motie': 0.0, 'voordracht': 0.0}</td>\n",
       "      <td>{'brief': 0.0, 'motie': 2.0, 'voordracht': 0.0}</td>\n",
       "      <td>[/home/azureuser/cloudfiles/code/blobfuse/raad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>text_trunc</td>\n",
       "      <td>2024-04-03 15:09:15.278413+02:00</td>\n",
       "      <td>18.851995</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'brief': 0.0, 'motie': 0.0, 'voordracht': 0.0}</td>\n",
       "      <td>{'brief': 0.0, 'motie': 0.0, 'voordracht': 0.0}</td>\n",
       "      <td>{'brief': 0.0, 'motie': 0.0, 'voordracht': 0.0}</td>\n",
       "      <td>{'brief': 0.0, 'motie': 2.0, 'voordracht': 0.0}</td>\n",
       "      <td>[/home/azureuser/cloudfiles/code/blobfuse/raad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id                          model prompt_function text_column  \\\n",
       "0       0  Rijgersberg/GEITje-7B-chat-v2   simple_prompt  text_trunc   \n",
       "0       1  Rijgersberg/GEITje-7B-chat-v2   simple_prompt  text_trunc   \n",
       "\n",
       "                              date    runtime   set  support  accuracy  \\\n",
       "0 2024-04-03 15:08:43.626104+02:00  18.881136  None      2.0       0.0   \n",
       "0 2024-04-03 15:09:15.278413+02:00  18.851995  None      2.0       0.0   \n",
       "\n",
       "   recall_weighted_avg  precision_weighted_avg  f1_weighted_avg  \\\n",
       "0                  0.0                     0.0              0.0   \n",
       "0                  0.0                     0.0              0.0   \n",
       "\n",
       "   recall_macro_avg  precision_macro_avg  f1_macro_avg  \\\n",
       "0               0.0                  0.0           0.0   \n",
       "0               0.0                  0.0           0.0   \n",
       "\n",
       "                                    recall_classes  \\\n",
       "0  {'brief': 0.0, 'motie': 0.0, 'voordracht': 0.0}   \n",
       "0  {'brief': 0.0, 'motie': 0.0, 'voordracht': 0.0}   \n",
       "\n",
       "                                 precision_classes  \\\n",
       "0  {'brief': 0.0, 'motie': 0.0, 'voordracht': 0.0}   \n",
       "0  {'brief': 0.0, 'motie': 0.0, 'voordracht': 0.0}   \n",
       "\n",
       "                                        f1_classes  \\\n",
       "0  {'brief': 0.0, 'motie': 0.0, 'voordracht': 0.0}   \n",
       "0  {'brief': 0.0, 'motie': 0.0, 'voordracht': 0.0}   \n",
       "\n",
       "                                   support_classes  \\\n",
       "0  {'brief': 0.0, 'motie': 2.0, 'voordracht': 0.0}   \n",
       "0  {'brief': 0.0, 'motie': 2.0, 'voordracht': 0.0}   \n",
       "\n",
       "                                           doc_paths  \n",
       "0  [/home/azureuser/cloudfiles/code/blobfuse/raad...  \n",
       "0  [/home/azureuser/cloudfiles/code/blobfuse/raad...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>text_column</th>\n",
       "      <th>prompt_function</th>\n",
       "      <th>response</th>\n",
       "      <th>prediction</th>\n",
       "      <th>label</th>\n",
       "      <th>runtime</th>\n",
       "      <th>date</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>text_trunc</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>Brief</td>\n",
       "      <td>brief</td>\n",
       "      <td>motie</td>\n",
       "      <td>7.803468</td>\n",
       "      <td>2024-04-03 15:08:32.485823+02:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>text_trunc</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>Voordracht</td>\n",
       "      <td>voordracht</td>\n",
       "      <td>motie</td>\n",
       "      <td>11.077668</td>\n",
       "      <td>2024-04-03 15:08:43.564827+02:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>text_trunc</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>Brief</td>\n",
       "      <td>brief</td>\n",
       "      <td>motie</td>\n",
       "      <td>7.768863</td>\n",
       "      <td>2024-04-03 15:09:04.137299+02:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>text_trunc</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>Voordracht</td>\n",
       "      <td>voordracht</td>\n",
       "      <td>motie</td>\n",
       "      <td>11.083132</td>\n",
       "      <td>2024-04-03 15:09:15.221748+02:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               path text_column  \\\n",
       "0   0  /home/azureuser/cloudfiles/code/blobfuse/raads...  text_trunc   \n",
       "1   1  /home/azureuser/cloudfiles/code/blobfuse/raads...  text_trunc   \n",
       "0   0  /home/azureuser/cloudfiles/code/blobfuse/raads...  text_trunc   \n",
       "1   1  /home/azureuser/cloudfiles/code/blobfuse/raads...  text_trunc   \n",
       "\n",
       "  prompt_function    response  prediction  label    runtime  \\\n",
       "0   simple_prompt       Brief       brief  motie   7.803468   \n",
       "1   simple_prompt  Voordracht  voordracht  motie  11.077668   \n",
       "0   simple_prompt       Brief       brief  motie   7.768863   \n",
       "1   simple_prompt  Voordracht  voordracht  motie  11.083132   \n",
       "\n",
       "                              date  run_id  \n",
       "0 2024-04-03 15:08:32.485823+02:00       0  \n",
       "1 2024-04-03 15:08:43.564827+02:00       0  \n",
       "0 2024-04-03 15:09:04.137299+02:00       1  \n",
       "1 2024-04-03 15:09:15.221748+02:00       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yeet = pd.read_pickle(f\"{cf.output_path}/overview_results.pkl\")\n",
    "display(yeet)\n",
    "\n",
    "yeet = pd.read_pickle(f\"{cf.output_path}/predictions/ICgeitje_predictions.pkl\")\n",
    "display(yeet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/anaconda/envs/ThesisAmsterdamEnvironment19/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>text_column</th>\n",
       "      <th>prompt_function</th>\n",
       "      <th>response</th>\n",
       "      <th>prediction</th>\n",
       "      <th>label</th>\n",
       "      <th>runtime</th>\n",
       "      <th>date</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>text_trunc</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>Brief</td>\n",
       "      <td>brief</td>\n",
       "      <td>motie</td>\n",
       "      <td>7.768863</td>\n",
       "      <td>2024-04-03 15:09:04.137299+02:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
       "      <td>text_trunc</td>\n",
       "      <td>simple_prompt</td>\n",
       "      <td>Voordracht</td>\n",
       "      <td>voordracht</td>\n",
       "      <td>motie</td>\n",
       "      <td>11.083132</td>\n",
       "      <td>2024-04-03 15:09:15.221748+02:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               path text_column  \\\n",
       "0   0  /home/azureuser/cloudfiles/code/blobfuse/raads...  text_trunc   \n",
       "1   1  /home/azureuser/cloudfiles/code/blobfuse/raads...  text_trunc   \n",
       "\n",
       "  prompt_function    response  prediction  label    runtime  \\\n",
       "0   simple_prompt       Brief       brief  motie   7.768863   \n",
       "1   simple_prompt  Voordracht  voordracht  motie  11.083132   \n",
       "\n",
       "                              date  run_id  \n",
       "0 2024-04-03 15:09:04.137299+02:00       1  \n",
       "1 2024-04-03 15:09:15.221748+02:00       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "\"\"\" Given a dataframe with txt, return a df with predictions \"\"\"\n",
    "# docs_df = dataframe with the documents that need to be predicted\n",
    "# text_column = name of the column that includes the input_text. Can be different based on the text representation method. \n",
    "# prompt_function = prompt template -> ONLY prompt templates that take classes and doc as input (ZERO SHOT)\n",
    "\n",
    "def zero_shot_predictions_incontextlearning(docs_df, text_column, prompt_function):\n",
    "    results_df = pd.DataFrame(columns = ['id', 'path', 'text_column', 'prompt_function', 'response', 'prediction', 'label', 'runtime', 'date'])\n",
    "    \n",
    "    # prompt each document\n",
    "    for index, row in docs_df.iterrows():\n",
    "        start_time = time.time()\n",
    "\n",
    "        # get the prompt, with the doc filled in\n",
    "        txt = row[text_column]\n",
    "        prompt = prompt_function(txt)\n",
    "\n",
    "        # prompt and get the response\n",
    "        converse = chatbot(Conversation(prompt))\n",
    "        response = converse[1]['content']\n",
    "\n",
    "        # extract prediction from response\n",
    "        prediction = get_prediction_from_response(response)\n",
    "\n",
    "        # save results in dataframe\n",
    "        results_df.loc[len(results_df)] = {\n",
    "            'id': row['id'],\n",
    "            'path' : row['path'],\n",
    "            'text_column' : text_column,\n",
    "            'prompt_function': get_promptfunction_name(prompt_function),\n",
    "            'response':response,\n",
    "            'prediction':prediction,\n",
    "            'label':row['label'].lower(),\n",
    "            'runtime':time.time()-start_time,\n",
    "            'date': get_datetime()\n",
    "        }\n",
    "    return results_df\n",
    "\n",
    "\"\"\" Run a prediction function -> can be ZeroShot or FewShot \"\"\"\n",
    "def run_prediction(docs_df, text_column, prompt_function, subset=None, learning='ZeroShot'):\n",
    "    if learning == 'ZeroShot':\n",
    "        # get the predictions\n",
    "        res = zero_shot_predictions_incontextlearning(docs_df, text_column, prompt_function)\n",
    "\n",
    "        # get run_id\n",
    "        path = f\"{cf.output_path}/predictions/ICgeitje_predictions.pkl\"\n",
    "        res['run_id'], predictions_df = get_runid(path)\n",
    "\n",
    "        all_predictions = pd.concat([predictions_df, res])\n",
    "\n",
    "        # save predictions\n",
    "        all_predictions.to_pickle(path)\n",
    "\n",
    "        update_overview_results(res, 'Rijgersberg/GEITje-7B-chat-v2')\n",
    "        return res\n",
    "\n",
    "\n",
    "\n",
    "res = run_prediction(df, 'text_trunc', pt.simple_prompt)\n",
    "display(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ThesisAmsterdamEnvironment19",
   "language": "python",
   "name": "thesisamsterdamenvironment19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
