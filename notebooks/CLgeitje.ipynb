{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "!bash /home/azureuser/cloudfiles/code/blobfuse/blobfuse_raadsinformatie.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1712584227159
        }
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "# Select where to run notebook: \"azure\" or \"local\"\n",
        "my_run = \"azure\"\n",
        "\n",
        "import my_secrets as sc\n",
        "import settings as st\n",
        "\n",
        "if my_run == \"azure\":\n",
        "    import config_azure as cf\n",
        "elif my_run == \"local\":\n",
        "    import config as cf\n",
        "\n",
        "\n",
        "import os\n",
        "if my_run == \"azure\":\n",
        "    if not os.path.exists(cf.HUGGING_CACHE):\n",
        "        os.mkdir(cf.HUGGING_CACHE)\n",
        "    os.environ[\"TRANSFORMERS_CACHE\"] = cf.HUGGING_CACHE\n",
        "\n",
        "# set-up environment - GEITje-7b-chat InContextLearning:\n",
        "# - install blobfuse -> sudo apt-get install blobfuse\n",
        "# - pip install transformers\n",
        "# - pip install torch\n",
        "# - pip install accelerate\n",
        "# - pip install jupyter\n",
        "# - pip install ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notebook overview\n",
        "- Goal: Run experiment for InContext Learning GEITje\n",
        "- Trial run model -> prompt GEITje using, example prompt\n",
        "- Zeroshot prompts\n",
        "- Fewshot prompts\n",
        "\n",
        "Load data and functions:\n",
        "- data is already split\n",
        "- text is already converted to tokens using model tokenizer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# df = pd.read_pickle(f\"{cf.output_path}/txtfiles_tokenizer.pkl\")\n",
        "\n",
        "import sys\n",
        "sys.path.append('../scripts/') \n",
        "import prompt_template as pt\n",
        "import prediction_helperfunctions as ph\n",
        "import truncation as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Trial run Models \n",
        "Code to run the models with a simple prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "2024-05-01 12:48:59.201322: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_geitje = pipeline(task='conversational', model='Rijgersberg/GEITje-7B-chat-v2',\n",
        "                   device_map='auto', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "\n",
        "chatbot_llama = pipeline(task='conversational', model='meta-llama/Llama-2-7b-chat-hf',\n",
        "                   device_map='auto', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "chatbot_mistral = pipeline(task='conversational', model='mistralai/Mistral-7B-Instruct-v0.2',\n",
        "                   device_map='auto', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "## EXAMPLE PROMPT\n",
        "# print(chatbot(\n",
        "    # Conversation('Welk woord hoort er niet in dit rijtje thuis: \"auto, vliegtuig, geitje, bus\"?')\n",
        "# ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Experiment functions\n",
        "Prompt GEITje for each document and save the prediction, return response, response time and the prompt version\n",
        "\n",
        "Code structure:\n",
        "- 2 functions/cells:\n",
        "- predictions_incontextlearning -> given a df with docs that need to be predicted, prompt the model\n",
        "- run the experiment -> built in failsaves (df run in parts, with saves in between)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "from bm25 import BM25\n",
        "\n",
        "\n",
        "\"\"\" Given a dataframe with txt, return a df with predictions \"\"\"\n",
        "# docs_df = dataframe with the documents that need to be predicted\n",
        "# text_column = name of the column that includes the input_text. Can be different based on the text representation method. \n",
        "# prompt_function = prompt template \n",
        "# train_df = dataframe with docs, which can be used as examples/training data/context data\n",
        "# num_examples = number of examples in the prompt\n",
        "\n",
        "def predictions_incontextlearning(chatbot, docs_df, text_column, prompt_function, train_df, num_examples):\n",
        "    results_df = pd.DataFrame(columns = ['id', 'path', 'text_column', 'prompt_function', 'response', 'prediction', 'label', 'runtime', 'date', 'prompt'])\n",
        "\n",
        "\n",
        "    if prompt_function == pt.fewshot_prompt_bm25:\n",
        "        BM25_model = BM25()\n",
        "        BM25_model.fit(train_df[text_column])\n",
        "    \n",
        "    # elif prompt_function == fewshot_prompt_bm25:\n",
        "    #     BM25_model = BM25()\n",
        "    #     BM25_model.fit(train_df[text_column])\n",
        "\n",
        "    # prompt each document\n",
        "    for index, row in docs_df.iterrows():\n",
        "        if (index + 1) % 200 == 0:\n",
        "            print(f\"Iteration {index +1}/{len(docs_df)} completed.\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # get the prompt, with the doc filled in\n",
        "        txt = row[text_column]\n",
        "\n",
        "        # each prompt function takes different arguments\n",
        "        # simple function is zeroshot+simple instruction\n",
        "        if prompt_function == pt.simple_prompt:\n",
        "            prompt = prompt_function(txt)\n",
        "\n",
        "        # elif prompt_function == simple_prompt:\n",
        "        #     prompt = prompt_function(txt)\n",
        "      \n",
        "        # select fewshot examples using bm25\n",
        "        elif prompt_function == pt.fewshot_prompt_bm25:\n",
        "            prompt = prompt_function(txt, train_df, num_examples, text_column, BM25_model)\n",
        "\n",
        "        # elif prompt_function == fewshot_prompt_bm25:\n",
        "        #     prompt = prompt_function(txt, train_df, num_examples, text_column, BM25_model)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Prompt function not recognised. Check if prompt function is in prompt_template.py and included in the options above.\")\n",
        "\n",
        "        # prompt and get the response\n",
        "        converse = chatbot(Conversation(prompt))\n",
        "        response = converse[1]['content']\n",
        "        print(\"label: \", row['label'].lower())\n",
        "        print(\"response: \", response)\n",
        "\n",
        "        # extract prediction from response\n",
        "        prediction = ph.get_prediction_from_response(response)\n",
        "        print(\"prediction:\", prediction)\n",
        "\n",
        "        # save results in dataframe\n",
        "        results_df.loc[len(results_df)] = {\n",
        "            'id': row['id'],\n",
        "            'path' : row['path'],\n",
        "            'text_column' : docs_df.iloc[0]['trunc_col'],\n",
        "            'prompt_function': ph.get_promptfunction_name(prompt_function),\n",
        "            'response':response,\n",
        "            'prediction':prediction,\n",
        "            'label':row['label'].lower(),\n",
        "            'runtime':time.time()-start_time,\n",
        "            'date': ph.get_datetime(),\n",
        "            'prompt':prompt\n",
        "        }\n",
        "    return results_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\"\"\"\n",
        "Function to run GEITje In-Context Learning experiment. \n",
        "The function allows to resume experiment, if run_id matches.\n",
        "\"\"\"\n",
        "# df = dataframe with all docs that need to have a prediction (docs still need to be predict + already predicted)\n",
        "# run_id = unqiue for each experiment. \n",
        "# prompt_function = which prompt from prompt_template.py to use\n",
        "# text_col = colum in df where the text is. (Needs to be already truncated)\n",
        "# split_col = column with the dataset split. Either '2split' (train and test)or '4split'(train, test, dev and val)\n",
        "# subset_train = indicates which subset to use as training. either 'train' or 'dev'\n",
        "# subset_test = indicates which subset to use for testing. either 'test' or 'val'\n",
        "# label_col = column with the true label\n",
        "# prediction_path = path to file where predictions need to be saved.\n",
        "# overview_path = path to file where results of each run need to be saved.\n",
        "# model_name = name of the model. string.\n",
        "# num_exmples = number of exaples given to prompt. zero in case of zeroshot. \n",
        "\n",
        "def run_experiment(chatbot, df, run_id, prompt_function, text_col, split_col, subset_train, subset_test, label_col, prediction_path, overview_path, model_name, num_examples=0):\n",
        "    start_time = time.time()\n",
        "    test_df = df.loc[df[split_col]==subset_test]\n",
        "    train_df = df.loc[df[split_col]==subset_train]\n",
        "    \n",
        "    # get rows of df that still need to be predicted for the specific run_id\n",
        "    to_predict, previous_predictions = ph.get_rows_to_predict(test_df, prediction_path, run_id)\n",
        "\n",
        "    # devide to_predict into subsection of 50 predictions at a time. \n",
        "    # Allows to rerun without problem. And save subsections of 50 predictions.\n",
        "    step_range = list(range(0, len(to_predict), 25))\n",
        "\n",
        "    for i in range(len(step_range)):\n",
        "        try:\n",
        "            sub_to_predict = to_predict.iloc[step_range[i]:step_range[i+1]]\n",
        "            print(f'Starting...{step_range[i]}:{step_range[i+1]} out of {len(to_predict)}')\n",
        "        except Exception as e:\n",
        "            sub_to_predict = to_predict[step_range[i]:]\n",
        "            print(f'Starting...last {len(sub_to_predict)} docs')\n",
        "\n",
        "        # prompt geitje\n",
        "        predictions = predictions_incontextlearning(chatbot, sub_to_predict, text_col, prompt_function, train_df, num_examples)\n",
        "\n",
        "        # save info\n",
        "        predictions['run_id'] = run_id\n",
        "        predictions['train_set'] = subset_train\n",
        "        predictions['test_set'] = subset_test\n",
        "        predictions['shots'] = num_examples\n",
        "\n",
        "        # save new combinations in file\n",
        "        print(\"Dont interrupt, saving predictions...\")\n",
        "        ph.combine_and_save_df(predictions, prediction_path)\n",
        "\n",
        "        # if previous predictions, combine previous with new predictions, to get update classification report\n",
        "        try:\n",
        "            predictions = pd.concat([predictions, previous_predictions])\n",
        "\n",
        "            # set previous predictions to all predictions made until now. Necessary for next loop\n",
        "            previous_predictions = predictions\n",
        "        except Exception as e:\n",
        "            # set previous predictions to all predictions made until now. Necessary for next loop\n",
        "            previous_predictions = predictions\n",
        "\n",
        "        # save results in overview file\n",
        "        date = ph.get_datetime()\n",
        "        y_test = predictions['label']\n",
        "        y_pred = predictions['prediction']\n",
        "        report = classification_report(y_test, y_pred)\n",
        "\n",
        "        overview = pd.DataFrame(\n",
        "            [{\n",
        "                'model':model_name,\n",
        "                'run_id':run_id,\n",
        "                'date': date,\n",
        "                'train_set': subset_train,\n",
        "                'test_set': subset_test,\n",
        "                'train_set_support':len(df.loc[df[split_col]==subset_train]),\n",
        "                'test_set_support':len(predictions),\n",
        "                'split_col':split_col,\n",
        "                'text_col':df.iloc[0]['trunc_col'],\n",
        "                'runtime':sum(predictions['runtime']),\n",
        "                'accuracy': accuracy_score(y_test, y_pred),\n",
        "                'macro_avg_precision': precision_score(y_test, y_pred, average='macro'),\n",
        "                'macro_avg_recall': recall_score(y_test, y_pred, average='macro'),\n",
        "                'macro_avg_f1': f1_score(y_test, y_pred, average='macro'),\n",
        "                'classification_report':report\n",
        "            }   ]\n",
        "        )\n",
        "        # remove previous results of run_id, replace with new/updated results\n",
        "        ph.replace_and_save_df(overview, overview_path, run_id)\n",
        "        print(\"Saving done! Interrupting is allowed.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set up variables that are the same for each model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set  variables, same for each model\n",
        "TRAIN_SET = 'dev' # must be dev or train\n",
        "TEST_SET = 'val' # must be val or test\n",
        "SPLIT_COLUMN = '4split' #must be either 2split or 4split. 2split = data split into train and test. 4split = data split into train, test, dev and val. \n",
        "LABEL_COLUMN = 'label'\n",
        "TEXT_COLUMN = 'trunc_txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = pd.read_pickle(f\"{cf.output_path}/txtfiles_tokenizer.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GEITje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_geitje = pipeline(task='conversational', model='Rijgersberg/GEITje-7B-chat-v2',\n",
        "                   device_map='auto', model_kwargs={'offload_buffers':True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# PREDICTION_PATH = f\"{cf.output_path}/predictions/trialfewShotGeitjepredictions.pkl\"\n",
        "# OVERVIEW_PATH = f\"{cf.output_path}/overview/trialfewShotGeitjepredictions.pkl\"\n",
        "\n",
        "\n",
        "MODEL_NAME = 'GEITje-7B-chat-v2'\n",
        "PROMPT = pt.fewshot_prompt_bm25\n",
        "PROMPT_NAME = ph.get_promptfunction_name(PROMPT)\n",
        "TOKENS_COL = 'LlamaTokens' # column with text split using tokenizer of either mistral (MistralTokens) or Llama (LlamaTokens). Using Llama, because Llama split into more tokens. \n",
        "FRONT_THRESHOLD = 200\n",
        "BACK_THRESHOLD = 0\n",
        "\n",
        "if PROMPT == pt.simple_prompt:\n",
        "    NUMBER_EXAMPLES = 0\n",
        "elif PROMPT == pt.fewshot_prompt_bm25:\n",
        "    NUMBER_EXAMPLES = 2\n",
        "    \n",
        "OVERVIEW_PATH = f\"{cf.output_path}/predictionsVal/in_context/GEITje/{PROMPT_NAME}/overview.pkl\"\n",
        "PREDICTION_PATH = f\"{cf.output_path}/predictionsVal/in_context/GEITje/{PROMPT_NAME}/predictions.pkl\"\n",
        "\n",
        "small = txt.iloc[16:22]\n",
        "small['4split']=['val', 'dev', 'dev', 'dev', 'dev', 'dev']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----- EXPERIMENT --------\n",
        "\n",
        "# add new column with truncated text -> new dataframe with column + new column name\n",
        "trunc_df = tf.add_truncation_column(txt,'text', TOKENS_COL, FRONT_THRESHOLD, BACK_THRESHOLD)\n",
        "\n",
        "run_id = f'IC_{MODEL_NAME}{PROMPT_NAME}{TOKENS_COL}{FRONT_THRESHOLD}_{BACK_THRESHOLD}{TRAIN_SET}{TEST_SET}_numEx{NUMBER_EXAMPLES}'\n",
        "\n",
        "# if new run MAKE SURE RUN_ID IS UNIQUE, if want to resume run, pass in that run_id\n",
        "run_experiment(chatbot_geitje, trunc_df, run_id, PROMPT, TEXT_COLUMN, SPLIT_COLUMN, TRAIN_SET, TEST_SET, LABEL_COLUMN, PREDICTION_PATH, OVERVIEW_PATH, MODEL_NAME, NUMBER_EXAMPLES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = pd.read_pickle(OVERVIEW_PATH)\n",
        "# pred_run = pred.loc[pred['run_id']==f'{PROMPT_NAME}{TOKENS_COL}{FRONT_THRESHOLD}_{BACK_THRESHOLD}']\n",
        "display(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Llama\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_llama = pipeline(task='conversational', model='meta-llama/Llama-2-7b-chat-hf',\n",
        "                   device_map='cpu', model_kwargs={'offload_buffers':True})\n",
        "\n",
        "# load llama using cpu, else will give cuda out of memory error when running fewshot bm25 prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "PREDICTION_PATH = f\"{cf.output_path}/predictions/Llamapredictions.pkl\"\n",
        "OVERVIEW_PATH = f\"{cf.output_path}/overview/Llamapredictions.pkl\"\n",
        "\n",
        "MODEL_NAME = 'Llama-2-7b-chat-hf'\n",
        "PROMPT = pt.simple_prompt\n",
        "PROMPT_NAME = ph.get_promptfunction_name(PROMPT)\n",
        "TOKENS_COL = 'LlamaTokens'\n",
        "FRONT_THRESHOLD = 200\n",
        "BACK_THRESHOLD = 0\n",
        "\n",
        "if PROMPT == pt.simple_prompt:\n",
        "    NUMBER_EXAMPLES = 0\n",
        "elif PROMPT == pt.fewshot_prompt_bm25:\n",
        "    NUMBER_EXAMPLES = 2\n",
        "    \n",
        "# OVERVIEW_PATH = f\"{cf.output_path}/predictionsVal/in_context/Llama/{PROMPT_NAME}/overview.pkl\"\n",
        "# PREDICTION_PATH = f\"{cf.output_path}/predictionsVal/in_context/Llama/{PROMPT_NAME}/predictions.pkl\"\n",
        "\n",
        "run_id = f'IC_{MODEL_NAME}{PROMPT_NAME}{TOKENS_COL}{FRONT_THRESHOLD}_{BACK_THRESHOLD}{TRAIN_SET}{TEST_SET}_numEx{NUMBER_EXAMPLES}'\n",
        "\n",
        "# small = txt.iloc[7:13]\n",
        "# small['4split']=['val', 'dev', 'dev', 'dev', 'dev', 'dev']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run experiment\n",
        "\n",
        "# add new column with truncated text -> new dataframe with column + new column name\n",
        "trunc_df = tf.add_truncation_column(txt,'text', TOKENS_COL, FRONT_THRESHOLD, BACK_THRESHOLD)\n",
        "\n",
        "# if new run MAKE SURE RUN_ID IS UNIQUE, if want to resume run, pass in that run_id\n",
        "run_experiment(chatbot_llama, trunc_df, run_id, PROMPT, TEXT_COLUMN, SPLIT_COLUMN, TRAIN_SET, TEST_SET, LABEL_COLUMN, PREDICTION_PATH, OVERVIEW_PATH, MODEL_NAME, NUMBER_EXAMPLES)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Mistral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "2024-05-01 12:49:53.049905: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-01 12:49:56.428210: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83811a1314ae46169c235c371db23980",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc28396839bb4e51bae687ce9a9f50e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot_mistral = pipeline(task='conversational', model='mistralai/Mistral-7B-Instruct-v0.2',\n",
        "                   device_map='auto', model_kwargs={'offload_buffers':True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# PREDICTION_PATH = f\"{cf.output_path}/predictions/mistralPredictions.pkl\"\n",
        "# OVERVIEW_PATH = f\"{cf.output_path}/overview/mistralPredictions.pkl\"\n",
        "\n",
        "\n",
        "MODEL_NAME = 'Mistral-7B-Instruct-v0.2'\n",
        "PROMPT = pt.fewshot_prompt_bm25\n",
        "PROMPT_NAME = ph.get_promptfunction_name(PROMPT)\n",
        "TOKENS_COL = 'LlamaTokens'\n",
        "FRONT_THRESHOLD = 200\n",
        "BACK_THRESHOLD = 0\n",
        "\n",
        "if PROMPT == pt.simple_prompt:\n",
        "    NUMBER_EXAMPLES = 0\n",
        "elif PROMPT == pt.fewshot_prompt_bm25:\n",
        "    NUMBER_EXAMPLES = 2\n",
        "\n",
        "\n",
        "OVERVIEW_PATH = f\"{cf.output_path}/predictionsVal/in_context/Mistral/{PROMPT_NAME}/overview.pkl\"\n",
        "PREDICTION_PATH = f\"{cf.output_path}/predictionsVal/in_context/Mistral/{PROMPT_NAME}/predictions.pkl\"\n",
        "\n",
        "run_id = f'IC_{MODEL_NAME}{PROMPT_NAME}{TOKENS_COL}{FRONT_THRESHOLD}_{BACK_THRESHOLD}{TRAIN_SET}{TEST_SET}_numEx{NUMBER_EXAMPLES}'\n",
        "\n",
        "# small = txt.iloc[7:13]\n",
        "# small['4split']=['val', 'dev', 'dev', 'dev', 'dev', 'dev']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting...0:25 out of 209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  agenda\n",
            "response:  Based on the provided context, the document \"X Gemeente Amsterdam WB % Raadscommissie voor Bouwen, Wonen, Wijkaanpak en Dierenwelzijn % Agenda, woensdag 19 april 2017\" should be categorized as an \"Agenda\". Here's the JSON output:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Agenda\"}\n",
            "```\n",
            "prediction: agenda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  brief\n",
            "response:  {\"categorie\": \"Besluit\"}\n",
            "\n",
            "Explanation:\n",
            "Based on the provided context, the document appears to be a \"Gemeente Raadsinformatiebrief\" from the city council of Amsterdam, discussing a decision made by the college regarding the implementation of a policy to remove certain applications from municipal devices. This document falls under the category \"Besluit\" (Decision) as it communicates an official decision made by the college.\n",
            "prediction: besluit\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  agenda\n",
            "response:  Based on the provided context and examples, the document \"X Gemeente Amsterdam J C % Raadscommissie voor Onderwijs, Jeugd, Diversiteit en Integratie, Kunst en Cultuur, Lokale Media en Monumenten % Gewijzigde agenda, donderdag 3 en 8 december 2015\" should be categorized as 'Agenda'.\n",
            "\n",
            "Output in JSON format: {'categorie': 'Agenda'}\n",
            "prediction: agenda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  onderzoeksrapport\n",
            "response:  Based on the provided list of categories and the given document, I would categorize the document as follows:\n",
            "\n",
            "Document: sn OO EER OOR\n",
            "\n",
            "...\n",
            "\n",
            "Output: {'categorie': 'Agenda'}\n",
            "\n",
            "Therefore, the JSON output for the document would be:\n",
            "\n",
            "{'categorie': 'Agenda'}\n",
            "prediction: MultiplePredictionErrorInFormatting\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  factsheet\n",
            "response:  Based on the provided context and the document text, the document \"D RTT Amsterdam or a ische k Ijfers Amsterd D 7 EC maart en april 2020 How does the Amsterdam economy look now?\" can be categorized as a 'Factsheet'. Therefore, the output in JSON format would be:\n",
            "\n",
            "{'categorie': 'Factsheet'}\n",
            "prediction: factsheet\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  voordracht\n",
            "response:  Based on the provided context, the document \"virz020n4780\" is a \"Raadsinformatiebrief\" or a \"Council Information Brief\". Therefore, the output in JSON format would be:\n",
            "\n",
            "{'categorie': 'Raadsnotulen'}\n",
            "prediction: raadsnotulen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  Based on the provided document, the document can be categorized as 'Agenda' as it appears to be a letter to the members of the council with a specific agenda item discussed.\n",
            "\n",
            "Output in JSON format: {'categorie': 'Agenda'}\n",
            "prediction: agenda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  Based on the provided document, the output would be:\n",
            "\n",
            "{'categorie': 'Motie'}\n",
            "\n",
            "The document appears to be a motion, as indicated by the presence of the words \"amendement\" and \"aan de gemeenteraad\" (to the city council).\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  {\"categorie\": \"Schriftelijke Vraag\"}\n",
            "prediction: schriftelijke vraag\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  Based on the provided information, the document can be categorized as follows:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Motie\"}\n",
            "```\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  raadsadres\n",
            "response:  Based on the provided context and the example documents, the document you have been given to categorize is:\n",
            "\n",
            "Mail aan raad, verzonden d.d. 14-2-2012\n",
            "\n",
            "Inzake Participatieplan Airystrook\n",
            "\n",
            "Beste Lezer,\n",
            "\n",
            "Ik woon in 1 van de blokken die door Rochdale binnenkort aan Eigen Haard over worden gedragen. Liever zou ik er niet verhuizen, maar ik zal het kort houden.\n",
            "\n",
            "Het volgende valt mij op aan het participatieplan en de startnotitie:\n",
            "\n",
            "Startnotitie:\n",
            "\n",
            "- De planning is indicatief. Wat als Eigen Haard, door onvoorziene omstandigheden, wel al gaat slopen maar pas\n",
            "veel later gaat bouwen? Dit is in het verleden op andere plekken in Amsterdam ook gebeurd. Dat zou nieuw-west, en mijn achtertuin, niet ten goe.\n",
            "\n",
            "Based on the given context and examples, the document can be categorized as:\n",
            "\n",
            "\n",
            "prediction: NoPredictionFormat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  raadsadres\n",
            "response:  {\"categorie\": \"Raadsadres\"}\n",
            "prediction: raadsadres\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  Based on the provided context, the document should be categorized as \"Schriftelijke Vraag\" (Dutch for \"Written Question\") since it follows the same format as the examples given and contains a clear request for information from a council member to the council.\n",
            "\n",
            "Output in JSON format: {'categorie': 'Schriftelijke Vraag'}\n",
            "prediction: schriftelijke vraag\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  brief\n",
            "response:  Based on the provided information, the document can be categorized as 'Motie' because it contains a reference to a motie (motion) number and the document is addressed to the members of the municipal council. Therefore, the output in JSON format would be:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Motie\"}\n",
            "```\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  agenda\n",
            "response:  Based on the provided context, the document \"Xx Gemeente Amsterdam Z S\" with the given content belongs to the category \"Agenda\". Therefore, the output in JSON format would be:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Agenda\"}\n",
            "```\n",
            "prediction: agenda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  agenda\n",
            "response:  Based on the provided context and the given document, the document \"Termijnagenda stadsdeelcommissie Noord, 6-jan-2021 - 2021\" should be categorized as 'Agenda'. Here's the JSON output:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Agenda\"}\n",
            "```\n",
            "prediction: agenda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  {\"categorie\": \"Schriftelijke Vraag\"}\n",
            "prediction: schriftelijke vraag\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  voordracht\n",
            "response:  Based on the provided context, the document \"Weens07000, X Gemeente Raadscommissie voor MBO-agenda, Jongerenwerk, Sport en Recreatie, S EF D, wers articipatie % Amsterdam Economische Zaken, Sociale Zaken, Opvang, Gemeentelijk Vastgoed, Volwasseneneducatie, Democratisering, Voordracht voor de Commissie SED van 13 september 2023, Ter bespreking en ter kennisneming, Portefeuill Sociale Zaken, Agendapunt 12, Datum besluit n.v.t., Onderwerp: Knowledge acquisition of the final report of the Amsterdam experiment with social assistance (AEB)\" should be categorized as an \"Onderzoeksrapport\" (Research Report).\n",
            "\n",
            "Output in JSON format: {\"categorie\": \"Onderzoeksrapport\"}\n",
            "prediction: onderzoeksrapport\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  {\"categorie\": \"Schriftelijke Vraag\"}\n",
            "prediction: schriftelijke vraag\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  {\"categorie\": \"Motie\"}\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  agenda\n",
            "response:  Based on the provided information, the document can be categorized as 'Agenda'. Here is the output in the requested JSON format:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Agenda\"}\n",
            "```\n",
            "prediction: agenda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  Based on the provided context, the document can be categorized as 'Motie' (motion) or 'Raadsnotulen' (council minutes). However, since the document mentions that it is a report about a stakeholders meeting, I would suggest categorizing it as 'Onderzoeksrapport' (research report).\n",
            "\n",
            "Output: {'categorie': 'Onderzoeksrapport'}\n",
            "prediction: onderzoeksrapport\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  actualiteit\n",
            "response:  Based on the provided context and example documents, the document \"Smoon Aeterdan R\" should be categorized as an \"Interpellatie\" or \"Question\" since it is an interpellation made by certain council members to the city council. Therefore, the output in JSON format would be:\n",
            "\n",
            "{'categorie': 'Interpellatie'}\n",
            "prediction: NoPredictionInOutput\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  Based on the provided context, the document can be categorized as 'Schriftelijke Vraag' (Dutch for 'Written Question') because it follows the same format as the examples given, which includes the label \"Schriftelijke vragen\" (Written Questions), a number, a date of submission and approval, and a subject related to answering questions from council members. Therefore, the output in JSON format would be:\n",
            "\n",
            "{'categorie': 'Schriftelijke Vraag'}\n",
            "prediction: schriftelijke vraag\n",
            "label:  voordracht\n",
            "response:  Based on the provided context, the document \"VN2021-015993 X Gemeente Raadscommissie voor Ruimtelijke Ordening, Grondzaken, Zuidas en RO mts SN Marineterrein, Energietransitie vurzaamheid x Amsterdam Voordracht voor de Commissie RO van 08 september 2021 Ter kennisneming Portefeuille Ruimtelijke Ordening Agendapunt 9 Datum besluit n.v.t. Onderwerp Afdoening van de toezegging TA2019-000337 uit de commissievergadering van 6 maart 2019 m.b.t. horecavergunning voor Overtoom 558. De commissie wordt gevraagd\" can be categorized as follows:\n",
            "\n",
            "Output: {'categorie': 'Agenda'}\n",
            "prediction: agenda\n",
            "Dont interrupt, saving predictions...\n",
            "Saving done! Interrupting is allowed.\n",
            "Starting...25:50 out of 209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  Based on the provided context, the document to be categorised is:\n",
            "\n",
            "€ Bezoekadres |\n",
            "x gemeente Weesperplein 8 |\n",
            "Amsterdam 1018 XA Amsterdam |\n",
            "Postbus 1204 |\n",
            "1000 BC Amsterdam\n",
            "Telefoon 14 020\n",
            "x amsterdam.nl |\n",
            "Ê\n",
            "Retouradres: Postbus 2404, 1000 BC Amsterdam\n",
            "\n",
            "The output in the form of a JSON file would be:\n",
            "\n",
            "{'categorie': 'Bezoekadres'}\n",
            "prediction: NoPredictionInOutput\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  Based on the provided context, the document can be categorized as follows:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Schriftelijke Vraag\"}\n",
            "```\n",
            "\n",
            "The document is a response to a written inquiry submitted to the city council of Amsterdam, as indicated by the \"Gemeenteblad\" header and the presence of a number and a date of submission and approval. The document contains answers to specific questions posed by a council member, as indicated by the \"schriftelijke vragen\" header and the \"Toelichting door vragenstelster\" section. Therefore, the document falls under the \"Schriftelijke Vraag\" (written inquiry) category.\n",
            "prediction: schriftelijke vraag\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  {\"categorie\": \"Motie\"}\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  agenda\n",
            "response:  Based on the provided context and example documents, the document \"Termijnagenda stadsdeelcommissie Noord\" should be categorized as \"Agenda\". Therefore, the output in JSON format would be:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Agenda\"}\n",
            "```\n",
            "prediction: agenda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  Based on the provided context, the document \"X Gemeente Amsterdam x West Memo\" can be categorized as \"Schriftelijke Vraag\" (Written Request). Therefore, the output in JSON format would be:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Schriftelijke Vraag\"}\n",
            "```\n",
            "prediction: schriftelijke vraag\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  {\"categorie\": \"Motie\"}\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  voordracht\n",
            "response:  Based on the provided context and examples, the document \"VN2021-000293 X Gemeente Raadscommissie voor Kunst en Cultuur Monumenten en Erfgoed, K D D directie sb Diversiteit en Antidiscriminatiebeleid, Democratisering, Gemeentelijk Amsterdam ĳ Vastgoed, ICT en Digitale Stad, Dienstverlening, Personeel en % Organisatie, Coördinatie bedrijfsvoering, Inkoop Voordracht voor de Commissie KDD van 27 janvari 2021 Ter bespreking en ter kennisneming Portefeuille Democratisering (inclusief Bestuurlijk Stelsel) Agendapunt 6 Datum besluit 15 december 2020 Onderwerp Rapport Evaluatie Bestuurlijk Stelsel\" can be categorized as a \"Voordracht\" (presentation or memorandum).\n",
            "\n",
            "Output in JSON format: {\"categorie\": \"Voordracht\"}\n",
            "prediction: voordracht\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  {\"categorie\": \"Motie\"}\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  Based on the provided information, the document \"x Gemeente Amsterdam R, Gemeenteraad, % Gemeenteblad, % Schriftelijke vragen, Jaar 2018, Afdeling 1, Nummer 693, Datum indiening 3 augustus 2018, Datum akkoord college van b&w van 28 augustus 2018, Publicatiedatum 29 augustus 2018\" should be categorized as follows:\n",
            "\n",
            "{'categorie': 'Schriftelijke Vraag'}\n",
            "\n",
            "This document is a response to a written inquiry or question submitted to the city council, as indicated by the \"Schriftelijke vragen\" label and the presence of a numbered document reference. The document contains the response from the council to the inquiry, as well as a date of submission and publication. Therefore, it falls under the 'Schriftelijke Vraag' (written inquiry) category.\n",
            "prediction: schriftelijke vraag\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  voordracht\n",
            "response:  Based on the provided document, the output in JSON format would be:\n",
            "\n",
            "{'categorie': 'Voordracht'}\n",
            "\n",
            "The document is a 'Voordracht' (draft or proposal) as indicated by the presence of an agenda point, a date for consideration by the committee, and the term \"Voordracht\" in the document title.\n",
            "prediction: voordracht\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  Based on the provided document, the output in JSON format would be: {'categorie': 'Motie'}\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  raadsadres\n",
            "response:  {\"categorie\": \"Brief\"}\n",
            "prediction: brief\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  onderzoeksrapport\n",
            "response:  Based on the provided context, the document \"PLAN VAN SCHOLEN BASISONDERWIJS 2022-2025\" should be categorized as \"Agenda\" or \"Raadsnotulen\" since it appears to be a plan or agenda related to schools that is being presented to the city council. However, without additional context, it is difficult to determine the exact category with certainty. Therefore, I would suggest the following output:\n",
            "\n",
            "{'categorie': ['Agenda', 'Raadsnotulen']}\n",
            "\n",
            "This output indicates that the document could belong to either the 'Agenda' or 'Raadsnotulen' category. The final determination would depend on additional context or information that may be available.\n",
            "prediction: MultiplePredictionErrorInOutput\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  onderzoeksrapport\n",
            "response:  Based on the provided context and examples, the document \"ENERGYGO TUDelft On weg naar een aardgasvrije Van der Pek buurt\" should be categorized as \"Actualiteit\" (Dutch for \"news\" or \"current affairs\"). Therefore, the output in JSON format would be:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Actualiteit\"}\n",
            "```\n",
            "prediction: actualiteit\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  onderzoeksrapport\n",
            "response:  Based on the provided context, the document \"Vroeg Erop Af in de particuliere verhuur? - Antoniek Vermeulen, Monique Stavenuiter, Micky Out\" should be categorized as a 'Raadsadres' or 'Brief' since it appears to be a report or document addressed to the Amsterdam city council, possibly containing recommendations or proposals. However, without further context or specific information about the document's content, it is difficult to determine the exact category with certainty. Here's the JSON output:\n",
            "\n",
            "{'categorie': 'Raadsadres' or 'Brief'}\n",
            "prediction: MultiplePredictionErrorInOutput\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  brief\n",
            "response:  Based on the provided information, the document can be categorized as 'Motie' because it mentions a referendum initiative.\n",
            "\n",
            "Output: {'categorie': 'Motie'}\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  Based on the provided context and examples, the document \"x Gemeente Amsterdam R Gemeenteraad % Gemeenteblad Motie Jaar 2019 Afdeling 1 Nummer 155 Publicatiedatum 22 februari 2019 Ingekomen onder C Ingekomen op woensdag 13 februari 2019 Behandeld op woensdag 13 februari 2019 Status Aangenomen Onderwerp Motie van de leden Vroege en Yilmaz inzake de agenda autodelen (free floating deelauto’s) Aan de gemeenteraad\" should be categorized as 'Motie'.\n",
            "\n",
            "Output: {'categorie': 'Motie'}\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  {\"categorie\": \"Motie\"}\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  Based on the provided context, the document to be categorized is also a \"Schriftelijke Vraag\" (Dutch for \"Written Question\") as it follows the same format as the given examples. Here's the JSON output:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Schriftelijke Vraag\"}\n",
            "```\n",
            "prediction: schriftelijke vraag\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  {\"categorie\": \"Schriftelijke Vraag\"}\n",
            "\n",
            "This document is a \"Schriftelijke Vraag\" (literally \"written question\" or \"written request\") as it is a document containing a question or request submitted in writing to the city council of Amsterdam, along with a response from the council.\n",
            "prediction: schriftelijke vraag\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  {\"categorie\": \"Onderzoeksrapport\"}\n",
            "prediction: onderzoeksrapport\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  agenda\n",
            "response:  Based on the provided context and examples, the document \"x Gemeente Amsterdam R % Raadscommissie voor Ruimtelijke Ordening en Grondzaken (inclusief Erfpacht) % Gewijzigde agenda, woensdag 7 september 2016\" should be categorized as an 'Agenda'. Here's the JSON output:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Agenda\"}\n",
            "```\n",
            "prediction: agenda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  {\"categorie\": \"Actualiteit\"}\n",
            "prediction: actualiteit\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  {\"categorie\": \"Motie\"}\n",
            "prediction: motie\n",
            "label:  actualiteit\n",
            "response:  Based on the provided context, the document \"Gemeente Amsterdam % Gemeenteraad R % Raadsagenda supplement 3, woensdag 22 en donderdag 23 januari 2020\" should be categorized as \"Raadsnotulen\" or \"Agenda\" depending on the content of the supplement. However, the given document only contains the schedule and the heading \"TOEGEVOEGDE INGEKOMEN STUKKEN,\" so it's not possible to determine the exact category without examining the contents of the added documents. Therefore, the output should be:\n",
            "\n",
            "{'categorie': 'Agenda' or 'Raadsnotulen', 'needs_further_analysis': True}\n",
            "\n",
            "This indicates that the document requires further analysis to determine its exact category.\n",
            "prediction: MultiplePredictionErrorInOutput\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Starting...50:75 out of 209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  {\"categorie\": \"Schriftelijke Vraag\"}\n",
            "prediction: schriftelijke vraag\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  Based on the provided document, the document can be categorized as 'Schriftelijke Vraag' (Dutch for \"Written Question\"). Therefore, the output in JSON format would be:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Schriftelijke Vraag\"}\n",
            "```\n",
            "prediction: schriftelijke vraag\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  raadsadres\n",
            "response:  Based on the provided context and examples, the document to be categorized is:\n",
            "\n",
            "x Gemeente Amsterdam\n",
            "Stadsdeel Centrum\n",
            "\n",
            "x% Aanbiedingsformulier\n",
            "X van het dagelijks bestuur aan de raadscommissie\n",
            "\n",
            "Verzoek tot agendering in raad via commissie Commissie Bouwen en Wonen\n",
            "\n",
            "Onderwerp Conceptbeantwoording raadsadres UMTS-masten (Lindengracht 60-62)\n",
            "\n",
            "The category for this document is: {'categorie': 'Raadsadres'}\n",
            "prediction: raadsadres\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  agenda\n",
            "response:  Based on the provided context, the document \"AGENDA (concept) Raadscommissie SOCIALE ZAKEN, Datum: 12 april 2012, Aanvang: 20.00 uur, Zaal: Restaurant, Stadsdeelhuis, Buikslotermeerplein 2000\" should be categorized as an \"Agenda\". The output in the format of a JSON file would be:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Agenda\"}\n",
            "```\n",
            "prediction: agenda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  agenda\n",
            "response:  {\"categorie\": \"Agenda\"}\n",
            "prediction: agenda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  {\"categorie\": \"Raadsadres\"}\n",
            "\n",
            "This document is a \"Raadsadres\" (council address) as it contains the contact information for a municipal council or federation, including their postal address, phone number, and email address.\n",
            "prediction: raadsadres\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  Based on the provided context and the given document, the document can be categorized as 'Motie'. Here is the output in the requested JSON format:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Motie\"}\n",
            "```\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  agenda\n",
            "response:  Based on the provided document, the document should be categorized as 'Agenda'. Here's the output in JSON format:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Agenda\"}\n",
            "```\n",
            "prediction: agenda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  {\"categorie\": \"Motie\"}\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  {\"categorie\": \"Motie\"}\n",
            "\n",
            "This document is categorized as a \"Motie\" (Motion) based on the provided information.\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  brief\n",
            "response:  Based on the provided context, the document can be categorized as 'Agenda' or 'Actualiteit' as it appears to be an update on the progress of a program and may include information that requires discussion or decision-making during a council meeting. However, without further context, it is difficult to determine the exact category with certainty. Here's the output in the requested JSON format:\n",
            "\n",
            "{'categorie': 'Agenda' or 'Actualiteit'}\n",
            "\n",
            "To make a definitive decision, it would be helpful to have more information about the content of the document and the purpose of the categorization. For example, if the document is specifically an agenda item, then it should be categorized as 'Agenda'. If it is a report or update on a current issue, then it should be categorized as 'Actualiteit'.\n",
            "prediction: MultiplePredictionErrorInOutput\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  brief\n",
            "response:  Based on the provided information, the document can be categorized as an \"Onderzoeksrapport\" (Research Report) because it contains information about a report on the future of drug criminality, which is a topic that typically requires research and analysis. Therefore, the output in JSON format would be:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Onderzoeksrapport\"}\n",
            "```\n",
            "prediction: onderzoeksrapport\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  {\"categorie\": \"Schriftelijke Vraag\"}\n",
            "prediction: schriftelijke vraag\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  raadsadres\n",
            "response:  Based on the provided context and the given document, the document can be categorized as 'Motie' (motion). The document is a letter to the city council from a group of residents advocating for improvements to make the streets safer for cyclists and pedestrians. This is a common format for motions or proposals to be presented to the city council for consideration and action.\n",
            "\n",
            "Output: {'categorie': 'Motie'}\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  onderzoeksrapport\n",
            "response:  Based on the provided context, the document \"Centrum Seksueel Geweld, Amsterdam-Amstelland, Jaarcijfers 2018\" should be categorized as: {'categorie': 'Actualiteit'}\n",
            "\n",
            "This document is about the Centrum Seksueel Geweld (Center for Sexual Violence) in Amsterdam-Amstelland and its annual report for the year 2018. It provides information about the center's progress, accessibility, and contact information. Since it is an informative text about a current topic, it falls under the 'Actualiteit' (Dutch for 'actuality' or 'news') category.\n",
            "prediction: actualiteit\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  {\"categorie\": \"Motie\"}\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  {\"categorie\": \"Motie\"}\n",
            "\n",
            "In het geval van het gegeven document handelt het ook om een motie van leden van de gemeenteraad.\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  onderzoeksrapport\n",
            "response:  Based on the provided context and examples, the document to be categorised is an \"Onderzoeksrapport\" (Research Report). Here's the JSON output:\n",
            "\n",
            "```json\n",
            "{\"categorie\": \"Onderzoeksrapport\"}\n",
            "```\n",
            "prediction: onderzoeksrapport\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  {\"categorie\": \"Motie\"}\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  brief\n",
            "response:  Based on the provided information, the document can be categorized as follows:\n",
            "\n",
            "Input document:\n",
            "> < Gemeente Raadsinformatiebrief\n",
            "Amsterdam\n",
            "Aan: De leden van de gemeenteraad van Amsterdam\n",
            "Datum 20 april 2021\n",
            "Portefeuille(s) Economische Zaken\n",
            "Portefeuillehouder(s): Wethouder Victor Everhardt\n",
            "Behandeld door Economische zaken, Tanja Hendriks, t.hendriks@amsterdam.nl\n",
            "Onderwerp Raadsinformatiebrief over de prognose ‘Bezoekersaantallen 2018-2021’ van\n",
            "Onderzoek, Informatie en Statistiek.\n",
            "\n",
            "Geachte leden van de gemeenteraad,\n",
            "Met deze brief informeer ik v over de prognose ‘Bezoekersaantallen 2018-2021’ van Onderzoek, Informatie en Statistiek.\n",
            "\n",
            "Output:\n",
            "{'categorie': 'Raadsnotulen'}\n",
            "\n",
            "Explanation:\n",
            "The document is a \"\n",
            "prediction: raadsnotulen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  voordracht\n",
            "response:  Based on the provided context, the document \"VN2022-044482 N% Gemeente Raadscommissie voor Publieke Gezondheid en Preventie, Zorg en OZA, Werk, Participatie Maatschappelijke Ontwikkeling, Jeugd(zorg), Onderwijs en Armoede en en Inkomen % Amsterdam | Schuldhulpverlening, Voordracht voor de Commissie OZA van 18 januari 2023, Ter kennisneming, Portefeuille Armoedebestrijding en Schuldhulpverlening, Zorg en Maatschappelijke Ontwikkeling\" should be categorized as follows:\n",
            "\n",
            "Output of document 3: {'categorie': 'Voordracht'}\n",
            "prediction: voordracht\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  voordracht\n",
            "response:  Based on the provided context, the document \"VN2021-010335\" can be categorized as follows:\n",
            "\n",
            "{'categorie': 'Raadsnotulen'}\n",
            "\n",
            "Explanation:\n",
            "The document starts with \"Voordracht voor de Commissie AZ\" which is a common title for a document presented to a city council committee. However, the title \"Raadsaangelegenheden, Preventie\" and the content of the document, which asks the commission to gain knowledge about various council motions and answers to council addresses related to street dealers, indicate that this document is most likely the minutes or notes of a city council meeting or committee session. Therefore, the appropriate category for this document would be \"Raadsnotulen\" (council minutes or notes).\n",
            "prediction: raadsnotulen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  schriftelijke vraag\n",
            "response:  {\"categorie\": \"Schriftelijke Vraag\"}\n",
            "prediction: schriftelijke vraag\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  {\"categorie\": \"Motie\"}\n",
            "prediction: motie\n",
            "label:  voordracht\n",
            "response:  Based on the provided context, the document can be categorized as 'Actualiteit' because it is about a news item or current event. Therefore, the output in JSON format would be:\n",
            "\n",
            "{'categorie': 'Actualiteit'}\n",
            "prediction: actualiteit\n",
            "Dont interrupt, saving predictions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/anaconda/envs/AmsterdamInContextLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving done! Interrupting is allowed.\n",
            "Starting...75:100 out of 209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  Based on the provided information, the document can be categorized as a \"Motie\" as it contains a reference to a motie (resolution) number and the document is addressed to the members of the municipal council.\n",
            "\n",
            "Output in JSON format: {'categorie': 'Motie'}\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  motie\n",
            "response:  {\"categorie\": \"Motie\"}\n",
            "prediction: motie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  voordracht\n",
            "response:  Based on the provided document, the output in JSON format would be:\n",
            "\n",
            "{'categorie': 'Voordracht'}\n",
            "prediction: voordracht\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  onderzoeksrapport\n",
            "response:  Based on the provided context, the document can be categorized as a \"Raadsnotulen\" (Council minutes) or \"Agenda\" (Agenda). However, the document seems to contain elements of both, such as a management summary and a progress report. Therefore, the most appropriate category would be \"Agenda\" with a sub-category or tag indicating that it includes a quarterly report or minutes from a specific committee or council meeting.\n",
            "\n",
            "Output: {'categorie': 'Agenda','sub-category': 'Quarterly Report/Council Minutes'}\n",
            "prediction: agenda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  voordracht\n",
            "response:  Based on the provided context, the document \"VN2021-034948 N% Gemeente Raadscommissie voor Algemene Zaken, Openbare Orde en Veiligheid, AZ onee Veoh Amsterdam Juridische Zaken, Communicatie, Raadsaangelegenheden, Preventie % en Toezicht Voordracht voor de Commissie AZ van 13 janvari 2022 Ter kennisneming Portefeuille Openbare Orde en Veiligheid Agendapunt 10 Datum besluit Onderwerp A. De halfjaarlijkse voortgangsbrief van het programma Radicalisering en Extremisme B. Vertrouwelijke rapporten\" should be categorized as an \"Onderzoeksrapport\".\n",
            "\n",
            "Output in JSON format: {\"categorie\": \"Onderzoeksrapport\"}\n",
            "prediction: onderzoeksrapport\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  onderzoeksrapport\n",
            "response:  Based on the provided context and the examples given, the document \"ea | | | __ VERWEY ln ET eh A. 9 Ns, zn, | IE E | Î Kn | Procesevaluatie Subsidieregeling ‘Diversiteit en inclusiviteit voor allianties Amsterdam 2021-2023 Ervaringen with alliances and alliance policy in Amsterdam Marian van der Klein, Mariam Badou and Micky Out mn an _ mn mn - Ervaringen met alliances mm: Procesevaluatie Subsidieregeling ‘Diversiteit en inclusiviteit voor allianties Amsterdam 2021-2023 Marian van der Klein Mariam Badou Micky Out mn Utrecht, november 2022\" should be categorized as an \"Agenda\" or a \"Raadsnotulen\" (Council minutes). Both categories could be suitable, depending on the exact context and format of the document. However, since it includes the names of the authors and a title that suggests a meeting or an agenda, \"Raadsnotulen\" seems to be the\n",
            "prediction: NoPredictionFormat\n"
          ]
        }
      ],
      "source": [
        "# run experiment\n",
        "\n",
        "# add new column with truncated text -> new dataframe with column + new column name\n",
        "trunc_df = tf.add_truncation_column(txt,'text', TOKENS_COL, FRONT_THRESHOLD, BACK_THRESHOLD)\n",
        "\n",
        "# if new run MAKE SURE RUN_ID IS UNIQUE, if want to resume run, pass in that run_id\n",
        "run_experiment(chatbot_mistral, trunc_df, run_id, PROMPT, TEXT_COLUMN, SPLIT_COLUMN, TRAIN_SET, TEST_SET, LABEL_COLUMN, PREDICTION_PATH, OVERVIEW_PATH, MODEL_NAME, NUMBER_EXAMPLES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>run_id</th>\n",
              "      <th>date</th>\n",
              "      <th>train_set</th>\n",
              "      <th>test_set</th>\n",
              "      <th>train_set_support</th>\n",
              "      <th>test_set_support</th>\n",
              "      <th>split_col</th>\n",
              "      <th>text_col</th>\n",
              "      <th>runtime</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro_avg_precision</th>\n",
              "      <th>macro_avg_recall</th>\n",
              "      <th>macro_avg_f1</th>\n",
              "      <th>classification_report</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mistral-7B-Instruct-v0.2</td>\n",
              "      <td>IC_Mistral-7B-Instruct-v0.2fewshot_prompt_bm25...</td>\n",
              "      <td>2024-05-01 21:06:56.220884+02:00</td>\n",
              "      <td>dev</td>\n",
              "      <td>val</td>\n",
              "      <td>832</td>\n",
              "      <td>75</td>\n",
              "      <td>4split</td>\n",
              "      <td>TruncationLlamaTokensFront200Back0</td>\n",
              "      <td>9123.21593</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.30768</td>\n",
              "      <td>0.325973</td>\n",
              "      <td>precision...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      model  \\\n",
              "0  Mistral-7B-Instruct-v0.2   \n",
              "\n",
              "                                              run_id  \\\n",
              "0  IC_Mistral-7B-Instruct-v0.2fewshot_prompt_bm25...   \n",
              "\n",
              "                              date train_set test_set  train_set_support  \\\n",
              "0 2024-05-01 21:06:56.220884+02:00       dev      val                832   \n",
              "\n",
              "   test_set_support split_col                            text_col     runtime  \\\n",
              "0                75    4split  TruncationLlamaTokensFront200Back0  9123.21593   \n",
              "\n",
              "   accuracy  macro_avg_precision  macro_avg_recall  macro_avg_f1  \\\n",
              "0      0.64                 0.37           0.30768      0.325973   \n",
              "\n",
              "                               classification_report  \n",
              "0                                       precision...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pred = pd.read_pickle(OVERVIEW_PATH)\n",
        "display(pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gibberish"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fewshot Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = pd.read_pickle(f\"{cf.output_path}/txtfiles_tokenizer.pkl\")\n",
        "\n",
        "#set  variables, same for each model\n",
        "TRAIN_SET = 'dev' # must be dev or train\n",
        "TEST_SET = 'val' # must be val or test\n",
        "SPLIT_COLUMN = '4split' #must be either 2split or 4split. 2split = data split into train and test. 4split = data split into train, test, dev and val. \n",
        "LABEL_COLUMN = 'label'\n",
        "PREDICTION_PATH = f\"{cf.output_path}/predictions/fewShotGeitjepredictions.pkl\"\n",
        "OVERVIEW_PATH = f\"{cf.output_path}/overview/fewShotGeitjepredictions.pkl\"\n",
        "# PREDICTION_PATH = f\"{cf.output_path}/predictions/trialfewShotGeitjepredictions.pkl\"\n",
        "# OVERVIEW_PATH = f\"{cf.output_path}/overview/trialfewShotGeitjepredictions.pkl\"\n",
        "MODEL_NAME = 'GEITje-7B-chat-v2'\n",
        "TEXT_COLUMN = 'trunc_txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# txt = pd.read_pickle(f\"{cf.output_path}/txtfiles_tokenizer.pkl\")\n",
        "\n",
        "#set  variables, same for each model\n",
        "TRAIN_SET = 'dev' # must be dev or train\n",
        "TEST_SET = 'val' # must be val or test\n",
        "SPLIT_COLUMN = '4split' #must be either 2split or 4split. 2split = data split into train and test. 4split = data split into train, test, dev and val. \n",
        "LABEL_COLUMN = 'label'\n",
        "PREDICTION_PATH = f\"{cf.output_path}/predictions/fewShotLlamapredictions.pkl\"\n",
        "OVERVIEW_PATH = f\"{cf.output_path}/overview/fewShotLlamapredictions.pkl\"\n",
        "# PREDICTION_PATH = f\"{cf.output_path}/predictions/trialfewShotLlamapredictions.pkl\"\n",
        "# OVERVIEW_PATH = f\"{cf.output_path}/overview/trialfewShotLlamapredictions.pkl\"\n",
        "MODEL_NAME = 'Llama-2-7b-chat-hf'\n",
        "TEXT_COLUMN = 'trunc_txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----- EXPERIMENT: ?? --------\n",
        "\n",
        "# run experiment\n",
        "PROMPT = pt.fewshot_prompt_bm25\n",
        "PROMPT_NAME = ph.get_promptfunction_name(PROMPT)\n",
        "TOKENS_COL = 'LlamaTokens'\n",
        "FRONT_THRESHOLD = 200\n",
        "BACK_THRESHOLD = 0\n",
        "NUMBER_EXAMPLES = 2\n",
        "# small = txt.iloc[0:5]\n",
        "# small['4split']='val'\n",
        "\n",
        "# add new column with truncated text -> new dataframe with column + new column name\n",
        "trunc_df = tf.add_truncation_column(txt,'text', TOKENS_COL, FRONT_THRESHOLD, BACK_THRESHOLD)\n",
        "\n",
        "# if new run MAKE SURE RUN_ID IS UNIQUE, if want to resume run, pass in that run_id\n",
        "run_experiment(trunc_df, f'{PROMPT_NAME}{TOKENS_COL}{FRONT_THRESHOLD}_{BACK_THRESHOLD}', PROMPT, TEXT_COLUMN, SPLIT_COLUMN, TRAIN_SET, TEST_SET, LABEL_COLUMN, PREDICTION_PATH, OVERVIEW_PATH, MODEL_NAME, NUMBER_EXAMPLES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = pd.read_pickle(OVERVIEW_PATH)\n",
        "# pred_run = pred.loc[pred['run_id']==f'{PROMPT_NAME}{TOKENS_COL}{FRONT_THRESHOLD}_{BACK_THRESHOLD}']\n",
        "# print(sum(pred_run['runtime']))\n",
        "# pred['runtime'] = sum(pred_run['runtime'])\n",
        "display(pred.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = pd.read_pickle(PREDICTION_PATH)\n",
        "pred_run = pred.loc[pred['run_id']==f'{PROMPT_NAME}{TOKENS_COL}{FRONT_THRESHOLD}_{BACK_THRESHOLD}']\n",
        "print(sum(pred_run['runtime']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## End notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def get_class_list():\n",
        "#     return ['Voordracht', 'Besluit', 'Schriftelijke Vragen', 'Brief', 'Raadsadres', 'Onderzoeksrapport', 'Termijnagenda', 'Raadsnotulen', 'Agenda', 'Motie', 'Actualiteit', 'Factsheets']\n",
        "\n",
        "# def fewshot_prompt_examples(doc, train_df, num_examples, text_column):\n",
        "#     examples = train_df.sample(n=num_examples)\n",
        "\n",
        "#     prompt = f\"\"\"\n",
        "#     Het is jouw taak om een document te categoriseren in één van de categoriën.\n",
        "#     Eerst krijg je een lijst met mogelijke categoriën, daarna {num_examples} voorbeelden van documenten en tot slot het document dat gecategoriseerd moet worden. \n",
        "    \n",
        "#     Categoriën: {get_class_list()}\n",
        "#     \"\"\"\n",
        "\n",
        "#     for index, row in examples.iterrows():\n",
        "#         mini_prompt = f\"\"\"\n",
        "#     Dit is een voorbeeld document de categorie {row['label']}:\n",
        "#         {row[text_column]}\n",
        "#         \"\"\"\n",
        "\n",
        "#         prompt += mini_prompt\n",
        "\n",
        "#     doc_prompt = f\"\"\"\n",
        "#     Categoriseer dit document:\n",
        "#         {doc}\n",
        "#     \"\"\"\n",
        "\n",
        "#     prompt += doc_prompt\n",
        "#     return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def simple_prompt(doc,train_df, num_examples, text_column):\n",
        "#     prompt = f\"\"\"\n",
        "#     Classificeer het document in één van de categoriën.\n",
        "#     Houd het kort, geef enkel de naam van de categorie als response.\n",
        "    \n",
        "#     Categoriën: {get_class_list()}\n",
        "    \n",
        "#     Document: \n",
        "#     {doc}\n",
        "    \n",
        "#     \"\"\"\n",
        "#     return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import time\n",
        "# import os\n",
        "# import pandas as pd\n",
        "\n",
        "\n",
        "# \"\"\" Given a dataframe with txt, return a df with predictions \"\"\"\n",
        "# # docs_df = dataframe with the documents that need to be predicted\n",
        "# # text_column = name of the column that includes the input_text. Can be different based on the text representation method. \n",
        "# # prompt_function = prompt template \n",
        "\n",
        "# def predictions_incontextlearning(docs_df, text_column, prompt_function, train_df, num_examples):\n",
        "#     results_df = pd.DataFrame(columns = ['id', 'path', 'text_column', 'prompt_function', 'response', 'prediction', 'label', 'runtime', 'date', 'prompt'])\n",
        "    \n",
        "#     # prompt each document\n",
        "#     for index, row in docs_df.iterrows():\n",
        "#         if (index + 1) % 200 == 0:\n",
        "#             print(f\"Iteration {index +1}/{len(docs_df)} completed.\")\n",
        "\n",
        "#         start_time = time.time()\n",
        "\n",
        "#         # get the prompt, with the doc filled in\n",
        "#         txt = row[text_column]\n",
        "\n",
        "#         # always give these as input, however not every template uses all of them\n",
        "#         prompt = prompt_function(txt, train_df, num_examples, text_column)\n",
        "\n",
        "#         # prompt and get the response\n",
        "#         converse = chatbot(Conversation(prompt))\n",
        "#         response = converse[1]['content']\n",
        "\n",
        "#         # extract prediction from response\n",
        "#         prediction = ph.get_prediction_from_response(response)\n",
        "\n",
        "#         # save results in dataframe\n",
        "#         results_df.loc[len(results_df)] = {\n",
        "#             'id': row['id'],\n",
        "#             'path' : row['path'],\n",
        "#             'text_column' : text_column,\n",
        "#             'prompt_function': ph.get_promptfunction_name(prompt_function),\n",
        "#             'response':response,\n",
        "#             'prediction':prediction,\n",
        "#             'label':row['label'].lower(),\n",
        "#             'runtime':time.time()-start_time,\n",
        "#             'date': ph.get_datetime(),\n",
        "#             'prompt':prompt\n",
        "#         }\n",
        "#     return results_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# import time\n",
        "# from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# \"\"\"\n",
        "# Function to run GEITje In-Context Learning experiment. \n",
        "# The function allows to resume experiment, if run_id matches.\n",
        "# \"\"\"\n",
        "# # df = dataframe with all docs that need to have a prediction (docs still need to be predict + already predicted)\n",
        "# # run_id = unqiue for each experiment. \n",
        "# # prompt_function = which prompt from prompt_template.py to use\n",
        "# # text_col = colum in df where the text is. (Needs to be already truncated)\n",
        "# # split_col = column with the dataset split. Either '2split' (train and test)or '4split'(train, test, dev and val)\n",
        "# # subset_train = indicates which subset to use as training. either 'train' or 'dev'\n",
        "# # subset_test = indicates which subset to use for testing. either 'test' or 'val'\n",
        "# # label_col = column with the true label\n",
        "# # prediction_path = path to file where predictions need to be saved.\n",
        "# # overview_path = path to file where results of each run need to be saved.\n",
        "# # model_name = name of the model. string.\n",
        "# # num_exmples = number of exaples given to prompt. zero in case of zeroshot. \n",
        "\n",
        "# def run_experiment(df, run_id, prompt_function, text_col, split_col, subset_train, subset_test, label_col, prediction_path, overview_path, model_name, num_examples=0):\n",
        "#     print(num_examples)\n",
        "#     start_time = time.time()\n",
        "#     test_df = df.loc[df[split_col]==subset_test]\n",
        "#     train_df = df.loc[df[split_col]==subset_train]\n",
        "    \n",
        "#     # get rows of df that still need to be predicted for the specific run_id\n",
        "#     to_predict, previous_predictions = ph.get_rows_to_predict(test_df, prediction_path, run_id)\n",
        "\n",
        "#     # devide to_predict into subsection of 50 predictions at a time. \n",
        "#     # Allows to rerun without problem. \n",
        "#     step_range = list(range(0, len(to_predict), 3))\n",
        "\n",
        "#     for i in range(len(step_range)):\n",
        "#         try:\n",
        "#             sub_to_predict = to_predict.iloc[step_range[i]:step_range[i+1]]\n",
        "#             print(f'Starting...{step_range[i]}:{step_range[i+1]} out of {len(to_predict)}')\n",
        "#         except Exception as e:\n",
        "#             sub_to_predict = to_predict[step_range[i]:]\n",
        "#             print(f'Starting...last {len(sub_to_predict)} docs')\n",
        "\n",
        "#         # prompt geitje\n",
        "#         predictions = predictions_incontextlearning(sub_to_predict, text_col, prompt_function, train_df, num_examples)\n",
        "\n",
        "#         # save info\n",
        "#         predictions['run_id'] = run_id\n",
        "#         predictions['train_set'] = subset_train\n",
        "#         predictions['test_set'] = subset_test\n",
        "#         predictions['shots'] = num_examples\n",
        "\n",
        "#         # save new combinations in file\n",
        "#         ph.combine_and_save_df(predictions, prediction_path)\n",
        "\n",
        "#         # if previous predictions, combine previous with new predictions, to get update classification report\n",
        "#         try:\n",
        "#             predictions = pd.concat([predictions, previous_predictions])\n",
        "\n",
        "#             # set previous predictions to all predictions made until now. Necessary for next loop\n",
        "#             previous_predictions = predictions\n",
        "#         except Exception as e:\n",
        "#             # set previous predictions to all predictions made until now. Necessary for next loop\n",
        "#             previous_predictions = predictions\n",
        "\n",
        "#         # save results in overview file\n",
        "#         date = ph.get_datetime()\n",
        "#         y_test = predictions['label']\n",
        "#         y_pred = predictions['prediction']\n",
        "#         report = classification_report(y_test, y_pred)\n",
        "\n",
        "#         overview = pd.DataFrame(\n",
        "#             [{\n",
        "#                 'model':model_name,\n",
        "#                 'run_id':run_id,\n",
        "#                 'date': date,\n",
        "#                 'train_set': subset_train,\n",
        "#                 'test_set': subset_test,\n",
        "#                 'train_set_support':len(df.loc[df[split_col]==subset_train]),\n",
        "#                 'test_set_support':len(predictions),\n",
        "#                 'split_col':split_col,\n",
        "#                 'text_col':text_col,\n",
        "#                 'runtime':time.time()-start_time,\n",
        "#                 'accuracy': accuracy_score(y_test, y_pred),\n",
        "#                 'macro_avg_precision': precision_score(y_test, y_pred, average='macro'),\n",
        "#                 'macro_avg_recall': recall_score(y_test, y_pred, average='macro'),\n",
        "#                 'macro_avg_f1': f1_score(y_test, y_pred, average='macro'),\n",
        "#                 'classification_report':report\n",
        "#             }   ]\n",
        "#         )\n",
        "#         # remove previous results of run_id, replace with new/updated results\n",
        "#         ph.replace_and_save_df(overview, overview_path, run_id)\n",
        "\n",
        "txt = pd.read_pickle(f\"{cf.output_path}/txtfiles_tokenizer.pkl\")\n",
        "\n",
        "#set  variables, same for each model\n",
        "TRAIN_SET = 'dev' # must be dev or train\n",
        "TEST_SET = 'val' # must be val or test\n",
        "SPLIT_COLUMN = '4split' #must be either 2split or 4split. 2split = data split into train and test. 4split = data split into train, test, dev and val. \n",
        "LABEL_COLUMN = 'label'\n",
        "PREDICTION_PATH = f\"{cf.output_path}/predictions/tryoutGeitjepredictions.pkl\"\n",
        "OVERVIEW_PATH = f\"{cf.output_path}/overview/tryoutGeitjepredictions.pkl\"\n",
        "MODEL_NAME = 'GEITje-7B-chat-v2'\n",
        "TEXT_COLUMN = 'trunc_txt'\n",
        "\n",
        "p_path = f\"{cf.output_path}/predictions/tryoutGeitjepredictions.pkl\"\n",
        "o_path = f\"{cf.output_path}/overview/tryoutGeitjeoverview.pkl\"\n",
        "run_experiment(small, 'tryout_zeroshot', pt.simple_prompt, 'trunc_txt', '4split', 'dev', 'val', 'label', p_path, o_path, 'GEITje-7B-chat-v2', 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "yeet = pd.read_pickle(p_path)\n",
        "yeet  = yeet.loc[yeet['run_id']=='tryout_zeroshot']\n",
        "display(yeet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(yeet.iloc[0]['prompt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = pd.read_pickle(f\"{cf.output_path}/txtfiles_tokenizer.pkl\")\n",
        "\n",
        "small = txt.iloc[0:5]\n",
        "small['4split']=['val', 'dev', 'val', 'dev', 'dev']\n",
        "\n",
        "# add new column with truncated text -> new dataframe with column + new column name\n",
        "trunc_df = tf.add_truncation_column(small,'text', 'LlamaTokens', 200, 200)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GIbberish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import time\n",
        "# import os\n",
        "# import pandas as pd\n",
        "\n",
        "\n",
        "# \"\"\" Given a dataframe with txt, return a df with predictions \"\"\"\n",
        "# # docs_df = dataframe with the documents that need to be predicted\n",
        "# # text_column = name of the column that includes the input_text. Can be different based on the text representation method. \n",
        "# # prompt_function = prompt template -> ONLY prompt templates that take doc as input (ZERO SHOT)\n",
        "\n",
        "# def zero_shot_predictions_incontextlearning(docs_df, text_column, prompt_function):\n",
        "#     results_df = pd.DataFrame(columns = ['id', 'path', 'text_column', 'prompt_function', 'response', 'prediction', 'label', 'runtime', 'date'])\n",
        "    \n",
        "#     # prompt each document\n",
        "#     for index, row in docs_df.iterrows():\n",
        "#         if (index + 1) % 200 == 0:\n",
        "#             print(f\"Iteration {index +1}/{len(docs_df)} completed.\")\n",
        "\n",
        "#         start_time = time.time()\n",
        "\n",
        "#         # get the prompt, with the doc filled in\n",
        "#         txt = row[text_column]\n",
        "#         prompt = prompt_function(txt)\n",
        "\n",
        "#         # prompt and get the response\n",
        "#         converse = chatbot(Conversation(prompt))\n",
        "#         response = converse[1]['content']\n",
        "\n",
        "#         # extract prediction from response\n",
        "#         prediction = ph.get_prediction_from_response(response)\n",
        "\n",
        "#         # save results in dataframe\n",
        "#         results_df.loc[len(results_df)] = {\n",
        "#             'id': row['id'],\n",
        "#             'path' : row['path'],\n",
        "#             'text_column' : text_column,\n",
        "#             'prompt_function': ph.get_promptfunction_name(prompt_function),\n",
        "#             'response':response,\n",
        "#             'prediction':prediction,\n",
        "#             'label':row['label'].lower(),\n",
        "#             'runtime':time.time()-start_time,\n",
        "#             'date': ph.get_datetime()\n",
        "#         }\n",
        "#     return results_df\n",
        "\n",
        "\n",
        "#  import os\n",
        "# import time\n",
        "# from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# \"\"\"\n",
        "# Function to run GEITje ZEROSHOT experiment. \n",
        "# The function allows to resume experiment, if run_id matches.\n",
        "# \"\"\"\n",
        "# # df = dataframe with all docs that need to have a prediction (docs still need to be predict + already predicted)\n",
        "# # run_id = unqiue for each experiment. \n",
        "# # prompt_function = which prompt from prompt_template.py to use\n",
        "# # text_col = colum in df where the text is. (Needs to be already truncated)\n",
        "# # split_col = column with the dataset split. Either '2split' (train and test)or '4split'(train, test, dev and val)\n",
        "# # subset_train = indicates which subset to use as training. either 'train' or 'dev'\n",
        "# # subset_test = indicates which subset to use for testing. either 'test' or 'val'\n",
        "# # label_col = column with the true label\n",
        "# # prediction_path = path to file where predictions need to be saved.\n",
        "# # overview_path = path to file where results of each run need to be saved.\n",
        "# # model_name = name of the model. string.\n",
        "# # num_exmples = number of exaples given to prompt. zero inn case of zeroshot. \n",
        "\n",
        "# def run_experiment(df, run_id, prompt_function, text_col, split_col, subset_train, subset_test, label_col, prediction_path, overview_path, model_name, num_examples=0):\n",
        "#     start_time = time.time()\n",
        "#     test_df = df.loc[df[split_col]==subset_test]\n",
        "    \n",
        "#     # get rows of df that still need to be predicted for the specific run_id\n",
        "#     to_predict, previous_predictions = ph.get_rows_to_predict(test_df, prediction_path, run_id)\n",
        "\n",
        "#     # devide to_predict into subsection of 50 predictions at a time. \n",
        "#     # Allows to rerun without problem. \n",
        "#     step_range = list(range(0, len(to_predict), 3))\n",
        "\n",
        "#     for i in range(len(step_range)):\n",
        "#         try:\n",
        "#             sub_to_predict = to_predict.iloc[step_range[i]:step_range[i+1]]\n",
        "#             print(f'Starting...{step_range[i]}:{step_range[i+1]} out of {len(to_predict)}')\n",
        "#         except Exception as e:\n",
        "#             sub_to_predict = to_predict[step_range[i]:]\n",
        "#             print(f'Starting...last {len(sub_to_predict)} docs')\n",
        "\n",
        "#         # prompt geitje\n",
        "#         predictions = zero_shot_predictions_incontextlearning(sub_to_predict, text_col, prompt_function)\n",
        "\n",
        "#         # save info\n",
        "#         predictions['run_id'] = run_id\n",
        "#         predictions['train_set'] = subset_train\n",
        "#         predictions['test_set'] = subset_test\n",
        "#         predictions['shots'] = num_examples\n",
        "\n",
        "#         # save new combinations in file\n",
        "#         ph.combine_and_save_df(predictions, prediction_path)\n",
        "\n",
        "#         # if previous predictions, combine previous with new predictions, to get update classification report\n",
        "#         try:\n",
        "#             predictions = pd.concat([predictions, previous_predictions])\n",
        "\n",
        "#             # set previous predictions to all predictions made until now. Necessary for next loop\n",
        "#             previous_predictions = predictions\n",
        "#         except Exception as e:\n",
        "#             # set previous predictions to all predictions made until now. Necessary for next loop\n",
        "#             previous_predictions = predictions\n",
        "\n",
        "#         # save results in overview file\n",
        "#         date = ph.get_datetime()\n",
        "#         y_test = predictions['label']\n",
        "#         y_pred = predictions['prediction']\n",
        "#         report = classification_report(y_test, y_pred)\n",
        "\n",
        "#         overview = pd.DataFrame(\n",
        "#             [{\n",
        "#                 'model':model_name,\n",
        "#                 'run_id':run_id,\n",
        "#                 'date': date,\n",
        "#                 'train_set': subset_train,\n",
        "#                 'test_set': subset_test,\n",
        "#                 'train_set_support':len(df.loc[df[split_col]==subset_train]),\n",
        "#                 'test_set_support':len(predictions),\n",
        "#                 'split_col':split_col,\n",
        "#                 'text_col':text_col,\n",
        "#                 'runtime':time.time()-start_time,\n",
        "#                 'accuracy': accuracy_score(y_test, y_pred),\n",
        "#                 'macro_avg_precision': precision_score(y_test, y_pred, average='macro'),\n",
        "#                 'macro_avg_recall': recall_score(y_test, y_pred, average='macro'),\n",
        "#                 'macro_avg_f1': f1_score(y_test, y_pred, average='macro'),\n",
        "#                 'classification_report':report\n",
        "#             }   ]\n",
        "#         )\n",
        "#         # remove previous results of run_id, replace with new/updated results\n",
        "#         ph.replace_and_save_df(overview, overview_path, run_id)\n",
        " \n",
        "# # p_path = f\"{cf.output_path}/predictions/tryoutGeitjepredictions.pkl\"\n",
        "# # o_path = f\"{cf.output_path}/overview/tryoutGeitjeoverview.pkl\"\n",
        "# # run_experiment(txt.iloc[25:30], 'tryout', pt.simple_prompt, trunc_col, '4split', 'dev', 'val', 'label', p_path, o_path, 'GEITje-7B-chat-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_pickle(f\"{cf.output_path}/txtfiles.pkl\")\n",
        "df = df.loc[df['set']=='val']\n",
        "df['text_trunc_100'] = df['tokens'].apply(text_truncation,100)\n",
        "df['text_trunc_1000'] = df['tokens'].apply(text_truncation,1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = f\"{cf.output_path}/predictions/ICgeitje_predictions.pkl\"\n",
        "resume_predictions(df, path, 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# dummy code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_in_subsections(df, path, set_run_id):\n",
        "\n",
        "    iterations = list(range(0, len(df)+50, 50))\n",
        "    for i in range(len(iterations)):\n",
        "        try:\n",
        "            subdf = df.iloc[iterations[i]:iterations[i+1]]\n",
        "\n",
        "        except IndexError:\n",
        "            subdf = df.iloc[iterations[i]:]\n",
        "\n",
        "        # if set_run_id == 'new' and iterations[i]==0:\n",
        "        #     run_prediction(subdf, 'text_trunc_100', pt.simple_prompt, 'new', path, 'val')\n",
        "        # else:\n",
        "        #     run_prediction(subdf, 'text_trunc_100', pt.simple_prompt, 'previous', path, 'val')\n",
        "\n",
        "\n",
        "\n",
        "path = f\"{cf.output_path}/predictions/ICgeitje_predictions_tryout.pkl\"\n",
        "run_in_subsections(df, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_in_subsections(df, path):\n",
        "    subdf = df.iloc[0:50]\n",
        "    run_prediction(subdf, 'text_trunc_100', pt.simple_prompt, 'new', path, 'val')\n",
        "\n",
        "    iterations = list(range(50, len(df)+50, 50))\n",
        "    for i in range(len(iterations)):\n",
        "        if i < len(iterations)-2:\n",
        "            subdf = df.iloc[iterations[i]:iterations[i+1]]\n",
        "            print(\"\\n\", \"iterations\", iterations[i], iterations[i+1], \"\\n\")\n",
        "            run_prediction(subdf, 'text_trunc_100', pt.simple_prompt, 'previous', path, 'val')\n",
        "\n",
        "        elif i < len(iterations)-1:\n",
        "            subdf = df.iloc[iterations[i]:]\n",
        "            print(\"\\n\", \"iterations\", iterations[i], '\\n')\n",
        "            run_prediction(subdf, 'text_trunc_100', pt.simple_prompt, 'previous', path, 'val')\n",
        "\n",
        "path = f\"{cf.output_path}/predictions/ICgeitje_predictions_tryout.pkl\"\n",
        "run_in_subsections(df, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "yeet = pd.read_pickle(f\"{cf.output_path}/predictions/ICgeitje_predictions.pkl\")\n",
        "display(yeet)\n",
        "\n",
        "yeet = pd.read_pickle(f\"{cf.output_path}/overview_results.pkl\")\n",
        "display(yeet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import sys\n",
        "sys.path.append('../scripts/') \n",
        "import prompt_template as pt\n",
        "import prediction_helperfunctions as ph\n",
        "\n",
        "\n",
        "\"\"\" Given a dataframe with txt, return a df with predictions \"\"\"\n",
        "# docs_df = dataframe with the documents that need to be predicted\n",
        "# text_column = name of the column that includes the input_text. Can be different based on the text representation method. \n",
        "# prompt_function = prompt template -> ONLY prompt templates that take doc as input (ZERO SHOT)\n",
        "\n",
        "def zero_shot_predictions_incontextlearning(docs_df, text_column, prompt_function):\n",
        "    results_df = pd.DataFrame(columns = ['id', 'path', 'text_column', 'prompt_function', 'response', 'prediction', 'label', 'runtime', 'date'])\n",
        "    \n",
        "    # prompt each document\n",
        "    for index, row in docs_df.iterrows():\n",
        "        if (index + 1) % 200 == 0:\n",
        "            print(f\"Iteration {index +1}/{len(docs_df)} completed.\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # get the prompt, with the doc filled in\n",
        "        txt = row[text_column]\n",
        "        prompt = prompt_function(txt)\n",
        "\n",
        "        # prompt and get the response\n",
        "        converse = chatbot(Conversation(prompt))\n",
        "        response = converse[1]['content']\n",
        "\n",
        "        # extract prediction from response\n",
        "        prediction = ph.get_prediction_from_response(response)\n",
        "\n",
        "        # save results in dataframe\n",
        "        results_df.loc[len(results_df)] = {\n",
        "            'id': row['id'],\n",
        "            'path' : row['path'],\n",
        "            'text_column' : text_column,\n",
        "            'prompt_function': ph.get_promptfunction_name(prompt_function),\n",
        "            'response':response,\n",
        "            'prediction':prediction,\n",
        "            'label':row['label'].lower(),\n",
        "            'runtime':time.time()-start_time,\n",
        "            'date': ph.get_datetime()\n",
        "        }\n",
        "    return results_df\n",
        "\n",
        "# \"\"\" Run a prediction function -> can be ZeroShot or FewShot \"\"\"\n",
        "# def run_prediction(docs_df, text_column, prompt_function, subset=None, learning='ZeroShot'):\n",
        "#     if learning == 'ZeroShot':\n",
        "#         # get the predictions\n",
        "#         res = zero_shot_predictions_incontextlearning(docs_df, text_column, prompt_function)\n",
        "\n",
        "#         # INSERT ELSE STATEMENT HERE FOR FEWSHOT\n",
        "\n",
        "#         # get run_id\n",
        "#         path = f\"{cf.output_path}/predictions/ICgeitje_predictions.pkl\"\n",
        "#         res['run_id'], predictions_df = ph.get_runid(path)\n",
        "\n",
        "#         # combine earlier predictions with new ones\n",
        "#         all_predictions = pd.concat([predictions_df, res])\n",
        "\n",
        "#         # save predictions\n",
        "#         all_predictions.to_pickle(path)\n",
        "\n",
        "#         # save the evaluation metrics for each run\n",
        "#         ph.update_overview_results(res, 'Rijgersberg/GEITje-7B-chat-v2')\n",
        "#         return res\n",
        "# gestart om 10.15/\n",
        "# res = run_prediction(df, 'text_trunc_100', pt.simple_prompt, 'val')\n",
        "# display(res)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "yeet = pd.read_pickle(f\"{cf.output_path}/overview_results.pkl\")\n",
        "display(yeet)\n",
        "\n",
        "yeet = pd.read_pickle(f\"{cf.output_path}/predictions/ICgeitje_predictions.pkl\")\n",
        "display(yeet)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tryout GEITje\n",
        "Load chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot = pipeline(task='conversational', model='Rijgersberg/GEITje-7B-chat-v2',\n",
        "                   device_map='auto')\n",
        "\n",
        "## simple query\n",
        "print(chatbot(\n",
        "    Conversation(\"Hallo, ik ben Bram. Ik wil vanavond graag een film kijken. Heb je enkele suggesties?\")\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "# load_in_8bit: lower precision but saves a lot of GPU memory\n",
        "# device_map=auto: loads the model across multiple GPUs\n",
        "# chatbot = pipeline(\"conversational\", model=\"BramVanroy/GEITje-7B-ultra\",  model_kwargs={\"load_in_8bit\": True}, device_map=\"auto\")\n",
        "chatbot = pipeline(\"conversational\", model=\"BramVanroy/GEITje-7B-ultra\",  device_map=\"auto\")\n",
        "\n",
        "# start_messages = [\n",
        "#     # {\"role\": \"system\", \"content\": \"Je bent een grappige chatbot die Bert heet. Je maakt vaak mopjes.\"},\n",
        "#     {\"role\": \"user\", \"content\": \"Hallo, ik ben Bram. Ik wil vanavond graag een film kijken. Heb je enkele suggesties?\"}\n",
        "# ]\n",
        "# conversation = Conversation(start_messages)\n",
        "# conversation = chatbot(conversation)\n",
        "# response = conversation.messages[-1][\"content\"]\n",
        "# print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = df.iloc[0]['text']\n",
        "prompt = f\"\"\"\n",
        "\n",
        "Classificeer de gegeven tekst in 1 van de categoriën.\n",
        "Geef als reactie enkel de naam van de categorie\n",
        "Categorieën: ['Voordracht', 'Besluit', 'Schriftelijke Vragen', 'Brief', 'Raadsadres', 'Onderzoeksrapport', 'Termijnagenda', 'Raadsnotulen', 'Agenda', 'Motie', 'Actualiteit', 'Factsheets']\n",
        "Tekst: \n",
        "\n",
        "{txt}\n",
        "\n",
        "\"\"\" \n",
        "\n",
        "start_messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Jouw enige taak is om teksten te classificeren. Je geeft geen uitleg voor je keuzes.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chatbot(Conversation(start_messages))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_pickle(f\"{cf.output_path}/txtfiles.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = df.loc[df['clean_tokens_count'].idxmax()]['text']\n",
        "print(df.loc[df['clean_tokens_count'].idxmax()]['clean_tokens_count'])\n",
        "\n",
        "print(pt.simple_prompt(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(chatbot(\n",
        "    Conversation(pt.simple_prompt(text))\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model_name = 'Rijgersberg/GEITje-7B-chat-v2'\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16,\n",
        "                                             low_cpu_mem_usage=True, attn_implementation='eager',\n",
        "                                             device_map=device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def generate(conversation, temperature=0.2, top_k=50, max_new_tokens=1_000):\n",
        "    tokenized = tokenizer.apply_chat_template(conversation, add_generation_prompt=True,\n",
        "                                              return_tensors='pt').to(device)\n",
        "    outputs = model.generate(tokenized, do_sample=True, temperature=temperature,\n",
        "                             top_k=top_k, max_new_tokens=max_new_tokens)\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "conversation = [\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': 'Welk woord hoort er niet in dit rijtje thuis: \"auto, vliegtuig, geitje, bus\"?'\n",
        "    }\n",
        "]\n",
        "print(generate(conversation))\n",
        "# <|user|>\n",
        "# Welk woord hoort er niet in dit rijtje thuis: \"auto, vliegtuig, geitje, bus\"? \n",
        "# <|assistant|>\n",
        "# Het woord dat niet op zijn plaats staat is 'geit'. Een geit zou niet tussen een lijst van vervoersmiddelen moeten staan. Het past beter bij een boerderijthema of dierenlijst."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BACK-UP CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "import time\n",
        "import datetime\n",
        "import pytz\n",
        "import os\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "\"\"\" Given the string response, extract the prediction \"\"\"\n",
        "def get_prediction_from_response(response):\n",
        "    # get a list of the possible classes\n",
        "    classes_list = pt.get_class_list()\n",
        "\n",
        "    predictions = [True if category.lower() in response.lower() else False for category in classes_list]\n",
        "\n",
        "    # check if multiple classes were named, this is a prediction error\n",
        "    if Counter(predictions)[True] > 1:\n",
        "        return \"PredictionError\"\n",
        "\n",
        "    # check if exactly one class is named, this is the prediction\n",
        "    elif Counter(predictions)[True] == 1:\n",
        "        prediction = [category.lower() for category in classes_list if category.lower() in response.lower()]\n",
        "        return prediction[0]\n",
        "\n",
        "    # if no class is named, then this is a no prediction error\n",
        "    else:\n",
        "        return 'NoPrediction'\n",
        "\n",
        "\"\"\" Extract the promptfunction name \"\"\"\n",
        "def get_promptfunction_name(prompt_function):\n",
        "    string = f\"{prompt_function}\"\n",
        "    match = re.search(r'<function\\s+(\\w+)', string)\n",
        "    if match:\n",
        "        function_name = match.group(1)\n",
        "        return function_name\n",
        "    else:\n",
        "        return f\"{prompt_function}\"\n",
        "    \n",
        "\"\"\" Get the current time in the Netherlands \"\"\"\n",
        "def get_datetime():\n",
        "    current_datetime_utc = datetime.datetime.now(pytz.utc)\n",
        "\n",
        "    # Convert UTC time to Dutch time (CET)\n",
        "    dutch_timezone = pytz.timezone('Europe/Amsterdam')\n",
        "    current_datetime_dutch = current_datetime_utc.astimezone(dutch_timezone)\n",
        "    return current_datetime_dutch\n",
        "        \n",
        "\"\"\" Get the new runid \"\"\"\n",
        "def get_runid(path):\n",
        "\n",
        "    # if not first run, set runid to most recent run+1\n",
        "    if os.path.exists(path):\n",
        "        df = pd.read_pickle(path)\n",
        "        return max(df['run_id'])+1, df\n",
        "\n",
        "    # if first run, set runid to 0\n",
        "    else:\n",
        "        return 0, pd.DataFrame()\n",
        "    \n",
        "\"\"\" Save evaluation metrics of a run \"\"\"\n",
        "def update_overview_results(df, model_name, subset=None):\n",
        "    # df= dataframe with predictions for each do, one row per doc/prediction\n",
        "    # model_name = string with the name of the model\n",
        "    # subset = can be train, val, or test, or left open\n",
        " \n",
        "    # get evalaution scores\n",
        "    evaluation_dict = classification_report(df['label'], df['prediction'], output_dict=True)\n",
        "    evaluation = pd.DataFrame(evaluation_dict).transpose()\n",
        "    \n",
        "    new_row = {\n",
        "        # stuff about the run\n",
        "        'run_id':df.iloc[0]['run_id'],\n",
        "        'model':model_name,\n",
        "        'prompt_function':df.iloc[0]['prompt_function'],\n",
        "        'text_column':df.iloc[0]['text_column'],\n",
        "        'date': get_datetime(),\n",
        "        'runtime':sum(df['runtime']),\n",
        "        'set':subset,\n",
        "        'support':evaluation.iloc[-1]['support'],\n",
        "\n",
        "        # evaluation\n",
        "        'accuracy': evaluation_dict['accuracy'],\n",
        "\n",
        "        'recall_weighted_avg':evaluation.loc[evaluation.index=='weighted avg']['recall'].values[0],\n",
        "        'precision_weighted_avg': evaluation.loc[evaluation.index=='weighted avg']['precision'].values[0],\n",
        "        'f1_weighted_avg': evaluation.loc[evaluation.index=='weighted avg']['f1-score'].values[0],\n",
        "\n",
        "        'recall_macro_avg':evaluation.loc[evaluation.index=='macro avg']['recall'].values[0],\n",
        "        'precision_macro_avg': evaluation.loc[evaluation.index=='macro avg']['precision'].values[0],\n",
        "        'f1_macro_avg': evaluation.loc[evaluation.index=='macro avg']['f1-score'].values[0],\n",
        "\n",
        "\n",
        "        'recall_classes': dict(zip(evaluation.index[0:-3], evaluation['recall'][0:-3])),\n",
        "        'precision_classes': dict(zip(evaluation.index[0:-3], evaluation['precision'][0:-3])),\n",
        "        'f1_classes': dict(zip(evaluation.index[0:-3], evaluation['f1-score'][0:-3])),\n",
        "        'support_classes': dict(zip(evaluation.index[0:-3], evaluation['support'][0:-3])),\n",
        "\n",
        "        # docs that were predicted\n",
        "        'doc_paths':list(df['path'].values)\n",
        "        \n",
        "    }\n",
        "\n",
        "    # create a new dataframe with the evaluation, each run has one row\n",
        "    results = pd.DataFrame(columns=new_row.keys())\n",
        "    results.loc[len(results)] = new_row\n",
        "   \n",
        "    # if not the first run, get results from previous runs\n",
        "    path = f\"{cf.output_path}/overview_results.pkl\"\n",
        "    if os.path.exists(path):\n",
        "        earlier_results = pd.read_pickle(path)\n",
        "\n",
        "        # combine evaluation of previous runs with current run\n",
        "        results = pd.concat([earlier_results, results])\n",
        "\n",
        "    # save to overview_results.pkl\n",
        "    results.to_pickle(path)\n",
        "   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# update_overview_results(res, 'geitje')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# yeet = pd.read_pickle(f\"{cf.output_path}/overview_results.pkl\")\n",
        "# display(yeet)\n",
        "\n",
        "# yeet = pd.read_pickle(f\"{cf.output_path}/predictions/ICgeitje_predictions.pkl\")\n",
        "# display(yeet)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "\n",
        "\"\"\" Given a dataframe with txt, return a df with predictions \"\"\"\n",
        "# docs_df = dataframe with the documents that need to be predicted\n",
        "# text_column = name of the column that includes the input_text. Can be different based on the text representation method. \n",
        "# prompt_function = prompt template -> ONLY prompt templates that take doc as input (ZERO SHOT)\n",
        "\n",
        "def zero_shot_predictions_incontextlearning(docs_df, text_column, prompt_function):\n",
        "    results_df = pd.DataFrame(columns = ['id', 'path', 'text_column', 'prompt_function', 'response', 'prediction', 'label', 'runtime', 'date'])\n",
        "    \n",
        "    # prompt each document\n",
        "    for index, row in docs_df.iterrows():\n",
        "        start_time = time.time()\n",
        "\n",
        "        # get the prompt, with the doc filled in\n",
        "        txt = row[text_column]\n",
        "        prompt = prompt_function(txt)\n",
        "\n",
        "        # prompt and get the response\n",
        "        converse = chatbot(Conversation(prompt))\n",
        "        response = converse[1]['content']\n",
        "\n",
        "        # extract prediction from response\n",
        "        prediction = get_prediction_from_response(response)\n",
        "\n",
        "        # save results in dataframe\n",
        "        results_df.loc[len(results_df)] = {\n",
        "            'id': row['id'],\n",
        "            'path' : row['path'],\n",
        "            'text_column' : text_column,\n",
        "            'prompt_function': get_promptfunction_name(prompt_function),\n",
        "            'response':response,\n",
        "            'prediction':prediction,\n",
        "            'label':row['label'].lower(),\n",
        "            'runtime':time.time()-start_time,\n",
        "            'date': get_datetime()\n",
        "        }\n",
        "    return results_df\n",
        "\n",
        "\"\"\" Run a prediction function -> can be ZeroShot or FewShot \"\"\"\n",
        "def run_prediction(docs_df, text_column, prompt_function, subset=None, learning='ZeroShot'):\n",
        "    if learning == 'ZeroShot':\n",
        "        # get the predictions\n",
        "        res = zero_shot_predictions_incontextlearning(docs_df, text_column, prompt_function)\n",
        "\n",
        "        # INSERT ELSE STATEMENT HERE FOR FEWSHOT\n",
        "\n",
        "        # get run_id\n",
        "        path = f\"{cf.output_path}/predictions/ICgeitje_predictions.pkl\"\n",
        "        res['run_id'], predictions_df = get_runid(path)\n",
        "\n",
        "        # combine earlier predictions with new ones\n",
        "        all_predictions = pd.concat([predictions_df, res])\n",
        "\n",
        "        # save predictions\n",
        "        all_predictions.to_pickle(path)\n",
        "\n",
        "        # save the evaluation metrics for each run\n",
        "        update_overview_results(res, 'Rijgersberg/GEITje-7B-chat-v2')\n",
        "        return res\n",
        "\n",
        "res = run_prediction(df, 'text_trunc', pt.simple_prompt)\n",
        "display(res)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "amsterdamincontextlearning"
    },
    "kernelspec": {
      "display_name": "AmsterdamInContextLearning",
      "language": "python",
      "name": "amsterdamincontextlearning"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "nl"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
