{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "!bash /home/azureuser/cloudfiles/code/blobfuse/blobfuse_raadsinformatie.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "# Select where to run notebook: \"azure\" or \"local\"\n",
        "my_run = \"azure\"\n",
        "\n",
        "import my_secrets as sc\n",
        "import settings as st\n",
        "\n",
        "if my_run == \"azure\":\n",
        "    import config_azure as cf\n",
        "elif my_run == \"local\":\n",
        "    import config as cf\n",
        "\n",
        "\n",
        "import os\n",
        "if my_run == \"azure\":\n",
        "    if not os.path.exists(cf.HUGGING_CACHE):\n",
        "        os.mkdir(cf.HUGGING_CACHE)\n",
        "    os.environ[\"TRANSFORMERS_CACHE\"] = cf.HUGGING_CACHE\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# setup environment GEITje-7B Finetuning\n",
        "# - pip install torch\n",
        "# - pip install datasets\n",
        "# - pip install transformers\n",
        "# - pip install trl\n",
        "# - pip install accelerate (restart after)\n",
        "# - switch device_map='auto' to avaoid memory error\n",
        "\n",
        "# - pip install sentencepiece\n",
        "# - pip install jupyter\n",
        "# - pip install protobuf \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notebook overview\n",
        "This notebook creates predictions for the baseline models. In total, five models are tried out.\n",
        "- Training function. Given a baseline model, will return scores.\n",
        "- Load Data. Load all the documents, and set parameters.\n",
        "- save predictions\n",
        "\n",
        "\n",
        "*Previous notebook: RepairMistralPredictions*\n",
        "\n",
        "*Next notebook: plot*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load file with training funcation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../scripts/') \n",
        "import baseline as bf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_pickle(f\"{cf.output_path}/txtfiles.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>path</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>num_pages</th>\n",
              "      <th>4split</th>\n",
              "      <th>2split</th>\n",
              "      <th>MistralTokens</th>\n",
              "      <th>count_MistralTokens</th>\n",
              "      <th>LlamaTokens</th>\n",
              "      <th>count_LlamaTokens</th>\n",
              "      <th>md5_hash</th>\n",
              "      <th>balanced_split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Motie</td>\n",
              "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
              "      <td>1874</td>\n",
              "      <td>x Gemeente Amsterdam R\\nGemeenteraad\\n% Gemeen...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>train</td>\n",
              "      <td>train</td>\n",
              "      <td>[▁x, ▁Geme, ente, ▁Amsterdam, ▁R, &lt;0x0A&gt;, G, e...</td>\n",
              "      <td>350</td>\n",
              "      <td>[▁x, ▁Geme, ente, ▁Amsterdam, ▁R, &lt;0x0A&gt;, G, e...</td>\n",
              "      <td>346</td>\n",
              "      <td>2f09ba2c967bba0eecf71f846f258a78</td>\n",
              "      <td>discard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Motie</td>\n",
              "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
              "      <td>230</td>\n",
              "      <td>X Gemeente Amsterdam R\\nGemeenteraad\\n% Gemeen...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>train</td>\n",
              "      <td>train</td>\n",
              "      <td>[▁X, ▁Geme, ente, ▁Amsterdam, ▁R, &lt;0x0A&gt;, G, e...</td>\n",
              "      <td>1130</td>\n",
              "      <td>[▁X, ▁Geme, ente, ▁Amsterdam, ▁R, &lt;0x0A&gt;, G, e...</td>\n",
              "      <td>1082</td>\n",
              "      <td>d14b33c32ba1e1bcff16320891bdf158</td>\n",
              "      <td>discard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Raadsnotulen</td>\n",
              "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
              "      <td>26304</td>\n",
              "      <td>Gemeente Amsterdam\\n% Gemeenteraad R\\n% Raadsn...</td>\n",
              "      <td>79.0</td>\n",
              "      <td>train</td>\n",
              "      <td>train</td>\n",
              "      <td>[▁Geme, ente, ▁Amsterdam, &lt;0x0A&gt;, %, ▁Geme, en...</td>\n",
              "      <td>89050</td>\n",
              "      <td>[▁Geme, ente, ▁Amsterdam, &lt;0x0A&gt;, %, ▁Geme, en...</td>\n",
              "      <td>85359</td>\n",
              "      <td>36964ae4a84926e2f825761d980d12f4</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Besluit</td>\n",
              "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
              "      <td>20677</td>\n",
              "      <td>3. Interne documenten - 5271\\nx Gemeente Beslu...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>train</td>\n",
              "      <td>train</td>\n",
              "      <td>[▁, 3, ., ▁Inter, ne, ▁document, en, ▁-, ▁, 5,...</td>\n",
              "      <td>1094</td>\n",
              "      <td>[▁, 3, ., ▁Inter, ne, ▁document, en, ▁-, ▁, 5,...</td>\n",
              "      <td>1071</td>\n",
              "      <td>f2f9203231ceba0504087b493b5ffd1d</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Raadsadres</td>\n",
              "      <td>/home/azureuser/cloudfiles/code/blobfuse/raads...</td>\n",
              "      <td>24174</td>\n",
              "      <td>|\\nÍ\\nAmsterdam, september 2016 |\\nGeachte led...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>train</td>\n",
              "      <td>train</td>\n",
              "      <td>[▁|, &lt;0x0A&gt;, Í, &lt;0x0A&gt;, Am, sterdam, ,, ▁septe...</td>\n",
              "      <td>1839</td>\n",
              "      <td>[▁|, &lt;0x0A&gt;, Í, &lt;0x0A&gt;, Am, sterdam, ,, ▁septe...</td>\n",
              "      <td>1775</td>\n",
              "      <td>cebc20ef3921faab5a377c1a637ed22d</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          label                                               path     id  \\\n",
              "0         Motie  /home/azureuser/cloudfiles/code/blobfuse/raads...   1874   \n",
              "1         Motie  /home/azureuser/cloudfiles/code/blobfuse/raads...    230   \n",
              "2  Raadsnotulen  /home/azureuser/cloudfiles/code/blobfuse/raads...  26304   \n",
              "3       Besluit  /home/azureuser/cloudfiles/code/blobfuse/raads...  20677   \n",
              "4    Raadsadres  /home/azureuser/cloudfiles/code/blobfuse/raads...  24174   \n",
              "\n",
              "                                                text  num_pages 4split 2split  \\\n",
              "0  x Gemeente Amsterdam R\\nGemeenteraad\\n% Gemeen...        1.0  train  train   \n",
              "1  X Gemeente Amsterdam R\\nGemeenteraad\\n% Gemeen...        2.0  train  train   \n",
              "2  Gemeente Amsterdam\\n% Gemeenteraad R\\n% Raadsn...       79.0  train  train   \n",
              "3  3. Interne documenten - 5271\\nx Gemeente Beslu...        2.0  train  train   \n",
              "4  |\\nÍ\\nAmsterdam, september 2016 |\\nGeachte led...        2.0  train  train   \n",
              "\n",
              "                                       MistralTokens  count_MistralTokens  \\\n",
              "0  [▁x, ▁Geme, ente, ▁Amsterdam, ▁R, <0x0A>, G, e...                  350   \n",
              "1  [▁X, ▁Geme, ente, ▁Amsterdam, ▁R, <0x0A>, G, e...                 1130   \n",
              "2  [▁Geme, ente, ▁Amsterdam, <0x0A>, %, ▁Geme, en...                89050   \n",
              "3  [▁, 3, ., ▁Inter, ne, ▁document, en, ▁-, ▁, 5,...                 1094   \n",
              "4  [▁|, <0x0A>, Í, <0x0A>, Am, sterdam, ,, ▁septe...                 1839   \n",
              "\n",
              "                                         LlamaTokens  count_LlamaTokens  \\\n",
              "0  [▁x, ▁Geme, ente, ▁Amsterdam, ▁R, <0x0A>, G, e...                346   \n",
              "1  [▁X, ▁Geme, ente, ▁Amsterdam, ▁R, <0x0A>, G, e...               1082   \n",
              "2  [▁Geme, ente, ▁Amsterdam, <0x0A>, %, ▁Geme, en...              85359   \n",
              "3  [▁, 3, ., ▁Inter, ne, ▁document, en, ▁-, ▁, 5,...               1071   \n",
              "4  [▁|, <0x0A>, Í, <0x0A>, Am, sterdam, ,, ▁septe...               1775   \n",
              "\n",
              "                           md5_hash balanced_split  \n",
              "0  2f09ba2c967bba0eecf71f846f258a78        discard  \n",
              "1  d14b33c32ba1e1bcff16320891bdf158        discard  \n",
              "2  36964ae4a84926e2f825761d980d12f4           test  \n",
              "3  f2f9203231ceba0504087b493b5ffd1d          train  \n",
              "4  cebc20ef3921faab5a377c1a637ed22d          train  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribution of sets:  Counter({'train': 9900, 'discard': 8718, 'test': 1100, 'val': 1100})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "sys.path.append('../scripts/') \n",
        "import baseline as bf\n",
        "from truncation import add_truncation_column\n",
        "\n",
        "#set  variables, same for each model\n",
        "SPLIT_COLUMN = 'balanced_split' #column that has the data split saved. must be either 2split, 4split or balanced_split. 2split = data split into train and test. 4split = data split into train, test, dev and val. \n",
        "print('Distribution of sets: ', Counter(df[SPLIT_COLUMN]))\n",
        "TRAIN_SET = 'train' # must be dev or train\n",
        "TEST_SET = 'test' # must be val or test\n",
        "# this split column, train_set and test_set might be a bit confusing. The split_column need to have values about the split, so a row either belongs, in my case, to 'train', 'test', 'dev' or 'val'.\n",
        "# Then the train_set indates which rows will be selected based on the filtering of the split column. \n",
        "# Thus if TRAIN_SET = 'train', then all rows where split_col is 'train', will be selected as the training set.\n",
        "# The same goes for TEST_SET    \n",
        "\n",
        "\n",
        "TEXT_COLUMN = 'text' # column where the text is\n",
        "LABEL_COLUMN = 'label' # column with truth label\n",
        "DATAFRAME = df.copy() # df where each row is a doc. \n",
        "FOLDER = f\"{cf.output_path}/predictionsFinal/baselines\" # folder where each individual prediction is saved\n",
        "OVERVIEW_PATH = f\"{cf.output_path}/predictionsFinal/baselines/overview.pkl\" # file where score and extra data about run is saved\n",
        "\n",
        "# needed for truncation experiment on baselines\n",
        "TRUNC_COLUMN = 'trunc_txt' # column with truncated text\n",
        "TOKENS_COL = 'LlamaTokens' # column with text split into tokens using model tokenizer, in this case Llama, could also be MistralTokens\n",
        "THRESHOLD_COMBINATIONS =[(100,0), (200,0), (100,100)] # combinations of front and back truncation thresholds. First value in tuple is first N tokens, second value is last N tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to run the baseline on each truncation threshold\n",
        "\n",
        "def run_truncation_on_baselines(baseline_function, model_name, predictions_path):\n",
        "    for thresholds in THRESHOLD_COMBINATIONS:\n",
        "\n",
        "        # select thresholds\n",
        "        front_threshold = thresholds[0]\n",
        "        back_threshold = thresholds[1]\n",
        "\n",
        "        # set run_id\n",
        "        run_id = f\"{model_name}_first{front_threshold}_last{back_threshold}\"\n",
        "\n",
        "        # get df with truncated text column\n",
        "        trunc = add_truncation_column(DATAFRAME, TEXT_COLUMN, TOKENS_COL, front_threshold,back_threshold)\n",
        "\n",
        "        # train and get predictions\n",
        "        bf.run_baseline(baseline_function, model_name, trunc, SPLIT_COLUMN, TRAIN_SET, TEST_SET, TRUNC_COLUMN, LABEL_COLUMN, predictions_path, OVERVIEW_PATH, run_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Baseline 1: linear SVM+tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/baselines/overview.pkl\n",
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/baselines/LinearSVCpredictions.pkl\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "model_name = 'LinearSVC'\n",
        "baseline_function = LinearSVC()\n",
        "run_id = f\"{model_name}_fulltext\"\n",
        "predictions_path = f\"{FOLDER}/{model_name}predictions.pkl\"\n",
        "\n",
        "print(OVERVIEW_PATH)\n",
        "print(predictions_path)\n",
        "linear_svm = bf.run_baseline(baseline_function, model_name , DATAFRAME, SPLIT_COLUMN, TRAIN_SET, TEST_SET,TEXT_COLUMN, LABEL_COLUMN, predictions_path, OVERVIEW_PATH, run_id)\n",
        "\n",
        "run_truncation_on_baselines(baseline_function, model_name, predictions_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Baseline 2: Naive Bayes+tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model_name = 'MultinomialNB'\n",
        "baseline_function = MultinomialNB()\n",
        "run_id = f\"{model_name}_fulltext\"\n",
        "predictions_path = f\"{FOLDER}/{model_name}predictions.pkl\"\n",
        "print(OVERVIEW_PATH)\n",
        "print(predictions_path)\n",
        "\n",
        "naive_bayes = bf.run_baseline(baseline_function, model_name , DATAFRAME, SPLIT_COLUMN, TRAIN_SET, TEST_SET,TEXT_COLUMN, LABEL_COLUMN, predictions_path, OVERVIEW_PATH, run_id)\n",
        "\n",
        "run_truncation_on_baselines(baseline_function, model_name, predictions_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Baseline 3: Logistic Regression + tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model_name = 'LogisticRegression'\n",
        "baseline_function = LogisticRegression()\n",
        "run_id = f\"{model_name}_fulltext\"\n",
        "predictions_path = f\"{FOLDER}/{model_name}predictions.pkl\"\n",
        "\n",
        "print(OVERVIEW_PATH)\n",
        "print(predictions_path)\n",
        "\n",
        "log_reg = bf.run_baseline(baseline_function, model_name , DATAFRAME, SPLIT_COLUMN, TRAIN_SET, TEST_SET,TEXT_COLUMN, LABEL_COLUMN, predictions_path, OVERVIEW_PATH, run_id)\n",
        "\n",
        "run_truncation_on_baselines(baseline_function, model_name, predictions_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Baseline 4: k Nearest Neigbors + tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model_name = 'KNeighborsClassifier'\n",
        "baseline_function = KNeighborsClassifier()\n",
        "run_id = f\"{model_name}_fulltext\"\n",
        "predictions_path = f\"{FOLDER}/{model_name}predictions.pkl\"\n",
        "\n",
        "print(OVERVIEW_PATH)\n",
        "print(predictions_path)\n",
        "knn = bf.run_baseline(baseline_function, model_name , DATAFRAME, SPLIT_COLUMN, TRAIN_SET, TEST_SET,TEXT_COLUMN, LABEL_COLUMN, predictions_path, OVERVIEW_PATH, run_id)\n",
        "\n",
        "run_truncation_on_baselines(baseline_function, model_name, predictions_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Baseline 5: RandomForest + tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_name = 'RandomForestClassifier'\n",
        "baseline_function = RandomForestClassifier()\n",
        "run_id = f\"{model_name}_fulltext\"\n",
        "predictions_path = f\"{FOLDER}/{model_name}predictions.pkl\"\n",
        "\n",
        "print(OVERVIEW_PATH)\n",
        "print(predictions_path)\n",
        "\n",
        "random_forest = bf.run_baseline(baseline_function, model_name , DATAFRAME, SPLIT_COLUMN, TRAIN_SET, TEST_SET,TEXT_COLUMN, LABEL_COLUMN, predictions_path, OVERVIEW_PATH, run_id)\n",
        "\n",
        "run_truncation_on_baselines(baseline_function, model_name, predictions_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Overview of all runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "overview = pd.read_pickle(OVERVIEW_PATH)\n",
        "display(overview)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
