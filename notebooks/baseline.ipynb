{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "!bash /home/azureuser/cloudfiles/code/blobfuse/blobfuse_raadsinformatie.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "# Select where to run notebook: \"azure\" or \"local\"\n",
        "my_run = \"azure\"\n",
        "\n",
        "import my_secrets as sc\n",
        "import settings as st\n",
        "\n",
        "if my_run == \"azure\":\n",
        "    import config_azure as cf\n",
        "elif my_run == \"local\":\n",
        "    import config as cf\n",
        "\n",
        "\n",
        "import os\n",
        "if my_run == \"azure\":\n",
        "    if not os.path.exists(cf.HUGGING_CACHE):\n",
        "        os.mkdir(cf.HUGGING_CACHE)\n",
        "    os.environ[\"TRANSFORMERS_CACHE\"] = cf.HUGGING_CACHE\n",
        "\n",
        "\n",
        "# setup environment GEITje-7B Finetuning\n",
        "# - pip install torch\n",
        "# - pip install datasets\n",
        "# - pip install transformers\n",
        "# - pip install trl\n",
        "# - pip install accelerate (restart after)\n",
        "# - switch device_map='auto' to avaoid memory error\n",
        "\n",
        "# - pip install sentencepiece\n",
        "# - pip install jupyter\n",
        "# - pip install protobuf \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notebook overview\n",
        "This notebook creates predictions for the baseline models. In total, five models are tried out.\n",
        "- Training function. Given a baseline model, will return scores.\n",
        "- Load Data. Load all the documents, and set parameters.\n",
        "- save predictions\n",
        "\n",
        "\n",
        "Kernel: Pytorch and Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load file with training funcation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../scripts/') \n",
        "import baseline as bf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# df = pd.read_pickle(f\"{cf.output_path}/txtfiles.pkl\")\n",
        "df = pd.read_pickle(f\"{cf.output_path}/txtfiles_tokenizer.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({'train': 16445, 'test': 4373})\n",
            "Counter({'train': 15613, 'test': 4164, 'dev': 832, 'val': 209})\n",
            "Counter({'train': 9900, 'discard': 8718, 'test': 1100, 'val': 1100})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "sys.path.append('../scripts/') \n",
        "import baseline as bf\n",
        "from truncation import add_truncation_column\n",
        "\n",
        "print(Counter(df['2split']))\n",
        "print(Counter(df['4split']))\n",
        "print(Counter(df['balanced_split']))\n",
        "\n",
        "#set  variables, same for each model\n",
        "SPLIT_COLUMN = 'balanced_split' #column that has the data split saved. must be either 2split, 4split or balanced_split. 2split = data split into train and test. 4split = data split into train, test, dev and val. \n",
        "TRAIN_SET = 'train' # must be dev or train\n",
        "TEST_SET = 'test' # must be val or test\n",
        "# this split column, train_set and test_set might be a bit confusing. The split_column need to have values about the split, so a row either belongs, in my case, to 'train', 'test', 'dev' or 'val'.\n",
        "# Then the train_set indates which rows will be selected based on the filtering of the split column. \n",
        "# Thus if TRAIN_SET = 'train', then all rows where split_col is 'train', will be selected as the training set.\n",
        "# The same goes for TEST_SET    \n",
        "\n",
        "\n",
        "TEXT_COLUMN = 'text' # column where the text is\n",
        "LABEL_COLUMN = 'label' # column with truth label\n",
        "DATAFRAME = df.copy() # df where each rows is a doc. \n",
        "FOLDER = f\"{cf.output_path}/predictionsFinal/baselines\" # path where each individual prediction is saved\n",
        "OVERVIEW_PATH = f\"{cf.output_path}/predictionsFinal/baselines/overview.pkl\" # path where score and extra data about run is saved\n",
        "\n",
        "# needed for truncation experiment on baselines\n",
        "TRUNC_COLUMN = 'trunc_txt'\n",
        "TOKENS_COL = 'LlamaTokens'\n",
        "THRESHOLD_COMBINATIONS =[(100,0), (200,0), (100,100)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_truncation_on_baselines(baseline_function, model_name, predictions_path):\n",
        "    for thresholds in THRESHOLD_COMBINATIONS:\n",
        "\n",
        "        # select thresholds\n",
        "        front_threshold = thresholds[0]\n",
        "        back_threshold = thresholds[1]\n",
        "\n",
        "        # set run_id\n",
        "        run_id = f\"{model_name}_first{front_threshold}_last{back_threshold}\"\n",
        "\n",
        "        # get df with truncated text column\n",
        "        trunc = add_truncation_column(DATAFRAME, TEXT_COLUMN, TOKENS_COL, front_threshold,back_threshold)\n",
        "\n",
        "        # train and get predictions\n",
        "        bf.run_baseline(baseline_function, model_name, trunc, SPLIT_COLUMN, TRAIN_SET, TEST_SET, TRUNC_COLUMN, LABEL_COLUMN, predictions_path, OVERVIEW_PATH, run_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Baseline 1: linear SVM+tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/baselines/overview.pkl\n",
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/baselines/LinearSVCpredictions.pkl\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(OVERVIEW_PATH)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions_path)\n\u001b[0;32m----> 9\u001b[0m linear_svm \u001b[38;5;241m=\u001b[39m \u001b[43mbf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_baseline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATAFRAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSPLIT_COLUMN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTRAIN_SET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTEST_SET\u001b[49m\u001b[43m,\u001b[49m\u001b[43mTEXT_COLUMN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLABEL_COLUMN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOVERVIEW_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m run_truncation_on_baselines(baseline_function, model_name, predictions_path)\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/femke-2nd-gpu-110ram/code/Users/f.bakker/document-classification-using-large-language-models/notebooks/../scripts/baseline.py:31\u001b[0m, in \u001b[0;36mrun_baseline\u001b[0;34m(baseline_function, model_name, dataframe, split_col, subset_train, subset_test, text_col, label_col, prediction_path, overview_path, run_id)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# use TF-IDF vectorizer\u001b[39;00m\n\u001b[1;32m     30\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[0;32m---> 31\u001b[0m X_train_tfidf_bin \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext_col\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m X_test_tfidf_bin \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(X_test[text_col])\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# train classifier on training data\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:2138\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[1;32m   2132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2133\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[1;32m   2134\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[1;32m   2135\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[1;32m   2136\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[1;32m   2137\u001b[0m )\n\u001b[0;32m-> 2138\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2140\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[1;32m   2141\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1389\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1381\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1385\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1386\u001b[0m             )\n\u001b[1;32m   1387\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1389\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1392\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1276\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1275\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1276\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1277\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1278\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
            "File \u001b[0;32m/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:112\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    110\u001b[0m     doc \u001b[38;5;241m=\u001b[39m preprocessor(doc)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "model_name = 'LinearSVC'\n",
        "baseline_function = LinearSVC()\n",
        "run_id = f\"{model_name}_fulltext\"\n",
        "predictions_path = f\"{FOLDER}/{model_name}predictions.pkl\"\n",
        "\n",
        "print(OVERVIEW_PATH)\n",
        "print(predictions_path)\n",
        "linear_svm = bf.run_baseline(baseline_function, model_name , DATAFRAME, SPLIT_COLUMN, TRAIN_SET, TEST_SET,TEXT_COLUMN, LABEL_COLUMN, predictions_path, OVERVIEW_PATH, run_id)\n",
        "\n",
        "run_truncation_on_baselines(baseline_function, model_name, predictions_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Baseline 2: Naive Bayes+tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/baselines/overview.pkl\n",
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/baselines/MultinomialNBpredictions.pkl\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model_name = 'MultinomialNB'\n",
        "baseline_function = MultinomialNB()\n",
        "run_id = f\"{model_name}_fulltext\"\n",
        "predictions_path = f\"{FOLDER}/{model_name}predictions.pkl\"\n",
        "print(OVERVIEW_PATH)\n",
        "print(predictions_path)\n",
        "\n",
        "# naive_bayes = bf.run_baseline(baseline_function, model_name , DATAFRAME, SPLIT_COLUMN, TRAIN_SET, TEST_SET,TEXT_COLUMN, LABEL_COLUMN, predictions_path, OVERVIEW_PATH, run_id)\n",
        "\n",
        "# run_truncation_on_baselines(baseline_function, model_name, predictions_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Baseline 3: Logistic Regression + tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/baselines/overview.pkl\n",
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/baselines/LogisticRegressionpredictions.pkl\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model_name = 'LogisticRegression'\n",
        "baseline_function = LogisticRegression()\n",
        "run_id = f\"{model_name}_fulltext\"\n",
        "predictions_path = f\"{FOLDER}/{model_name}predictions.pkl\"\n",
        "\n",
        "print(OVERVIEW_PATH)\n",
        "print(predictions_path)\n",
        "\n",
        "# log_reg = bf.run_baseline(baseline_function, model_name , DATAFRAME, SPLIT_COLUMN, TRAIN_SET, TEST_SET,TEXT_COLUMN, LABEL_COLUMN, predictions_path, OVERVIEW_PATH, run_id)\n",
        "\n",
        "# run_truncation_on_baselines(baseline_function, model_name, predictions_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Baseline 4: k Nearest Neigbors + tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/baselines/overview.pkl\n",
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/baselines/KNeighborsClassifierpredictions.pkl\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model_name = 'KNeighborsClassifier'\n",
        "baseline_function = KNeighborsClassifier()\n",
        "run_id = f\"{model_name}_fulltext\"\n",
        "predictions_path = f\"{FOLDER}/{model_name}predictions.pkl\"\n",
        "\n",
        "print(OVERVIEW_PATH)\n",
        "print(predictions_path)\n",
        "# knn = bf.run_baseline(baseline_function, model_name , DATAFRAME, SPLIT_COLUMN, TRAIN_SET, TEST_SET,TEXT_COLUMN, LABEL_COLUMN, predictions_path, OVERVIEW_PATH, run_id)\n",
        "# \n",
        "# run_truncation_on_baselines(baseline_function, model_name, predictions_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Baseline 5: RandomForest + tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/baselines/overview.pkl\n",
            "/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/predictionsFinal/baselines/RandomForestClassifierpredictions.pkl\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_name = 'RandomForestClassifier'\n",
        "baseline_function = RandomForestClassifier()\n",
        "run_id = f\"{model_name}_fulltext\"\n",
        "predictions_path = f\"{FOLDER}/{model_name}predictions.pkl\"\n",
        "\n",
        "print(OVERVIEW_PATH)\n",
        "print(predictions_path)\n",
        "\n",
        "# random_forest = bf.run_baseline(baseline_function, model_name , DATAFRAME, SPLIT_COLUMN, TRAIN_SET, TEST_SET,TEXT_COLUMN, LABEL_COLUMN, predictions_path, OVERVIEW_PATH, run_id)\n",
        "\n",
        "# run_truncation_on_baselines(baseline_function, model_name, predictions_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Overview of all runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>date</th>\n",
              "      <th>run_id</th>\n",
              "      <th>train_set</th>\n",
              "      <th>test_set</th>\n",
              "      <th>train_set_support</th>\n",
              "      <th>test_set_support</th>\n",
              "      <th>split_col</th>\n",
              "      <th>text_col</th>\n",
              "      <th>runtime</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro_avg_precision</th>\n",
              "      <th>macro_avg_recall</th>\n",
              "      <th>macro_avg_f1</th>\n",
              "      <th>classification_report</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>2024-05-15 15:04:05.242133+02:00</td>\n",
              "      <td>LinearSVC_fulltext</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>text</td>\n",
              "      <td>27.136113</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.928945</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.905174</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>2024-05-15 15:04:13.555519+02:00</td>\n",
              "      <td>LinearSVC_first100_last0</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront100Back0</td>\n",
              "      <td>17.967054</td>\n",
              "      <td>0.883636</td>\n",
              "      <td>0.915587</td>\n",
              "      <td>0.883636</td>\n",
              "      <td>0.875062</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>2024-05-15 15:04:33.013663+02:00</td>\n",
              "      <td>LinearSVC_first200_last0</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront200Back0</td>\n",
              "      <td>29.550975</td>\n",
              "      <td>0.882727</td>\n",
              "      <td>0.915784</td>\n",
              "      <td>0.882727</td>\n",
              "      <td>0.872667</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>2024-05-15 15:05:03.913225+02:00</td>\n",
              "      <td>LinearSVC_first100_last100</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront100Back100</td>\n",
              "      <td>38.544936</td>\n",
              "      <td>0.889091</td>\n",
              "      <td>0.922796</td>\n",
              "      <td>0.889091</td>\n",
              "      <td>0.882482</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>2024-05-15 15:07:25.298385+02:00</td>\n",
              "      <td>MultinomialNB_fulltext</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront100Back100</td>\n",
              "      <td>24.376280</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.510466</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.445479</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>2024-05-15 15:07:33.363364+02:00</td>\n",
              "      <td>MultinomialNB_first100_last0</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront100Back0</td>\n",
              "      <td>17.915161</td>\n",
              "      <td>0.676364</td>\n",
              "      <td>0.604005</td>\n",
              "      <td>0.676364</td>\n",
              "      <td>0.606069</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>2024-05-15 15:07:52.727659+02:00</td>\n",
              "      <td>MultinomialNB_first200_last0</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront200Back0</td>\n",
              "      <td>29.898976</td>\n",
              "      <td>0.669091</td>\n",
              "      <td>0.694272</td>\n",
              "      <td>0.669091</td>\n",
              "      <td>0.595079</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>2024-05-15 15:08:23.938886+02:00</td>\n",
              "      <td>MultinomialNB_first100_last100</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront100Back100</td>\n",
              "      <td>38.967012</td>\n",
              "      <td>0.665455</td>\n",
              "      <td>0.607280</td>\n",
              "      <td>0.665455</td>\n",
              "      <td>0.587982</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>2024-05-15 15:10:55.905981+02:00</td>\n",
              "      <td>LogisticRegression_fulltext</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront100Back100</td>\n",
              "      <td>55.377151</td>\n",
              "      <td>0.874545</td>\n",
              "      <td>0.903397</td>\n",
              "      <td>0.874545</td>\n",
              "      <td>0.864052</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>2024-05-15 15:11:09.919198+02:00</td>\n",
              "      <td>LogisticRegression_first100_last0</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront100Back0</td>\n",
              "      <td>23.894600</td>\n",
              "      <td>0.854545</td>\n",
              "      <td>0.903185</td>\n",
              "      <td>0.854545</td>\n",
              "      <td>0.835388</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>2024-05-15 15:11:37.816683+02:00</td>\n",
              "      <td>LogisticRegression_first200_last0</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront200Back0</td>\n",
              "      <td>37.763549</td>\n",
              "      <td>0.862727</td>\n",
              "      <td>0.907136</td>\n",
              "      <td>0.862727</td>\n",
              "      <td>0.846879</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>2024-05-15 15:12:17.498715+02:00</td>\n",
              "      <td>LogisticRegression_first100_last100</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront100Back100</td>\n",
              "      <td>47.561654</td>\n",
              "      <td>0.852727</td>\n",
              "      <td>0.905185</td>\n",
              "      <td>0.852727</td>\n",
              "      <td>0.833257</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>2024-05-15 15:13:51.674774+02:00</td>\n",
              "      <td>RandomForestClassifier_fulltext</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront100Back100</td>\n",
              "      <td>60.053122</td>\n",
              "      <td>0.857273</td>\n",
              "      <td>0.904137</td>\n",
              "      <td>0.857273</td>\n",
              "      <td>0.845614</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>2024-05-15 15:14:06.399404+02:00</td>\n",
              "      <td>RandomForestClassifier_first100_last0</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront100Back0</td>\n",
              "      <td>24.323382</td>\n",
              "      <td>0.862727</td>\n",
              "      <td>0.907597</td>\n",
              "      <td>0.862727</td>\n",
              "      <td>0.852021</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>2024-05-15 15:14:33.126219+02:00</td>\n",
              "      <td>RandomForestClassifier_first200_last0</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront200Back0</td>\n",
              "      <td>37.668777</td>\n",
              "      <td>0.862727</td>\n",
              "      <td>0.905115</td>\n",
              "      <td>0.862727</td>\n",
              "      <td>0.849060</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>2024-05-15 15:15:13.165839+02:00</td>\n",
              "      <td>RandomForestClassifier_first100_last100</td>\n",
              "      <td>train</td>\n",
              "      <td>test</td>\n",
              "      <td>9900</td>\n",
              "      <td>1100</td>\n",
              "      <td>balanced_split</td>\n",
              "      <td>TruncationLlamaTokensFront100Back100</td>\n",
              "      <td>48.077030</td>\n",
              "      <td>0.856364</td>\n",
              "      <td>0.907938</td>\n",
              "      <td>0.856364</td>\n",
              "      <td>0.844109</td>\n",
              "      <td>precision    recall  f1-s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    model                             date  \\\n",
              "0               LinearSVC 2024-05-15 15:04:05.242133+02:00   \n",
              "0               LinearSVC 2024-05-15 15:04:13.555519+02:00   \n",
              "0               LinearSVC 2024-05-15 15:04:33.013663+02:00   \n",
              "0               LinearSVC 2024-05-15 15:05:03.913225+02:00   \n",
              "0           MultinomialNB 2024-05-15 15:07:25.298385+02:00   \n",
              "0           MultinomialNB 2024-05-15 15:07:33.363364+02:00   \n",
              "0           MultinomialNB 2024-05-15 15:07:52.727659+02:00   \n",
              "0           MultinomialNB 2024-05-15 15:08:23.938886+02:00   \n",
              "0      LogisticRegression 2024-05-15 15:10:55.905981+02:00   \n",
              "0      LogisticRegression 2024-05-15 15:11:09.919198+02:00   \n",
              "0      LogisticRegression 2024-05-15 15:11:37.816683+02:00   \n",
              "0      LogisticRegression 2024-05-15 15:12:17.498715+02:00   \n",
              "0  RandomForestClassifier 2024-05-15 15:13:51.674774+02:00   \n",
              "0  RandomForestClassifier 2024-05-15 15:14:06.399404+02:00   \n",
              "0  RandomForestClassifier 2024-05-15 15:14:33.126219+02:00   \n",
              "0  RandomForestClassifier 2024-05-15 15:15:13.165839+02:00   \n",
              "\n",
              "                                    run_id train_set test_set  \\\n",
              "0                       LinearSVC_fulltext     train     test   \n",
              "0                 LinearSVC_first100_last0     train     test   \n",
              "0                 LinearSVC_first200_last0     train     test   \n",
              "0               LinearSVC_first100_last100     train     test   \n",
              "0                   MultinomialNB_fulltext     train     test   \n",
              "0             MultinomialNB_first100_last0     train     test   \n",
              "0             MultinomialNB_first200_last0     train     test   \n",
              "0           MultinomialNB_first100_last100     train     test   \n",
              "0              LogisticRegression_fulltext     train     test   \n",
              "0        LogisticRegression_first100_last0     train     test   \n",
              "0        LogisticRegression_first200_last0     train     test   \n",
              "0      LogisticRegression_first100_last100     train     test   \n",
              "0          RandomForestClassifier_fulltext     train     test   \n",
              "0    RandomForestClassifier_first100_last0     train     test   \n",
              "0    RandomForestClassifier_first200_last0     train     test   \n",
              "0  RandomForestClassifier_first100_last100     train     test   \n",
              "\n",
              "   train_set_support  test_set_support       split_col  \\\n",
              "0               9900              1100  balanced_split   \n",
              "0               9900              1100  balanced_split   \n",
              "0               9900              1100  balanced_split   \n",
              "0               9900              1100  balanced_split   \n",
              "0               9900              1100  balanced_split   \n",
              "0               9900              1100  balanced_split   \n",
              "0               9900              1100  balanced_split   \n",
              "0               9900              1100  balanced_split   \n",
              "0               9900              1100  balanced_split   \n",
              "0               9900              1100  balanced_split   \n",
              "0               9900              1100  balanced_split   \n",
              "0               9900              1100  balanced_split   \n",
              "0               9900              1100  balanced_split   \n",
              "0               9900              1100  balanced_split   \n",
              "0               9900              1100  balanced_split   \n",
              "0               9900              1100  balanced_split   \n",
              "\n",
              "                               text_col    runtime  accuracy  \\\n",
              "0                                  text  27.136113  0.909091   \n",
              "0    TruncationLlamaTokensFront100Back0  17.967054  0.883636   \n",
              "0    TruncationLlamaTokensFront200Back0  29.550975  0.882727   \n",
              "0  TruncationLlamaTokensFront100Back100  38.544936  0.889091   \n",
              "0  TruncationLlamaTokensFront100Back100  24.376280  0.545455   \n",
              "0    TruncationLlamaTokensFront100Back0  17.915161  0.676364   \n",
              "0    TruncationLlamaTokensFront200Back0  29.898976  0.669091   \n",
              "0  TruncationLlamaTokensFront100Back100  38.967012  0.665455   \n",
              "0  TruncationLlamaTokensFront100Back100  55.377151  0.874545   \n",
              "0    TruncationLlamaTokensFront100Back0  23.894600  0.854545   \n",
              "0    TruncationLlamaTokensFront200Back0  37.763549  0.862727   \n",
              "0  TruncationLlamaTokensFront100Back100  47.561654  0.852727   \n",
              "0  TruncationLlamaTokensFront100Back100  60.053122  0.857273   \n",
              "0    TruncationLlamaTokensFront100Back0  24.323382  0.862727   \n",
              "0    TruncationLlamaTokensFront200Back0  37.668777  0.862727   \n",
              "0  TruncationLlamaTokensFront100Back100  48.077030  0.856364   \n",
              "\n",
              "   macro_avg_precision  macro_avg_recall  macro_avg_f1  \\\n",
              "0             0.928945          0.909091      0.905174   \n",
              "0             0.915587          0.883636      0.875062   \n",
              "0             0.915784          0.882727      0.872667   \n",
              "0             0.922796          0.889091      0.882482   \n",
              "0             0.510466          0.545455      0.445479   \n",
              "0             0.604005          0.676364      0.606069   \n",
              "0             0.694272          0.669091      0.595079   \n",
              "0             0.607280          0.665455      0.587982   \n",
              "0             0.903397          0.874545      0.864052   \n",
              "0             0.903185          0.854545      0.835388   \n",
              "0             0.907136          0.862727      0.846879   \n",
              "0             0.905185          0.852727      0.833257   \n",
              "0             0.904137          0.857273      0.845614   \n",
              "0             0.907597          0.862727      0.852021   \n",
              "0             0.905115          0.862727      0.849060   \n",
              "0             0.907938          0.856364      0.844109   \n",
              "\n",
              "                               classification_report  \n",
              "0                       precision    recall  f1-s...  \n",
              "0                       precision    recall  f1-s...  \n",
              "0                       precision    recall  f1-s...  \n",
              "0                       precision    recall  f1-s...  \n",
              "0                       precision    recall  f1-s...  \n",
              "0                       precision    recall  f1-s...  \n",
              "0                       precision    recall  f1-s...  \n",
              "0                       precision    recall  f1-s...  \n",
              "0                       precision    recall  f1-s...  \n",
              "0                       precision    recall  f1-s...  \n",
              "0                       precision    recall  f1-s...  \n",
              "0                       precision    recall  f1-s...  \n",
              "0                       precision    recall  f1-s...  \n",
              "0                       precision    recall  f1-s...  \n",
              "0                       precision    recall  f1-s...  \n",
              "0                       precision    recall  f1-s...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "overview = pd.read_pickle(OVERVIEW_PATH)\n",
        "display(overview)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "2AmsterdamLLM",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
