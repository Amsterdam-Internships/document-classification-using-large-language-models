{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash /home/azureuser/cloudfiles/code/blobfuse/blobfuse_raadsinformatie.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Select where to run notebook: \"azure\" or \"local\"\n",
    "my_run = \"azure\"\n",
    "\n",
    "# import my_secrets as sc\n",
    "import settings as st\n",
    "\n",
    "if my_run == \"azure\":\n",
    "    import config_azure as cf\n",
    "elif my_run == \"local\":\n",
    "    import config as cf\n",
    "\n",
    "\n",
    "import os\n",
    "if my_run == \"azure\":\n",
    "    if not os.path.exists(cf.HUGGING_CACHE):\n",
    "        os.mkdir(cf.HUGGING_CACHE)\n",
    "    os.environ[\"TRANSFORMERS_CACHE\"] = cf.HUGGING_CACHE\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Overview\n",
    "Goal: Fine-tune models for document classification.\n",
    "\n",
    "Method: the documents are shortened by taking the first 200 tokens. Then the shortened doc is formatted using the zero-shot prompt, without template. Then the ideal response is formatted according to JSON format. Formatted doc and response are combined into conversation using the apply_chat_template function. \n",
    "\n",
    "*Previous notebook: FinetuningDataFormatting*\n",
    "\n",
    "*Next notebook: GetPredictions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41a8d4cd0204d25bc14b04b12c25104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# necesarry to log in to huggingface, to save models there\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning GEITje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GEITje formatted data\n",
    "\n",
    "from datasets import load_dataset\n",
    "chat_dataset = load_dataset('FemkeBakker/AmsterdamBalancedFirst200Tokens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53774210df5e4befae02c8fdda192956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8ddf5174fc401a86d247658160f27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# basemodel_name = 'Rijgersberg/GEITje-7B-chat-v2'\n",
    "basemodel_name = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "# basemodel_name = \"stabilityai/stablelm-2-1_6b\"\n",
    "# basemodel_name = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "model = AutoModelForCausalLM.from_pretrained(basemodel_name, torch_dtype=torch.bfloat16,\n",
    "                                                low_cpu_mem_usage=True, attn_implementation=\"sdpa\",\n",
    "                                                device_map='cpu')\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(basemodel_name)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "model.config.pad_token_id = tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# funcation to load previous saved dataframe and combine with current model, then save again\n",
    "def combine_and_save_df(model_df, save_to_path):\n",
    "    \n",
    "    # combine with earlier runs if exists\n",
    "    if os.path.exists(save_to_path):\n",
    "        original = pd.read_pickle(save_to_path)\n",
    "        model_df = pd.concat([original, model_df])\n",
    "\n",
    "    model_df.to_pickle(save_to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import DatasetDict, load_dataset, concatenate_datasets\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/') \n",
    "import prediction_helperfunctions as ph\n",
    "\n",
    "def train(model, model_name, tokenizer, chat_dataset, chat_dataset_name, new_model_name, output_directory, train_set, test_set, n_epochs, run_id='No_id', save_to_hub=True, resume=False):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # format conversations\n",
    "    def format(examples):\n",
    "        return [tokenizer.apply_chat_template(conversation, tokenize=False)\n",
    "                for conversation in examples['message']]\n",
    "\n",
    "    per_device_train_batch_size = 2\n",
    "    gradient_accumulation_steps = 8\n",
    "    steps_per_epoch = len(chat_dataset[train_set])\\\n",
    "                // (torch.cuda.device_count() * per_device_train_batch_size * gradient_accumulation_steps)\n",
    "    eval_steps = steps_per_epoch // 5\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        optim='adamw_bnb_8bit',\n",
    "        num_train_epochs=n_epochs,\n",
    "        learning_rate=1e-5,\n",
    "        lr_scheduler_type='cosine',\n",
    "        warmup_ratio=0.1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=8,\n",
    "        gradient_checkpointing=True,\n",
    "        evaluation_strategy='steps',\n",
    "        eval_steps=eval_steps,\n",
    "        save_strategy='epoch',\n",
    "        bf16=False, #bf16=True require CUDA 11 -> original code bf16=True\n",
    "        output_dir=output_directory,\n",
    "        report_to=[\"tensorboard\", 'wandb'],\n",
    "        logging_steps=1,\n",
    "        logging_first_step=True,\n",
    "        hub_model_id=new_model_name,\n",
    "        push_to_hub=True,\n",
    "        hub_private_repo=True,\n",
    "        hub_strategy='all_checkpoints',\n",
    "    )\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=8192,\n",
    "        train_dataset=chat_dataset[train_set],\n",
    "        eval_dataset=chat_dataset[test_set],\n",
    "        formatting_func=format,\n",
    "        neftune_noise_alpha=5,\n",
    "    )\n",
    "\n",
    "  \n",
    "    dict_info = {\n",
    "        'model':new_model_name,\n",
    "        'base_model':model_name,\n",
    "        'chat_dataset':chat_dataset_name,\n",
    "        'train_set':train_set,\n",
    "        'test_set': test_set,\n",
    "        'training_args': training_args,\n",
    "        'resume_from_checkpoint':resume,\n",
    "        'date':ph.get_datetime(),\n",
    "        'runtime': False,\n",
    "        'Error': False,\n",
    "        'run_id':run_id,\n",
    "        'save_to_hub':save_to_hub,\n",
    "        'output_dir': output_directory,\n",
    "        'num_train_epochs':n_epochs\n",
    "        }\n",
    "\n",
    "    data = pd.DataFrame(columns=dict_info.keys())\n",
    "\n",
    "    # if no error during training, save run in overview_models and push to hub\n",
    "    try:\n",
    "        trainer.train(resume_from_checkpoint=resume)\n",
    "        if save_to_hub == True:\n",
    "            trainer.push_to_hub()\n",
    "            \n",
    "        dict_info['runtime'] = time.time()-start_time\n",
    "\n",
    "        data.loc[len(data)] = dict_info\n",
    "        combine_and_save_df(data, f'{cf.output_path}/finetuning_output/overview_models.pkl')\n",
    "        print(\"Finished without error!\")\n",
    "\n",
    "    # if keyboardinterrupted or an error is thrown, save run in overview_models\n",
    "    except KeyboardInterrupt:\n",
    "        dict_info['Error'] = 'KeyboardInterrupt'        \n",
    "        dict_info['runtime'] = time.time()-start_time\n",
    "\n",
    "        data.loc[len(data)] = dict_info\n",
    "        combine_and_save_df(data, f'{cf.output_path}/finetuning_output/overview_models.pkl')\n",
    "\n",
    "    except Exception  as e:\n",
    "        print(e)\n",
    "        dict_info['Error'] = e\n",
    "        dict_info['runtime'] = time.time()-start_time\n",
    "\n",
    "        data.loc[len(data)] = dict_info\n",
    "        combine_and_save_df(data, f'{cf.output_path}/finetuning_output/overview_models.pkl')\n",
    "\n",
    "\n",
    "        model_df = pd.DataFrame(dict_info)\n",
    "        combine_and_save_df(model_df, f'{cf.output_path}/finetuning_output/overview_models.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "To use resume_from_checkpoint, the epoch must be complete; otherwise, it will throw an error. If an error occurs even after an epoch is complete, remove the last checkpoint folder to resolve this. This means you can only resume training from a completed checkpoint. Since each epoch took about 50 minutes, this was not an issue.\n",
    "\n",
    "MAKE SURE: run_id is unique, for each seperate run. Check overview_models.pkl to find which run ids have already been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to folder where the checkpoint of the model need to be saved\n",
    "output_directory = f'{cf.output_path}/finetuning_output/MistralTry2epochs'\n",
    "\n",
    "# the name of the chat dataset\n",
    "chat_dataset_name = 'FemkeBakker/AmsterdamBalancedFirst200Tokens'\n",
    "\n",
    "training_set = 'train' \n",
    "validation_set = 'val'\n",
    "\n",
    "new_model_name = 'FemkeBakker/MistralTry2epochs'\n",
    "n_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:257: UserWarning: You passed a `neftune_noise_alpha` argument to the SFTTrainer, the value you passed will override the one in the `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfemkebakker\u001b[0m (\u001b[33mthesisamsterdam\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/batch/tasks/shared/LS_root/mounts/clusters/femke-gpu-24cores-220ram/code/Users/f.bakker/document-classification-using-large-language-models/notebooks/wandb/run-20240614_080415-2uj4idx7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/thesisamsterdam/huggingface/runs/2uj4idx7\" target=\"_blank\">/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/MistralTry2epochs</a></strong> to <a href=\"https://wandb.ai/thesisamsterdam/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1236' max='1236' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1236/1236 1:07:29, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.986300</td>\n",
       "      <td>0.879042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>0.791800</td>\n",
       "      <td>0.832382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>369</td>\n",
       "      <td>0.513300</td>\n",
       "      <td>0.791489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>492</td>\n",
       "      <td>0.570200</td>\n",
       "      <td>0.759139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.697555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>738</td>\n",
       "      <td>0.587200</td>\n",
       "      <td>0.676763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>861</td>\n",
       "      <td>0.424200</td>\n",
       "      <td>0.664945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>984</td>\n",
       "      <td>0.522200</td>\n",
       "      <td>0.660889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1107</td>\n",
       "      <td>0.260900</td>\n",
       "      <td>0.659912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.483400</td>\n",
       "      <td>0.660117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/2AmsterdamLLM/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished without error!\n"
     ]
    }
   ],
   "source": [
    "train(model, basemodel_name, tokenizer, chat_dataset, chat_dataset_name,new_model_name,\n",
    "          output_directory, training_set, validation_set,  n_epochs, run_id=31, save_to_hub=True, resume=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: clean up overview file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = pd.read_pickle(f'{cf.output_path}/finetuning_output/overview_models.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "yeet = overview.loc[overview['Error']!= 'KeyboardInterrupt']\n",
    "yeet = yeet.drop(columns=['training_args'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>base_model</th>\n",
       "      <th>chat_dataset</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>resume_from_checkpoint</th>\n",
       "      <th>date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>Error</th>\n",
       "      <th>run_id</th>\n",
       "      <th>save_to_hub</th>\n",
       "      <th>output_dir</th>\n",
       "      <th>num_train_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationGEITje200T</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-29 14:07:04.642821+02:00</td>\n",
       "      <td>2926.216714</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationGEITje200T</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistral200T</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-29 15:36:45.085202+02:00</td>\n",
       "      <td>2879.482625</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationMistral200T</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationLlama200T</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-29 16:44:49.778730+02:00</td>\n",
       "      <td>2459.635145</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationLlama200T</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationLlama200T</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-29 17:32:34.996990+02:00</td>\n",
       "      <td>2435.851116</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationLlama200T</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistrallama200T</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-29 18:17:40.189426+02:00</td>\n",
       "      <td>2909.715319</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationMistral200T</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistral200T</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-29 19:21:12.049071+02:00</td>\n",
       "      <td>370.747607</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationMistral200T</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationGEITje200T</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-29 19:39:27.535325+02:00</td>\n",
       "      <td>2821.834527</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationGEITje200T</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationGEITje200T2Epochs</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-03 08:33:45.251941+02:00</td>\n",
       "      <td>419.937012</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationGEITje200T</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationLlama200T2Epochs</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-03 08:52:32.234614+02:00</td>\n",
       "      <td>378.556517</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationLlama200T</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistral200T2Epochs</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-03 09:10:08.642664+02:00</td>\n",
       "      <td>257.880533</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationMistral200T</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistral200T2Epochs</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-03 09:47:29.893554+02:00</td>\n",
       "      <td>4838.240750</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationMistral200T</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistral200T3Epochs</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-03 11:46:00.812280+02:00</td>\n",
       "      <td>2946.555611</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationMistral200T3Epochs</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationGEITje200T3Epochs</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-03 12:37:59.230015+02:00</td>\n",
       "      <td>3017.832458</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationGEITje200T3Epochs</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistral200T1Epochs</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-03 13:43:52.561702+02:00</td>\n",
       "      <td>2617.233767</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationMistral200T1Epochs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationLlama200T1Epochs</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-03 14:50:23.584077+02:00</td>\n",
       "      <td>2360.351855</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationLlama200T1Epochs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationGEITje200T1Epochs</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-03 16:00:56.389979+02:00</td>\n",
       "      <td>2804.619510</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationGEITje200T1Epochs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationLlama200T3Epochs</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-03 16:59:27.147043+02:00</td>\n",
       "      <td>2569.094163</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationLlama200T3Epochs</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/Try2epochGEITje</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-13 16:02:56.282677+02:00</td>\n",
       "      <td>1.883692</td>\n",
       "      <td>No valid checkpoint found in output directory (/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/OutputTry2epochGEITje)</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/OutputTry2epochGEITje</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/Try2epochGEITje</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-13 16:03:19.036004+02:00</td>\n",
       "      <td>0.325213</td>\n",
       "      <td>No valid checkpoint found in output directory (/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/OutputTry2epochGEITje)</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/OutputTry2epochGEITje</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/MistralTry2epochs</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-14 09:58:59.555286+02:00</td>\n",
       "      <td>4925.885951</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/MistralTry2epochs</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/MistralTry3epochs</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-14 12:26:24.665959+02:00</td>\n",
       "      <td>2984.912049</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/MistralTry3epochs</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/Mistral3Epochs</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-14 13:33:27.353668+02:00</td>\n",
       "      <td>6528.719046</td>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/Mistral3Epochs</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      model  \\\n",
       "0          FemkeBakker/AmsterdamDocClassificationGEITje200T   \n",
       "0         FemkeBakker/AmsterdamDocClassificationMistral200T   \n",
       "0           FemkeBakker/AmsterdamDocClassificationLlama200T   \n",
       "0           FemkeBakker/AmsterdamDocClassificationLlama200T   \n",
       "0     FemkeBakker/AmsterdamDocClassificationMistrallama200T   \n",
       "0         FemkeBakker/AmsterdamDocClassificationMistral200T   \n",
       "0          FemkeBakker/AmsterdamDocClassificationGEITje200T   \n",
       "0   FemkeBakker/AmsterdamDocClassificationGEITje200T2Epochs   \n",
       "0    FemkeBakker/AmsterdamDocClassificationLlama200T2Epochs   \n",
       "0  FemkeBakker/AmsterdamDocClassificationMistral200T2Epochs   \n",
       "0  FemkeBakker/AmsterdamDocClassificationMistral200T2Epochs   \n",
       "0  FemkeBakker/AmsterdamDocClassificationMistral200T3Epochs   \n",
       "0   FemkeBakker/AmsterdamDocClassificationGEITje200T3Epochs   \n",
       "0  FemkeBakker/AmsterdamDocClassificationMistral200T1Epochs   \n",
       "0    FemkeBakker/AmsterdamDocClassificationLlama200T1Epochs   \n",
       "0   FemkeBakker/AmsterdamDocClassificationGEITje200T1Epochs   \n",
       "0    FemkeBakker/AmsterdamDocClassificationLlama200T3Epochs   \n",
       "0                               FemkeBakker/Try2epochGEITje   \n",
       "0                               FemkeBakker/Try2epochGEITje   \n",
       "0                             FemkeBakker/MistralTry2epochs   \n",
       "0                             FemkeBakker/MistralTry3epochs   \n",
       "0                                FemkeBakker/Mistral3Epochs   \n",
       "\n",
       "                           base_model  \\\n",
       "0       Rijgersberg/GEITje-7B-chat-v2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0       meta-llama/Llama-2-7b-chat-hf   \n",
       "0       meta-llama/Llama-2-7b-chat-hf   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0       Rijgersberg/GEITje-7B-chat-v2   \n",
       "0       Rijgersberg/GEITje-7B-chat-v2   \n",
       "0       meta-llama/Llama-2-7b-chat-hf   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0       Rijgersberg/GEITje-7B-chat-v2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0       meta-llama/Llama-2-7b-chat-hf   \n",
       "0       Rijgersberg/GEITje-7B-chat-v2   \n",
       "0       meta-llama/Llama-2-7b-chat-hf   \n",
       "0       Rijgersberg/GEITje-7B-chat-v2   \n",
       "0       Rijgersberg/GEITje-7B-chat-v2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "\n",
       "                                  chat_dataset train_set test_set  \\\n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "\n",
       "   resume_from_checkpoint                             date      runtime  \\\n",
       "0                   False 2024-05-29 14:07:04.642821+02:00  2926.216714   \n",
       "0                   False 2024-05-29 15:36:45.085202+02:00  2879.482625   \n",
       "0                   False 2024-05-29 16:44:49.778730+02:00  2459.635145   \n",
       "0                    True 2024-05-29 17:32:34.996990+02:00  2435.851116   \n",
       "0                    True 2024-05-29 18:17:40.189426+02:00  2909.715319   \n",
       "0                    True 2024-05-29 19:21:12.049071+02:00   370.747607   \n",
       "0                    True 2024-05-29 19:39:27.535325+02:00  2821.834527   \n",
       "0                    True 2024-06-03 08:33:45.251941+02:00   419.937012   \n",
       "0                    True 2024-06-03 08:52:32.234614+02:00   378.556517   \n",
       "0                    True 2024-06-03 09:10:08.642664+02:00   257.880533   \n",
       "0                   False 2024-06-03 09:47:29.893554+02:00  4838.240750   \n",
       "0                    True 2024-06-03 11:46:00.812280+02:00  2946.555611   \n",
       "0                    True 2024-06-03 12:37:59.230015+02:00  3017.832458   \n",
       "0                   False 2024-06-03 13:43:52.561702+02:00  2617.233767   \n",
       "0                   False 2024-06-03 14:50:23.584077+02:00  2360.351855   \n",
       "0                   False 2024-06-03 16:00:56.389979+02:00  2804.619510   \n",
       "0                    True 2024-06-03 16:59:27.147043+02:00  2569.094163   \n",
       "0                    True 2024-06-13 16:02:56.282677+02:00     1.883692   \n",
       "0                    True 2024-06-13 16:03:19.036004+02:00     0.325213   \n",
       "0                   False 2024-06-14 09:58:59.555286+02:00  4925.885951   \n",
       "0                    True 2024-06-14 12:26:24.665959+02:00  2984.912049   \n",
       "0                   False 2024-06-14 13:33:27.353668+02:00  6528.719046   \n",
       "\n",
       "                                                                                                                                                                                         Error  \\\n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0  No valid checkpoint found in output directory (/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/OutputTry2epochGEITje)   \n",
       "0  No valid checkpoint found in output directory (/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/OutputTry2epochGEITje)   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "0                                                                                                                                                                                        False   \n",
       "\n",
       "   run_id save_to_hub  \\\n",
       "0      15        True   \n",
       "0      16        True   \n",
       "0      17        True   \n",
       "0      17        True   \n",
       "0      16        True   \n",
       "0      16        True   \n",
       "0      15        True   \n",
       "0      18        True   \n",
       "0      19        True   \n",
       "0      20        True   \n",
       "0      22        True   \n",
       "0      23        True   \n",
       "0      24        True   \n",
       "0      25        True   \n",
       "0      26        True   \n",
       "0      27        True   \n",
       "0      28        True   \n",
       "0      30        True   \n",
       "0      30        True   \n",
       "0      31        True   \n",
       "0      32        True   \n",
       "0      33        True   \n",
       "\n",
       "                                                                                                                                                                   output_dir  \\\n",
       "0                  /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationGEITje200T   \n",
       "0                 /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationMistral200T   \n",
       "0                   /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationLlama200T   \n",
       "0                   /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationLlama200T   \n",
       "0                 /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationMistral200T   \n",
       "0                 /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationMistral200T   \n",
       "0                  /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationGEITje200T   \n",
       "0                  /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationGEITje200T   \n",
       "0                   /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationLlama200T   \n",
       "0                 /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationMistral200T   \n",
       "0         /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationMistral200T   \n",
       "0          /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationMistral200T3Epochs   \n",
       "0           /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationGEITje200T3Epochs   \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationMistral200T1Epochs   \n",
       "0    /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationLlama200T1Epochs   \n",
       "0   /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationGEITje200T1Epochs   \n",
       "0            /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/AmsterdamDocClassificationLlama200T3Epochs   \n",
       "0                                 /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/OutputTry2epochGEITje   \n",
       "0                                 /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/OutputTry2epochGEITje   \n",
       "0                                     /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/MistralTry2epochs   \n",
       "0                                     /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/MistralTry3epochs   \n",
       "0                                /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/Mistral3Epochs   \n",
       "\n",
       "   num_train_epochs  \n",
       "0               1.0  \n",
       "0               1.0  \n",
       "0               1.0  \n",
       "0               2.0  \n",
       "0               2.0  \n",
       "0               2.0  \n",
       "0               2.0  \n",
       "0               2.0  \n",
       "0               2.0  \n",
       "0               2.0  \n",
       "0               2.0  \n",
       "0               3.0  \n",
       "0               3.0  \n",
       "0               1.0  \n",
       "0               1.0  \n",
       "0               1.0  \n",
       "0               3.0  \n",
       "0               3.0  \n",
       "0               3.0  \n",
       "0               2.0  \n",
       "0               3.0  \n",
       "0               3.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(yeet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>base_model</th>\n",
       "      <th>chat_dataset</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>resume_from_checkpoint</th>\n",
       "      <th>date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>Error</th>\n",
       "      <th>run_id</th>\n",
       "      <th>save_to_hub</th>\n",
       "      <th>output_dir</th>\n",
       "      <th>num_train_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationGEITje200T1Epochs</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-29 14:07:04.642821+02:00</td>\n",
       "      <td>2926.216714</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationGEITje200T1Epochs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationGEITje200T2Epochs</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-29 19:39:27.535325+02:00</td>\n",
       "      <td>2821.834527</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationGEITje200T2Epochs</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationGEITje200T3Epochs</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-03 12:37:59.230015+02:00</td>\n",
       "      <td>3017.832458</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/AmsterdamDocClassificationGEITje200T3Epochs</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     model  \\\n",
       "0  FemkeBakker/AmsterdamDocClassificationGEITje200T1Epochs   \n",
       "0  FemkeBakker/AmsterdamDocClassificationGEITje200T2Epochs   \n",
       "0  FemkeBakker/AmsterdamDocClassificationGEITje200T3Epochs   \n",
       "\n",
       "                      base_model                                 chat_dataset  \\\n",
       "0  Rijgersberg/GEITje-7B-chat-v2  FemkeBakker/AmsterdamBalancedFirst200Tokens   \n",
       "0  Rijgersberg/GEITje-7B-chat-v2  FemkeBakker/AmsterdamBalancedFirst200Tokens   \n",
       "0  Rijgersberg/GEITje-7B-chat-v2  FemkeBakker/AmsterdamBalancedFirst200Tokens   \n",
       "\n",
       "  train_set test_set  resume_from_checkpoint                             date  \\\n",
       "0     train      val                   False 2024-05-29 14:07:04.642821+02:00   \n",
       "0     train      val                    True 2024-05-29 19:39:27.535325+02:00   \n",
       "0     train      val                    True 2024-06-03 12:37:59.230015+02:00   \n",
       "\n",
       "       runtime  Error  run_id save_to_hub  \\\n",
       "0  2926.216714  False      15        True   \n",
       "0  2821.834527  False      15        True   \n",
       "0  3017.832458  False      24        True   \n",
       "\n",
       "                                                                                                                                                                  output_dir  \\\n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationGEITje200T1Epochs   \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationGEITje200T2Epochs   \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/AmsterdamDocClassificationGEITje200T3Epochs   \n",
       "\n",
       "   num_train_epochs  \n",
       "0               1.0  \n",
       "0               2.0  \n",
       "0               3.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "geitje = yeet.loc[yeet['base_model']=='Rijgersberg/GEITje-7B-chat-v2']\n",
    "geitje = geitje.loc[~geitje['model'].isin(['FemkeBakker/Try2epochGEITje', 'FemkeBakker/AmsterdamDocClassificationGEITje200T2Epochs', 'FemkeBakker/AmsterdamDocClassificationGEITje200T1Epochs'])]\n",
    "geitje['model'] = ['FemkeBakker/AmsterdamDocClassificationGEITje200T1Epochs', 'FemkeBakker/AmsterdamDocClassificationGEITje200T2Epochs', 'FemkeBakker/AmsterdamDocClassificationGEITje200T3Epochs']\n",
    "geitje['output_dir'] = ['/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationGEITje200T1Epochs', '/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationGEITje200T2Epochs', '/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/AmsterdamDocClassificationGEITje200T3Epochs']\n",
    "display(geitje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46714/2490775648.py:3: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns, Europe/Amsterdam] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  llama = llama.loc[~llama['date'].isin(['2024-05-29 16:44:49.778730+02:00'])]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>base_model</th>\n",
       "      <th>chat_dataset</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>resume_from_checkpoint</th>\n",
       "      <th>date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>Error</th>\n",
       "      <th>run_id</th>\n",
       "      <th>save_to_hub</th>\n",
       "      <th>output_dir</th>\n",
       "      <th>num_train_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationLlama200T2Epochs</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-29 17:32:34.996990+02:00</td>\n",
       "      <td>2435.851116</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationLlama200T2Epochs</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationLlama200T1Epochs</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-03 14:50:23.584077+02:00</td>\n",
       "      <td>2360.351855</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationLlama200T1Epochs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationLlama200T3Epochs</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-03 16:59:27.147043+02:00</td>\n",
       "      <td>2569.094163</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/AmsterdamDocClassificationLlama200T3Epochs</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    model  \\\n",
       "0  FemkeBakker/AmsterdamDocClassificationLlama200T2Epochs   \n",
       "0  FemkeBakker/AmsterdamDocClassificationLlama200T1Epochs   \n",
       "0  FemkeBakker/AmsterdamDocClassificationLlama200T3Epochs   \n",
       "\n",
       "                      base_model                                 chat_dataset  \\\n",
       "0  meta-llama/Llama-2-7b-chat-hf  FemkeBakker/AmsterdamBalancedFirst200Tokens   \n",
       "0  meta-llama/Llama-2-7b-chat-hf  FemkeBakker/AmsterdamBalancedFirst200Tokens   \n",
       "0  meta-llama/Llama-2-7b-chat-hf  FemkeBakker/AmsterdamBalancedFirst200Tokens   \n",
       "\n",
       "  train_set test_set  resume_from_checkpoint                             date  \\\n",
       "0     train      val                    True 2024-05-29 17:32:34.996990+02:00   \n",
       "0     train      val                   False 2024-06-03 14:50:23.584077+02:00   \n",
       "0     train      val                    True 2024-06-03 16:59:27.147043+02:00   \n",
       "\n",
       "       runtime  Error  run_id save_to_hub  \\\n",
       "0  2435.851116  False      17        True   \n",
       "0  2360.351855  False      26        True   \n",
       "0  2569.094163  False      28        True   \n",
       "\n",
       "                                                                                                                                                                 output_dir  \\\n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationLlama200T2Epochs   \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationLlama200T1Epochs   \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/AmsterdamDocClassificationLlama200T3Epochs   \n",
       "\n",
       "   num_train_epochs  \n",
       "0               2.0  \n",
       "0               1.0  \n",
       "0               3.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llama = yeet.loc[yeet['base_model']=='meta-llama/Llama-2-7b-chat-hf']\n",
    "llama = llama.loc[~llama['model'].isin(['FemkeBakker/AmsterdamDocClassificationLlama200T2Epochs'])]\n",
    "llama = llama.loc[~llama['date'].isin(['2024-05-29 16:44:49.778730+02:00'])]\n",
    "llama['model'] = ['FemkeBakker/AmsterdamDocClassificationLlama200T2Epochs', 'FemkeBakker/AmsterdamDocClassificationLlama200T1Epochs', 'FemkeBakker/AmsterdamDocClassificationLlama200T3Epochs']\n",
    "llama['output_dir'] = ['/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationLlama200T2Epochs', '/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationLlama200T1Epochs', '/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/AmsterdamDocClassificationLlama200T3Epochs']\n",
    "display(llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46714/3188728291.py:2: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns, Europe/Amsterdam] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  mistral = mistral.loc[mistral['date'].isin(['2024-06-14 09:58:59.555286+02:00' , '2024-06-14 12:26:24.665959+02:00' , '2024-06-03 13:43:52.561702+02:00'])]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>base_model</th>\n",
       "      <th>chat_dataset</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>resume_from_checkpoint</th>\n",
       "      <th>date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>Error</th>\n",
       "      <th>run_id</th>\n",
       "      <th>save_to_hub</th>\n",
       "      <th>output_dir</th>\n",
       "      <th>num_train_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistral200T1Epochs</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-03 13:43:52.561702+02:00</td>\n",
       "      <td>2617.233767</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationMistral200T1Epochs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistral200T2Epochs</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-14 09:58:59.555286+02:00</td>\n",
       "      <td>4925.885951</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationMistral200T2Epochs</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistral200T3Epochs</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-14 12:26:24.665959+02:00</td>\n",
       "      <td>2984.912049</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/AmsterdamDocClassificationMistral200T3Epochs</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      model  \\\n",
       "0  FemkeBakker/AmsterdamDocClassificationMistral200T1Epochs   \n",
       "0  FemkeBakker/AmsterdamDocClassificationMistral200T2Epochs   \n",
       "0  FemkeBakker/AmsterdamDocClassificationMistral200T3Epochs   \n",
       "\n",
       "                           base_model  \\\n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "\n",
       "                                  chat_dataset train_set test_set  \\\n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "\n",
       "   resume_from_checkpoint                             date      runtime  \\\n",
       "0                   False 2024-06-03 13:43:52.561702+02:00  2617.233767   \n",
       "0                   False 2024-06-14 09:58:59.555286+02:00  4925.885951   \n",
       "0                    True 2024-06-14 12:26:24.665959+02:00  2984.912049   \n",
       "\n",
       "   Error  run_id save_to_hub  \\\n",
       "0  False      25        True   \n",
       "0  False      31        True   \n",
       "0  False      32        True   \n",
       "\n",
       "                                                                                                                                                                   output_dir  \\\n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationMistral200T1Epochs   \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationMistral200T2Epochs   \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/AmsterdamDocClassificationMistral200T3Epochs   \n",
       "\n",
       "   num_train_epochs  \n",
       "0               1.0  \n",
       "0               2.0  \n",
       "0               3.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mistral = yeet.loc[yeet['base_model']== 'mistralai/Mistral-7B-Instruct-v0.2']\n",
    "mistral = mistral.loc[mistral['date'].isin(['2024-06-14 09:58:59.555286+02:00' , '2024-06-14 12:26:24.665959+02:00' , '2024-06-03 13:43:52.561702+02:00'])]\n",
    "mistral = mistral.sort_values(by=['date'])\n",
    "mistral['model'] = ['FemkeBakker/AmsterdamDocClassificationMistral200T1Epochs', 'FemkeBakker/AmsterdamDocClassificationMistral200T2Epochs', 'FemkeBakker/AmsterdamDocClassificationMistral200T3Epochs']\n",
    "mistral['output_dir'] = ['/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationMistral200T1Epochs', '/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationMistral200T2Epochs', '/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/AmsterdamDocClassificationMistral200T3Epochs']\n",
    "display(mistral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>base_model</th>\n",
       "      <th>chat_dataset</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>resume_from_checkpoint</th>\n",
       "      <th>date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>Error</th>\n",
       "      <th>run_id</th>\n",
       "      <th>save_to_hub</th>\n",
       "      <th>output_dir</th>\n",
       "      <th>num_train_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationGEITje200T1Epochs</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-29 14:07:04.642821+02:00</td>\n",
       "      <td>2926.216714</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationGEITje200T1Epochs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationGEITje200T2Epochs</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-29 19:39:27.535325+02:00</td>\n",
       "      <td>2821.834527</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationGEITje200T2Epochs</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationGEITje200T3Epochs</td>\n",
       "      <td>Rijgersberg/GEITje-7B-chat-v2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-03 12:37:59.230015+02:00</td>\n",
       "      <td>3017.832458</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/AmsterdamDocClassificationGEITje200T3Epochs</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistral200T1Epochs</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-03 13:43:52.561702+02:00</td>\n",
       "      <td>2617.233767</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationMistral200T1Epochs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistral200T2Epochs</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-14 09:58:59.555286+02:00</td>\n",
       "      <td>4925.885951</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationMistral200T2Epochs</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationMistral200T3Epochs</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-14 12:26:24.665959+02:00</td>\n",
       "      <td>2984.912049</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/AmsterdamDocClassificationMistral200T3Epochs</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationLlama200T2Epochs</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-29 17:32:34.996990+02:00</td>\n",
       "      <td>2435.851116</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationLlama200T2Epochs</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationLlama200T1Epochs</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-03 14:50:23.584077+02:00</td>\n",
       "      <td>2360.351855</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationLlama200T1Epochs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FemkeBakker/AmsterdamDocClassificationLlama200T3Epochs</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>FemkeBakker/AmsterdamBalancedFirst200Tokens</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-06-03 16:59:27.147043+02:00</td>\n",
       "      <td>2569.094163</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "      <td>/home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/AmsterdamDocClassificationLlama200T3Epochs</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      model  \\\n",
       "0   FemkeBakker/AmsterdamDocClassificationGEITje200T1Epochs   \n",
       "0   FemkeBakker/AmsterdamDocClassificationGEITje200T2Epochs   \n",
       "0   FemkeBakker/AmsterdamDocClassificationGEITje200T3Epochs   \n",
       "0  FemkeBakker/AmsterdamDocClassificationMistral200T1Epochs   \n",
       "0  FemkeBakker/AmsterdamDocClassificationMistral200T2Epochs   \n",
       "0  FemkeBakker/AmsterdamDocClassificationMistral200T3Epochs   \n",
       "0    FemkeBakker/AmsterdamDocClassificationLlama200T2Epochs   \n",
       "0    FemkeBakker/AmsterdamDocClassificationLlama200T1Epochs   \n",
       "0    FemkeBakker/AmsterdamDocClassificationLlama200T3Epochs   \n",
       "\n",
       "                           base_model  \\\n",
       "0       Rijgersberg/GEITje-7B-chat-v2   \n",
       "0       Rijgersberg/GEITje-7B-chat-v2   \n",
       "0       Rijgersberg/GEITje-7B-chat-v2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "0       meta-llama/Llama-2-7b-chat-hf   \n",
       "0       meta-llama/Llama-2-7b-chat-hf   \n",
       "0       meta-llama/Llama-2-7b-chat-hf   \n",
       "\n",
       "                                  chat_dataset train_set test_set  \\\n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "0  FemkeBakker/AmsterdamBalancedFirst200Tokens     train      val   \n",
       "\n",
       "   resume_from_checkpoint                             date      runtime  \\\n",
       "0                   False 2024-05-29 14:07:04.642821+02:00  2926.216714   \n",
       "0                    True 2024-05-29 19:39:27.535325+02:00  2821.834527   \n",
       "0                    True 2024-06-03 12:37:59.230015+02:00  3017.832458   \n",
       "0                   False 2024-06-03 13:43:52.561702+02:00  2617.233767   \n",
       "0                   False 2024-06-14 09:58:59.555286+02:00  4925.885951   \n",
       "0                    True 2024-06-14 12:26:24.665959+02:00  2984.912049   \n",
       "0                    True 2024-05-29 17:32:34.996990+02:00  2435.851116   \n",
       "0                   False 2024-06-03 14:50:23.584077+02:00  2360.351855   \n",
       "0                    True 2024-06-03 16:59:27.147043+02:00  2569.094163   \n",
       "\n",
       "   Error  run_id save_to_hub  \\\n",
       "0  False      15        True   \n",
       "0  False      15        True   \n",
       "0  False      24        True   \n",
       "0  False      25        True   \n",
       "0  False      31        True   \n",
       "0  False      32        True   \n",
       "0  False      17        True   \n",
       "0  False      26        True   \n",
       "0  False      28        True   \n",
       "\n",
       "                                                                                                                                                                   output_dir  \\\n",
       "0   /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationGEITje200T1Epochs   \n",
       "0   /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationGEITje200T2Epochs   \n",
       "0   /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/AmsterdamDocClassificationGEITje200T3Epochs   \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationMistral200T1Epochs   \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationMistral200T2Epochs   \n",
       "0  /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/AmsterdamDocClassificationMistral200T3Epochs   \n",
       "0    /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/2epochs/AmsterdamDocClassificationLlama200T2Epochs   \n",
       "0    /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/1epochs/AmsterdamDocClassificationLlama200T1Epochs   \n",
       "0    /home/azureuser/cloudfiles/code/blobfuse/raadsinformatie/processed_data/woo_document_classification/finetuning_output/3epochs/AmsterdamDocClassificationLlama200T3Epochs   \n",
       "\n",
       "   num_train_epochs  \n",
       "0               1.0  \n",
       "0               2.0  \n",
       "0               3.0  \n",
       "0               1.0  \n",
       "0               2.0  \n",
       "0               3.0  \n",
       "0               2.0  \n",
       "0               1.0  \n",
       "0               3.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_overview_models = pd.concat([geitje, mistral, llama])\n",
    "display(clean_overview_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_overview_models.to_pickle(f\"{cf.output_path}/finetuning_output/clean_overview_models.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
